[["index.html", "edav.info, 2nd edition Chapter 1 Welcome!", " edav.info, 2nd edition Joyce Robbins 2022-04-05 Chapter 1 Welcome! This is the brand new start of edav.info 2.0! The first version of edav.info is still available, but will no longer be updated. With this resource, we try to give you a curated collection of tools and references that will make it easier to learn how to work with data in R. Detailed Examples will also be used to show proper exploratory data analysis under different circumstances. This resource is specifically tailored to the GR5293 Statistical Graphics and GR5702 Exploratory Data Analysis and Visualization courses offered at Columbia University. However, we hope that anyone interested in working with data in R will benefit from these pages. Happy coding! (Note. edav.info 2.0 is still under construction, and we will try our best to update new chapters weekly so that it will be up-to-date with the information you need to complete the current problem set.) "],["getting-started.html", "Chapter 2 Getting started 2.1 Top 10 essentials checklist 2.2 Troubleshooting 2.3 Tips &amp; tricks", " Chapter 2 Getting started Welcome to the world of EDAV! As you have already known, we will mainly use R through out the course. In an effort to get everyone on the same page, here is a checklist of essentials so you can get up and running. The best resources are scattered in different places online, so bear with links to various sites depending on the topic. 2.1 Top 10 essentials checklist (r4ds = R for Data Science by Garrett Grolemund and Hadley Wickham, free online) Install R (r4ds) – You need to have this installed but you won’t open the application since you’ll be working in RStudio. If you already installed R, make sure you’re current! The latest version of R (as of 2022-01-18) is R 4.1.2 “Bird Hippie” released on 2021/11/01. Install RStudio (r4ds) – Download the free, Desktop version for your OS. Working in this IDE will make working in R much more enjoyable. As with R, stay current. RStudio is constantly adding new features. The latest version (as of 2022-01-18) is RStudio 2021.09.2+382 (“Ghost Orchid”) release notes. Get comfortable with RStudio – In this chapter of Bruno Rodriguez’s Modern R with the Tidyverse, you’ll learn about panes, options, getting help, keyboard shortcuts, projects, add-ins, and packages. Be sure to try out: Do some math in the console Create an R Markdown file (.Rmd) and render it to .html Install some packages like tidyverse or MASS Another great option for learning the IDE: Watch Writing Code in RStudio (RStudio webinar) Learn “R Nuts and Bolts” – Roger Peng’s chapter in R Programming will give you a solid foundation in the basic building blocks of R. It’s worth making the investing in understanding how R objects work now so they don’t cause you problems later. Focus on vectors and especially data frames; matrices and lists don’t come up often in data visualization. Get familiar with R classes: integer, numeric, character, and logical. Understand how factors work; they are very important for graphing. Tidy up (r4ds) – Install the tidyverse, and get familiar with what it is. We will discuss differences between base R and the tidyverse in class. Learn ggplot2 basics (r4ds) – In class we will study the grammar of graphics on which ggplot2 is based, but it will help to familiarize yourself with the syntax in advance. Avail yourself of the “Data Visualization with ggplot2” cheatsheet by clicking “Help” “Cheatsheets…” within RStudio. Learn some RMarkdown – For this class you will write assignments in R Markdown (stored as .Rmd files) and then render them into pdfs for submission. You can jump right in and open a new R Markdown file (File &gt; New File &gt; R Markdown…), and leave the Default Output Format as HTML. You will get a R Markdown template you can tinker with. Click the “knit” button and see what happens. For more detail, watch the RStudio webinar Getting Started with R Markdown Use RStudio projects (r4ds) – If you haven’t already, drink the Kool-Aid. Make each problem set a separate project. You will never have to worry about getwd() or setwd() again because everything will just be in the right places. Or watch the webinar: “Projects in RStudio”. If you run into a situation in which you must change the filepaths used to read files depending on whether you are running the code in the Console or knitting the document, it is likely due to having .Rmd files stored in subfolders of the project. The here package will eliminate the need for you to repeatedly make these changes by creating relative paths from the project root, that just work. This is a small but powerful tool; once you start using it there’s no going back. Learn the basic dplyr verbs for data manipulation (r4ds) – Concentrate on the main verbs: filter() (rows), select() (columns), mutate(), arrange() (rows), group_by(), and summarize(). Learn the pipe %&gt;% operator. Know how to tidy your data – The pivot_longer() function from the tidyr package – successor to gather() – will help you get your data in the right form for plotting. More on this in class. Check out these super cool animations, which follow a data frame as it is transformed by tidyr functions. 2.2 Troubleshooting 2.2.1 Document doesn’t knit Normally an error message will display in the R Markdown section pointing to some lines with specific reasons. Try Googling as your first option and if not finding a solution, leave a post on ed discussion. 2.2.2 Functions stop working Strange behavior from functions that previously worked are often caused by function conflicts. This can happen if you have two packages loaded with the same function names. To indicate the proper package, namespace it. Conflicts commonly occur with select and filter and map. If you intend the tidyverse ones use: dplyr::select, dplyr::filter and purrr::map. Some other culprits: dplyr::summarise() and vcdExtra::summarise() ggmosaic::mosaic() and vcd::mosaic() leaflet::addLegend() and xts::addLegend() dplyr::select and MASS::select 2.3 Tips &amp; tricks 2.3.1 knitr Upon creating a new R markdown file, you should always notice a section like this: {r setup, include=False} knitr::opts_chunk$set(echo = TRUE) The chunk options refer to the first line and you can add some of the following options: {r setup, include=False, warning=False, message=False, cache=True} knitr::opts_chunk$set(echo = TRUE) warning=FALSE - Suppress warnings message=FALSE – Suppress messages, especially useful when loading packages cache=TRUE – only changed chunks will be evaluated, be careful though since changes in dependencies will not be detected. 2.3.2 Sizing figures Always use chunk options to size figures. You can set a default size in the YAML at the beginning of the .Rmd file as so: output: pdf_document: fig_height: 3 fig_width: 5 Another method is to click the gear ⚙️ next to the Knit button, then Output Options…, and finally the Figures tab. Then as needed override one or more defaults in particular chunks: {r, fig.width=4, fig.height=2} Figure related chunk options include fig.width, fig.height, fig.asp, and fig.align; there are many more. 2.3.3 R studio keyborad shortcuts Insert R chunk - option-command-i (Mac) - ctrl+alt+I (Windows) ```{r} ``` Insert %&gt;% (“the pipe”): shift-command(ctrl)-M Mac/Windows Comment/Uncomment lines shift-command(ctrl)-C Mac/Windows Knit Document shift-command(ctrl)-K Mac/Windows For more shortcuts, refer here 2.3.4 Viewing plots in plot window Would you like your plots to appear in the plot window instead of below each chunk in the .Rmd file? Click ⚙️ and then Chunk Output in Console. 2.3.5 Adding figures and links Add images ![DESCRIPTION HERE](PATH HERE) Add links: The text in the content column will act as a hyperlink [CONTENT HERE](LINK HERE) Note: Do not use these in r chunks as they will not work. "],["working-with-factors.html", "Chapter 3 Working with factors 3.1 Recode factor levels 3.2 Relevel the factor 3.3 Reorder the factors 3.4 Dealing wirh NAs 3.5 Summary of useful functions 3.6 Continuous to Categorical", " Chapter 3 Working with factors As what we have mentioned in the previous chapter, R sorts levels of factors in alphabetical order by default. In this chapter we will talk about working with factors using forcats package, which can be helpful when you managing categorical variables. 3.1 Recode factor levels Don’t directly assign levels with levels()&lt;-. Instead, using fct_recode(). library(forcats) x &lt;- factor(c(&quot;G234&quot;, &quot;G452&quot;, &quot;G136&quot;)) y &lt;- fct_recode(x, Physics = &quot;G234&quot;, Math = &quot;G452&quot;, Chemistry = &quot;G136&quot;) y ## [1] Physics Math Chemistry ## Levels: Chemistry Physics Math 3.2 Relevel the factor For the binned, ordinal data with levels out of order, fct_relevel() can be used to set a correct order. library(tibble) library(ggplot2) Births2015 &lt;- tibble(MotherAge = c(&quot;15-19 years&quot;, &quot;20-24 years&quot;, &quot;25-29 years&quot;, &quot;30-34 years&quot;, &quot;35-39 years&quot;, &quot;40-44 years&quot;, &quot;45-49 years&quot;, &quot;50 years and over&quot;, &quot;Under 15 years&quot;), Num = c(229.715, 850.509, 1152.311, 1094.693, 527.996, 111.848, 8.171, .754, 2.5)) ggplot(Births2015, aes(fct_relevel(MotherAge, &quot;Under 15 years&quot;), Num)) + geom_col() + coord_flip() + scale_y_continuous(breaks = seq(0, 1250, 250)) + ggtitle(&quot;United States Births, 2015&quot;, subtitle = &quot;in thousands&quot;) + theme_grey(16) + labs(y = &quot;mother age&quot;, x = &quot;count&quot;) The following examples give three circumstances when using fct_relevel(). Using fct_relevel() to move levels to the beginning: x &lt;- c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;move1&quot;, &quot;D&quot;, &quot;E&quot;, &quot;move2&quot;, &quot;F&quot;) fct_relevel(x, &quot;move1&quot;, &quot;move2&quot;) ## [1] A B C move1 D E move2 F ## Levels: move1 move2 A B C D E F Using fct_relevel() to move levels after an item (by position): x &lt;- c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;move1&quot;, &quot;D&quot;, &quot;E&quot;, &quot;move2&quot;, &quot;F&quot;) fct_relevel(x, &quot;move1&quot;, &quot;move2&quot;, after = 4) # move after the fourth item ## [1] A B C move1 D E move2 F ## Levels: A B C D move1 move2 E F Using fct_relevel() to move levels to the end x &lt;- c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;move1&quot;, &quot;D&quot;, &quot;E&quot;, &quot;move2&quot;, &quot;F&quot;) fct_relevel(x, &quot;move1&quot;, &quot;move2&quot;, after = Inf) ## [1] A B C move1 D E move2 F ## Levels: A B C D E F move1 move2 If the row order is correct, use fct_inorder(): df &lt;- data.frame(temperature = factor(c(&quot;cold&quot;, &quot;warm&quot;, &quot;hot&quot;)), count = c(15, 5, 22)) # row order is correct (think: factor in ROW order) ggplot(df, aes(x = fct_inorder(temperature), y = count)) + geom_col() + theme_grey(16) + labs( x = &quot;temperature&quot;) 3.3 Reorder the factors Usually, unbinned, nominal data should be sorted by frequency order, which can be achieved using fct_infreq() (default is decreasing order of frequency) df &lt;- data.frame( color = c(&quot;orange&quot;,&quot;blue&quot;, &quot;red&quot;,&quot;brown&quot;,&quot;yellow&quot;, &quot;green&quot;, &quot;orange&quot;, &quot;red&quot;, &quot;yellow&quot;,&quot;blue&quot;,&quot;blue&quot;,&quot;red&quot;,&quot;orange&quot;,&quot;blue&quot;,&quot;red&quot;,&quot;orange&quot;,&quot;orange&quot;) ) ggplot(df, aes(fct_infreq(color))) + geom_bar() + theme_grey(16) For binned, nominal data which should be sorted by frequency order, use fct_reorder(). In the following example count is used, generally you can also apply mean,median, etc. to .fun inside `fct_reorder()``. pack1 &lt;- data.frame( color = c(&quot;blue&quot;, &quot;brown&quot;, &quot;green&quot;, &quot;orange&quot;, &quot;red&quot;, &quot;yellow&quot;), count = c(13, 7, 12, 9, 7, 8) ) ggplot(pack1, aes(fct_reorder(color, count, .desc = TRUE), count)) + geom_col() + theme_grey(16) + labs(x = &quot;color&quot;) 3.4 Dealing wirh NAs For prominent NA bars which should not be eliminated, use fct_explicit_na(x). And using fct_rev(x) to reverse the factor level doesn’t help. library(dplyr) df &lt;- data.frame(temperature = factor(c(&quot;cold&quot;, &quot;warm&quot;, &quot;hot&quot;, NA)), count = c(15, 5, 22, 12)) df %&gt;% mutate(temperature = fct_explicit_na(temperature, &quot;NA&quot;) %&gt;% fct_relevel(&quot;NA&quot;, &quot;hot&quot;, &quot;warm&quot;, &quot;cold&quot;)) %&gt;% ggplot(aes(x = temperature, y = count)) + geom_col() + coord_flip() + theme_grey(16) + labs(x = &quot;temperature&quot;) 3.5 Summary of useful functions For analyzing categorical variables, the first step is always to decide whether the class is ordinal or nominal. fct_recode(x, …) – change names of levels fct_inorder(x) – set level order of x to row order fct_relevel(x, …) – manually set the order of levels of x fct_reorder(x, y) – reorder x by y fct_infreq(x) – order the levels of x by decreasing frequency fct_rev(x) – reverse the order of factor levels of x fct_explicit_na(x) – turn NAs into a real factor level 3.6 Continuous to Categorical Sometimes you want to transfer a continuous variable to a categorical variable. For example, you might want assign grades to final scores of a course. In the following example, we generated a data set of test scores randomly and we assign grades based on some thresholds. We then apply function cut. (You can similarly use case_when) set.seed(2022) testscore &lt;- round(runif(100, min = 70, max = 100)) df &lt;- data.frame(testscore) |&gt; mutate(grade = cut(testscore, breaks = seq(70, 100, 10), labels = c(&quot;C&quot;, &quot;B&quot;, &quot;A&quot;), right = FALSE, include.lowest = TRUE)) head(df) ## testscore grade ## 1 94 A ## 2 89 B ## 3 74 C ## 4 86 B ## 5 76 C ## 6 89 B "],["data-transformation.html", "Chapter 4 Data transformation 4.1 What is tidy data? 4.2 pivot_longer 4.3 pivot_wider 4.4 Basic transformation functions", " Chapter 4 Data transformation Plotting a graph is easy. You just need to find the right library with the right function. However, it is sometimes not so easy to get your data into the form desired to generate a graph. In this chapter, we will cover some basic techniques in tidying data with ggplot2. 4.1 What is tidy data? Here’s the definition of Tidy Data given by Hadley Wickham: A dataset is messy or tidy depending on how rows, columns and tables are matched up with observations, variables and types. In tidy data: Each variable forms a column. Each observation forms a row. Each observational unit forms a value in the table. See r4ds on tidy data for more info. What are the advantages of tidy data? Uniformity : It is easier to learn the tools that work with the data because they have a consistent way of storing data. Most built-in R functions work with vectors of values. Thus, having variables as columns/vectors allows R’s vectorized nature to shine. Take a look at the following data and can you tell whether this data is messy or not? ## mpg cyl disp hp drat wt qsec vs am gear carb ## Mazda RX4 21.0 6 160 110 3.90 2.620 16.46 0 1 4 4 ## Mazda RX4 Wag 21.0 6 160 110 3.90 2.875 17.02 0 1 4 4 ## Datsun 710 22.8 4 108 93 3.85 2.320 18.61 1 1 4 1 ## Hornet 4 Drive 21.4 6 258 110 3.08 3.215 19.44 1 0 3 1 ## Hornet Sportabout 18.7 8 360 175 3.15 3.440 17.02 0 0 3 2 ## Valiant 18.1 6 225 105 2.76 3.460 20.22 1 0 3 1 In this data set,all the variables are parameters of cars. This means that they are not different variables, but are values of a common variable. To transform the data, we use pivot_longer. 4.2 pivot_longer mtcars %&gt;% rownames_to_column(&quot;carname&quot;) %&gt;% pivot_longer(cols = !carname, names_to = &quot;Parameters&quot;,values_to = &quot;value&quot;) %&gt;% head() ## # A tibble: 6 × 3 ## carname Parameters value ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Mazda RX4 mpg 21 ## 2 Mazda RX4 cyl 6 ## 3 Mazda RX4 disp 160 ## 4 Mazda RX4 hp 110 ## 5 Mazda RX4 drat 3.9 ## 6 Mazda RX4 wt 2.62 Follow the simple two steps: Identify the column you want to keep as is. In this case, we want all variables to match car names. Additionally, notice that in the original data set, carname acts as the index of the data set. You would want to convert the index to a column using rownames_to_column. Create meaningful names for the two new columns. In our case, straightforwardly, column names go into parameters and corresponding values go into value. 4.3 pivot_wider pivot_wider is just the opposite of pivot_longer. Using pivot_wider, we can transform our tidy data back into the messy form as all distinct values in Parameters will become column names. pivot_wider is often used in the case such that one observation being recorded over multiple rows. Consider the following example: ## # A tibble: 4 × 3 ## Country Type Number ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 USA Case 4 ## 2 USA Death 3 ## 3 Canada Case 2 ## 4 Canada Death 1 example %&gt;% pivot_wider(names_from = Type, values_from = Number) ## # A tibble: 2 × 3 ## Country Case Death ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 USA 4 3 ## 2 Canada 2 1 It would make much more sense if Case and Death are separate features. The main focus of this chapter is pivot_longer and pivot_wider. However, other fundamental functions in dplyr are also very important in manipulating your data set. In the following section, we will give an overview of the basics. 4.4 Basic transformation functions For the following sections, we will use data set biopsy from MASS for demonstration purpose. ## ID V1 V2 V3 V4 V5 V6 V7 V8 V9 class ## 1 1000025 5 1 1 1 2 1 3 1 1 benign ## 2 1002945 5 4 4 5 7 10 3 2 1 benign ## 3 1015425 3 1 1 1 2 2 3 1 1 benign ## 4 1016277 6 8 8 1 3 4 3 7 1 benign ## 5 1017023 4 1 1 3 2 1 3 1 1 benign ## 6 1017122 8 10 10 8 7 10 9 7 1 malignant 4.4.1 rename Upon getting the data, we noticed that the names of the columns are very vague. After reading the documentation, we wanted to change the names of the column so that the viewer gets a sense of the values they’re referring to. We use rename to modify the column names. biopsy_new &lt;- rename(biopsy, thickness = V1,cell_size = V2, cell_shape = V3, marg_adhesion = V4, epithelial_cell_size = V5, bare_nuclei = V6, chromatin = V7, norm_nucleoli = V8, mitoses = V9) head(biopsy_new) ## ID thickness cell_size cell_shape marg_adhesion epithelial_cell_size ## 1 1000025 5 1 1 1 2 ## 2 1002945 5 4 4 5 7 ## 3 1015425 3 1 1 1 2 ## 4 1016277 6 8 8 1 3 ## 5 1017023 4 1 1 3 2 ## 6 1017122 8 10 10 8 7 ## bare_nuclei chromatin norm_nucleoli mitoses class ## 1 1 3 1 1 benign ## 2 10 3 2 1 benign ## 3 2 3 1 1 benign ## 4 4 3 7 1 benign ## 5 1 3 1 1 benign ## 6 10 9 7 1 malignant 4.4.2 select select is column-wise operation. Specifically, only the columns that are specified will be returned. In the biopsy data, we do not require the variables “chromatin” and “mitoses”. So, let’s drop them using a minus sign: #selecting all except the columns chromatin and mitoses biopsy_new &lt;- biopsy_new %&gt;% dplyr::select(-chromatin,-mitoses) head(biopsy_new,5) ## ID thickness cell_size cell_shape marg_adhesion epithelial_cell_size ## 1 1000025 5 1 1 1 2 ## 2 1002945 5 4 4 5 7 ## 3 1015425 3 1 1 1 2 ## 4 1016277 6 8 8 1 3 ## 5 1017023 4 1 1 3 2 ## bare_nuclei norm_nucleoli class ## 1 1 1 benign ## 2 10 2 benign ## 3 2 1 benign ## 4 4 7 benign ## 5 1 1 benign 4.4.3 mutate The mutate function computes new variables from the already existing variables and adds them to the dataset. It gives information that the data already contained but was never displayed. The variable bare_nucleus contains the values from 1.00 to 10.00. If we wish to normalize the variable, we can use the mutate function: #normalize the bare nuclei values maximum_bare_nuclei&lt;-max(biopsy_new$bare_nuclei,na.rm=TRUE) biopsy_new &lt;- biopsy_new %&gt;% mutate(bare_nuclei=bare_nuclei/maximum_bare_nuclei) head(biopsy_new,5) ## ID thickness cell_size cell_shape marg_adhesion epithelial_cell_size ## 1 1000025 5 1 1 1 2 ## 2 1002945 5 4 4 5 7 ## 3 1015425 3 1 1 1 2 ## 4 1016277 6 8 8 1 3 ## 5 1017023 4 1 1 3 2 ## bare_nuclei norm_nucleoli class ## 1 0.1 1 benign ## 2 1.0 2 benign ## 3 0.2 1 benign ## 4 0.4 7 benign ## 5 0.1 1 benign In some situations, your new variable might involve conditions. You can consider using case_when combined with mutate. 4.4.4 select Filter is a row-wise operation. It returns a modified copy that contains only certain rows. This function filters rows based on conditions supplied in its argument. The filter function takes the data frame as the first argument. The next argument contains one or more logical tests. The rows/observations that pass these logical tests are returned in the result of the filter function. For our example, say we only want the data of those tumor cells that have clump thickness greater than 6. biopsy_new &lt;- biopsy_new %&gt;% filter(thickness&gt;5.5) head(biopsy_new,5) ## ID thickness cell_size cell_shape marg_adhesion epithelial_cell_size ## 1 1016277 6 8 8 1 3 ## 2 1017122 8 10 10 8 7 ## 3 1044572 8 7 5 10 7 ## 4 1047630 7 4 6 4 6 ## 5 1050670 10 7 7 6 4 ## bare_nuclei norm_nucleoli class ## 1 0.4 7 benign ## 2 1.0 7 malignant ## 3 0.9 5 malignant ## 4 0.1 3 malignant ## 5 1.0 1 malignant If you want to filter using multiple conditions, use logical operators: &amp;(And), |(Or). 4.4.5 arrange Arrange reorders the rows of the data based on their contents in the ascending order by default. Say in our example, the doctors would want to view the data in the order of the cell size of the tumor. #arrange in the order of V2:cell size head(arrange(biopsy_new,cell_size)) ## ID thickness cell_size cell_shape marg_adhesion epithelial_cell_size ## 1 1050718 6 1 1 1 2 ## 2 1204898 6 1 1 1 2 ## 3 1223967 6 1 3 1 2 ## 4 543558 6 1 3 1 4 ## 5 63375 9 1 2 6 4 ## 6 752904 10 1 1 1 2 ## bare_nuclei norm_nucleoli class ## 1 0.1 1 benign ## 2 0.1 1 benign ## 3 0.1 1 benign ## 4 0.5 10 malignant ## 5 1.0 7 malignant ## 6 1.0 4 malignant In case you want your data in descending order, wrap your variable with desc(). 4.4.6 group_by and summarize The summarize function uses the data to create a new data frame with the summary statistics such as minimum, maximum, average, and so on. These statistical functions must be aggregate functions which take a vector of values as input and output a single value. The group_by function groups the data by the values of the variables. This, along with summarize, makes observations about groups of rows of the dataset. The doctors would want to see the maximum cell size and the thickness for each of the classes: benign and malignant. This can be done by grouping the data by class and finding the maximum of the required variables: biopsy_grouped &lt;- group_by(biopsy_new,class) summarize(biopsy_grouped, max(thickness), mean(cell_size), var(norm_nucleoli)) ## # A tibble: 2 × 4 ## class `max(thickness)` `mean(cell_size)` `var(norm_nucleoli)` ## &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 benign 8 2.67 5.93 ## 2 malignant 10 6.73 11.3 4.4.7 slice_max (slice_min) The slice_max function helps you to find the top n values of a specific column. Suppose we now want to see the top five biopsies with the biggest thickness. Notice in this case, since we have more than five rows with thickness 10, all of them are selected (for neatness, we only show first several rows). biopsy_new %&gt;% slice_max(order_by = thickness,n=5) %&gt;% head() ## ID thickness cell_size cell_shape marg_adhesion epithelial_cell_size ## 1 1050670 10 7 7 6 4 ## 2 1054593 10 5 5 3 6 ## 3 1072179 10 7 7 3 8 ## 4 1080185 10 10 10 8 6 ## 5 1099510 10 4 3 1 3 ## 6 1103608 10 10 10 4 8 ## bare_nuclei norm_nucleoli class ## 1 1.0 1 malignant ## 2 0.7 10 malignant ## 3 0.5 4 malignant ## 4 0.1 9 malignant ## 5 0.3 5 malignant ## 6 0.1 10 malignant 4.4.8 join Sometimes you will need to combine two data sets and this is when function join comes into play. There are four types of joins provided by dplyr and take a look at the following example. # Main dataset s77 &lt;- data.frame(state.x77) %&gt;% rownames_to_column(&quot;state&quot;) %&gt;% dplyr::select(-c(Illiteracy)) head(s77) ## state Population Income Life.Exp Murder HS.Grad Frost Area ## 1 Alabama 3615 3624 69.05 15.1 41.3 20 50708 ## 2 Alaska 365 6315 69.31 11.3 66.7 152 566432 ## 3 Arizona 2212 4530 70.55 7.8 58.1 15 113417 ## 4 Arkansas 2110 3378 70.66 10.1 39.9 65 51945 ## 5 California 21198 5114 71.71 10.3 62.6 20 156361 ## 6 Colorado 2541 4884 72.06 6.8 63.9 166 103766 # https://www.cookpolitical.com/2020-national-popular-vote-tracker partyinfo &lt;- read_csv(&quot;https://docs.google.com/spreadsheets/d/e/2PACX-1vS3Z8Rq9xqOLISwoKdK0n6CFLBuPSCoXbbLeY8vhi-rzFS3ZFNEtR0BCdEbHcS-2Tlh5aPcnZbwBLao/pub?output=csv&quot;) partyinfo &lt;- partyinfo %&gt;% dplyr::select(state, called) head(left_join(s77, partyinfo)) ## state Population Income Life.Exp Murder HS.Grad Frost Area called ## 1 Alabama 3615 3624 69.05 15.1 41.3 20 50708 R ## 2 Alaska 365 6315 69.31 11.3 66.7 152 566432 R ## 3 Arizona 2212 4530 70.55 7.8 58.1 15 113417 D ## 4 Arkansas 2110 3378 70.66 10.1 39.9 65 51945 R ## 5 California 21198 5114 71.71 10.3 62.6 20 156361 D ## 6 Colorado 2541 4884 72.06 6.8 63.9 166 103766 D s77 contains statistics of 50 states in the US and partyinfo holds information whether a state is democratic or republican. The two data sets are joined on common feature state. If you want to join on features with different names, specify using the argument by. For detailed explanations of differnet types of joins, refer to the documentation. 4.4.9 Cases to tables When you want to perform a Chi-squared test or create a paired mosaic plot, your data has to follow a table format. For example, the following table is in the correct format. The columns are anxiety statues and rows are class years. ## moderate normal severe ## 1 11 34 2 ## 2 22 69 4 ## 3 8 41 5 ## 4 15 37 5 The following example demonstrates how you can convert cases to tables. Notice the starting data has a count for each of the categorical combinations. # watch out: summarise rebates &lt;- read_csv(&quot;https://data.ny.gov/resource/thd2-fu8y.csv&quot;) rebate_counts &lt;- rebates |&gt; group_by(make, ev_type) |&gt; summarize(Freq = n()) head(rebate_counts) ## # A tibble: 6 × 3 ## # Groups: make [3] ## make ev_type Freq ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 Audi BEV 6 ## 2 Audi PHEV 1 ## 3 BMW BEV 1 ## 4 BMW PHEV 9 ## 5 Chevrolet BEV 69 ## 6 Chevrolet PHEV 33 By using xtabs, we are able to transform our data into a table ready for Chi-squared test or paired mosaic plot. head(xtabs(Freq ~ ., data = rebate_counts)) ## ev_type ## make BEV PHEV ## Audi 6 1 ## BMW 1 9 ## Chevrolet 69 33 ## Chrysler 0 10 ## Ford 1 27 ## Honda 0 42 "],["gitgithub-resources.html", "Chapter 5 git/GitHub resources", " Chapter 5 git/GitHub resources Please see the git chapter in the first edition: https://jtr13.github.io/EDAV/github.html "],["learning-ggplot2.html", "Chapter 6 Learning ggplot2 6.1 Getting started 6.2 Default part: layer 6.3 Customized parts 6.4 Resources for ggplot2", " Chapter 6 Learning ggplot2 6.1 Getting started Hopefully, most of you already have experiences in plotting basic R graphics. In this Chapter, you will be briefly introduced one of the most powerful plotting packages in R: ggplot2 with it’s basic grammar and functions. To start, install ggplot2 in the console or in R chunk. install.packages(&#39;ggplot2&#39;) 6.2 Default part: layer For many R beginners, the question is always like: why is ggplot? One remarkable feature of ggplot2 is having an underlying grammar which enables you to compose graphs by combining different components. You can easily create novel graphics by adding ggplot2 functions to meet your needs based on your data. By definition of the grammar of graphics, the most important features are data and mapping in the layers and that’s where we are getting started. library(ggplot2) ggplot(data = iris) + #Data part geom_point(aes(Sepal.Length, Sepal.Width)) #Mapping part The most important part of all plots is data, which includes the information you want to visualize. Based on that, the next step is to decide its mapping, which determine how the data’s variable are mapped to aesthetic attributes on a graphic. Since data is independent from the other elements, you can always add several layers of data into the same ggplot while keeping the other components the same. ggplot(data = iris) + #Data part geom_point(aes(Petal.Length, Petal.Width)) + #layer 1 with mapping geom_point(aes(Sepal.Length, Sepal.Width), color=&#39;red&#39;) #layer 2 with a different mapping 6.3 Customized parts The following picture shows the order of ggplot functions: For more function order suggestions and auto-correction when writing your own ggplot2 functions, please refer to ggformat addin created by Joyce. 6.3.1 Geometric object, statistical transformation and position adjustment Geometric object, Statistical transformation and Position adjustment are components that can be customized in each layer. Geometric objects geoms control the type of plot you create. Different types of plot have different aesthetics features. For example, a point geom has position, color, shape, and size aesthetics. You should first decide which kind of plot better explains the data before choosing geoms and use help function to check what aesthetics can be modified to achieve your desired effects. A statistical transformation stat transforms the data. And Position adjustment is applied when you need to adjust the position of elements on the plot for dense data, otherwise data points might obscure one another. ggplot(data = iris) + geom_histogram(mapping=aes(x=Petal.Length, fill=Species), stat = &#39;bin&#39;,position = &#39;stack&#39;) 6.3.2 Scale A scale controls how data is mapped to aesthetic attributes, so one scale for one layer. ggplot(data = iris) + geom_histogram(mapping=aes(x=Petal.Length, fill=Species), stat = &#39;bin&#39;,position = &#39;stack&#39;) + scale_x_continuous(limits = c(0, 10)) + scale_y_continuous(limits = c(0, 50)) 6.3.3 Coordinate system A coordinate system coord maps the position of objects onto the plane of the plot, and controls how the axes and grid lines are drawn. One ggplot can only have one coord ggplot(data = iris) + geom_histogram(mapping=aes(x=Petal.Length, fill=Species), stat = &#39;bin&#39;,position = &#39;stack&#39;) + coord_polar() 6.3.4 Faceting Faceting can be used to split the data up into subsets of the entire dataset. ggplot(data = iris) + geom_histogram(mapping=aes(x=Petal.Length), stat = &#39;bin&#39;) + facet_wrap(iris$Species) 6.3.5 Labels Labels include titles, labels for x,y axis and annotates. Good graphics also need to give clear information by using labels to tell readers’ of the background knowledge of your data. ggplot(data = iris) + geom_histogram(mapping=aes(x=Petal.Length, fill=Species), stat = &#39;bin&#39;,position = &#39;stack&#39;) + ggtitle(&#39;Stacked petal length of different species&#39;) + xlab(&#39;Length of Petal&#39;) 6.4 Resources for ggplot2 For more implementations and examples, one easiest way is referring to the ggplot2 Cheatsheets provided by R. Follow the steps shown below and you can find the cheat-sheets in your RStudio. The cheat-sheets clearly list the basic components of a ggplot where you can customize your unique plot by choosing different functions. If you are seeking for more detailed explanations and examples with real datasets, here are some useful links for you: ggplot2: Elegant Graphics ggformat "],["faceting-1.html", "Chapter 7 Faceting 7.1 Faceting on one variable 7.2 Faceting on two variables", " Chapter 7 Faceting In this chapter, we will introduce facets, which are usually used to combine continuous and categorical data. 7.1 Faceting on one variable Facet partitions a plot into a matrix of panels. Each panel shows a different subset of the data. By default, facet_wrap gives consistent scales, which is easier for comparison between different panels. library(ggplot2) mycol = &quot;#7192E3&quot; ggplot(iris, aes(Sepal.Length, Sepal.Width)) + geom_point(color = mycol) + facet_wrap(~Species) + theme_grey(18) Rather than faceting on factor level, we can have one panel for each numerical variable. library(pgmm) library(dplyr) library(tidyr) data(wine) tidywine &lt;- wine %&gt;% pivot_longer(cols = -Type, names_to = &quot;variable&quot;, values_to = &quot;value&quot;) tidywine %&gt;% ggplot(aes(value)) + geom_histogram() + facet_wrap(~variable) + ggtitle(&quot;Consistent scales&quot;) + theme_grey(14) Axis scales can be made independent, by setting scales to free, free_x, or free_y. In this case, scales = \"free_x\" is a better option because the distribution of each numerical variable is more obvious. tidywine %&gt;% ggplot(aes(value)) + geom_histogram() + facet_wrap(~variable,scales = &quot;free_x&quot;) + ggtitle(&quot;Consistent scales&quot;) + theme_grey(14) 7.2 Faceting on two variables facet_grid can be used to split data-sets on two variables and plot them on the horizontal and/or vertical direction. wine %&gt;% mutate(Type = paste(&quot;Type&quot;, Type)) %&gt;% select(1:6) %&gt;% pivot_longer(cols = -Type, names_to = &quot;variable&quot;, values_to = &quot;value&quot;) %&gt;% ggplot(aes(value)) + geom_histogram(color = mycol, fill = &quot;lightblue&quot;) + facet_grid(Type ~ variable, scales = &quot;free_x&quot;) + theme_grey(14) "],["unidimensional-continuous-variables.html", "Chapter 8 Unidimensional continuous variables 8.1 Histogram 8.2 Boxplots 8.3 Ridgeline plot 8.4 Normal distribution", " Chapter 8 Unidimensional continuous variables In this chapter, we will demonstrate graphs with unidimensional continuous variables only using ggplot2. 8.1 Histogram 8.1.1 Basics and implications We will start with an easy example. library(ggplot2) library(gridExtra) #Example data x &lt;- c(50, 51, 53, 55, 56, 60, 65, 65, 68) #Stored as a dataframe df &lt;- data.frame(x) ggplot(df, aes(x)) + ggtitle(&quot;Histogram of x with ggplot2&quot;) + geom_histogram(color = &quot;blue&quot;, fill = &quot;lightBlue&quot;, binwidth = 5, center = 52.5) In this example, we used geom_histogram to create a histogram on variable x. We can see that it is quick to make and does not need much pre-processing. Moreover, Histograms show data’s empirical distribution within a set of intervals and we suggest using it as a one of the first steps to understand your data. Note: as shown above, ggplot expects a dataframe, so make sure you do not throw a vector into ggplot. 8.1.2 Types of histograms The y-scale of histograms can be represented in a variety of ways to express different results: Frequency or count: y = number of values that fall in each bin ggplot(finches, aes(x = Depth)) + geom_histogram(color=&quot;blue&quot;,fill=&quot;lightblue&quot;,binwidth = 0.5,boundary = 6) + ggtitle(&quot;Frequency histogram&quot;) Cumulative frequency: y = total number of values &lt;= (or &lt;) right boundary of bin ggplot(finches, aes(x = Depth)) + geom_histogram(aes(y=cumsum(..count..)),color=&quot;blue&quot;,fill=&quot;lightblue&quot;,binwidth = 0.5, boundary = 6) + ggtitle(&quot;Cumulative frequency histogram&quot;) + xlab(&quot;Cumulative frequency&quot;) Density: y = relative frequency / binwidth ggplot(finches, aes(x = Depth)) + geom_histogram(aes(y=..density..),color=&quot;blue&quot;,fill=&quot;lightblue&quot;,binwidth = 0.5, boundary = 6) + ggtitle(&quot;Density histogram&quot;) 8.1.3 Parameters for geom_histogram 8.1.3.1 Bin boundaries Be mindful of the boundaries of the bins and whether a point will fall into the left or right bin if it is on a boundary. You can use the parameter closed to control the intervals. p1 &lt;- ggplot(df, aes(x)) + geom_histogram(color=&quot;blue&quot;,fill=&quot;lightblue&quot;, binwidth = 5, center = 52.5, closed=&quot;left&quot;) + ggtitle(&quot;Left closed graph&quot;) p2 &lt;- ggplot(df, aes(x)) + geom_histogram(color=&quot;blue&quot;,fill=&quot;lightblue&quot;, binwidth = 5, center = 52.5, closed=&quot;right&quot;) + ggtitle(&quot;Right closed graph&quot;) grid.arrange(p1, p2, ncol = 2) 8.1.3.2 Bin numbers #Default / Only adding some styles to make graph consistent ggplot(finches, aes(x = Depth)) + geom_histogram(color=&quot;blue&quot;,fill=&quot;lightblue&quot;) + ggtitle(&quot;Default with pop-up about bin number&quot;) We start by passing no parameters into geom_histogram and you will notice a pop-up saying that the default number of bins is 30. We see that the graph is not ideal with some gaps. There are two ways to modify the number of bins: specify the width explicitly with binwidth or provide the desired number of bins with bins. Consider the following modifications: # using binwidth p3 &lt;- ggplot(finches, aes(x = Depth)) + geom_histogram(color=&quot;blue&quot;,fill=&quot;lightblue&quot;,binwidth = 0.5, boundary = 6) + ggtitle(&quot;Changed binwidth value&quot;) # using bins p4 &lt;- ggplot(finches, aes(x = Depth)) + geom_histogram(color=&quot;blue&quot;,fill=&quot;lightblue&quot;,bins = 15, boundary = 6) + ggtitle(&quot;Changed bin value&quot;) # format plot layout grid.arrange(p3, p4, ncol = 2) Note: There is no gold standard on the number of bins, so try different numbers to generate best results. 8.1.3.3 Bin alignment Consider this comparison p5 &lt;- ggplot(finches, aes(x = Depth)) + geom_histogram(color=&quot;blue&quot;,fill=&quot;lightblue&quot;,binwidth = 0.5) + ggtitle(&quot;Without alignment&quot;) p6 &lt;- ggplot(finches, aes(x = Depth)) + geom_histogram(color=&quot;blue&quot;,fill=&quot;lightblue&quot;,bins = 15, boundary = 6) + ggtitle(&quot;With alignment&quot;) grid.arrange(p5, p6, ncol = 2) Notice that the boundary of bins does not start at an axis and the only difference in the code is the removal of boundry. To control the position of bins, we can use either parameter center or boundary. You can use boundary to specify the endpoint of any bin or center to specify the center of any bin and ggplot2 will be able to calculate where to place the rest of the bins. (Also, notice that when the boundary was changed, the number of bins got smaller by one. This is because by default the bins are centered and go over/under the range of the data.) In the above example, we specify boundary to be 6. We can see the first bin starts at 6 and the position of other bins are calculated based on the binwidth 0.5. 8.1.4 Interactive histograms with ggvis The ggvis package is not currently in development, but does certain things very well, such as adjusting parameters of a histogram interactively while coding. If you are interested, refer here. 8.2 Boxplots 8.2.1 Single boxplot A boxplot is one of the simplest ways of representing a distribution of a continuous variable (Never use boxplots for categorical data). It consists of two parts: box and whiskers. Let’s starting with a simple example: single boxplot. ggplot(chickwts, aes(x=weight)) + geom_boxplot() + ggtitle(&quot;Boxplot of chicken weights&quot;) Here as you can see, boxplots provide a ton of information for a single chart. Boxplots tell you whether the variable is normally distributed, or if the distribution is skewed in either direction. You can also easily spot the outliers, which always helps. 8.2.2 Multiple boxplots Next, what if you want to compare the distributions between multiple classes? Here, you can create a multiple boxplot. But remember, your data frame needs to be tidy, that is you need to have a column with levels of the grouping variable. It can be be factor, character, or integer class. The following example still use the chickwts dataset. We compare the distributions of weight between different feed(which is a column with six factor levels). ggplot(chickwts, aes(x=reorder(feed, -weight, median),y=weight)) + geom_boxplot() + ggtitle(&quot;Multiple boxplots of chicken weights according to feed type&quot;) + labs(y=&quot;Weight&quot;, x=&quot;Feed Type&quot;) Note. Usually in a boxplot, the boxes should be reordered so that there will be a decreasing order of the class medians from left to right. Often you want boxplots to be horizontal. Super easy to do in ggplot2: just tack on + coord_flip() and remove the - from the reordering so that the factor level with the highest median will be on top: ggplot(chickwts, aes(x=reorder(feed, weight, median),y=weight)) + geom_boxplot() + coord_flip() + ggtitle(&quot;Multiple boxplots of chicken weights according to feed type&quot;) + labs(y=&quot;Weight&quot;, x=&quot;Feed Type&quot;) 8.2.3 Additional resources Tukey, John W. 1977. Exploratory Data Analysis. Addison-Wesley. (Chapter 2): the primary source in which boxplots are first presented. Article on boxplots with ggplot2: An excellent collection of code examples on how to make boxplots with ggplot2. Covers layering, working with legends, faceting, formatting, and more. If you want a boxplot to look a certain way, this article will help. Boxplots with plotly package: boxplot examples using the plotly package. These allow for a little interactivity on hover, which might better explain the underlying statistics of your plot. ggplot2 Boxplot: Quick Start Guide: Article from STHDA on making boxplots using ggplot2. Excellent starting point for getting immediate results and custom formatting. Hadley Wickhan and Lisa Stryjewski on boxplots: good for understanding basics of more complex boxplots and some of the history behind them. 8.3 Ridgeline plot 8.3.1 Basics and implications Ridgeline plots can be used when a number of data segments have to be plotted on the same horizontal scale. It is presented with slight overlap. Ridgeline plots are very useful to visualize the distribution of a categorical variable over time or space. A good example using ridgeline plots will be a great example is visualizing the distribution of salary over different departments in a company. Consider the following example: library(ggridges) library(forcats) world &lt;- read.csv(&quot;countries2012.csv&quot;) ggplot(world, aes(x = GDP, y = reorder(CONTINENT, -GDP,median))) + geom_density_ridges(fill = &quot;blue&quot;) + ggtitle(&quot;2012 continental GDP&quot;) + ylab(&quot;Continent&quot;) ggridge uses two main geoms to plot the ridgeline density plots: geom_density_ridges and geom_ridgeline. They are used to plot the densities of categorical variable factors and see their distribution over a continuous scale. 8.3.2 Create better visuals ggplot(world, aes(x = GDP, y = reorder(CONTINENT, GDP,median))) + geom_density_ridges(fill = &quot;blue&quot;,alpha = .5, scale = 1.2) + ggtitle(&quot;2012 continental GDP&quot;) + ylab(&quot;Continent&quot;) In this example, we added parameter scale and alpha to control overlaps between ridges. Scale defines how much the peak of the lower curve touches the curve above and alpha controls transparency. Note that the curves are ordered from lowest median GDP on the bottom (Africa) to highest on the top (Europe). 8.3.3 Additional resources Introduction to ggridges: An excellent collection of code examples on how to make ridgeline plots with ggplot2. Covers every parameter of ggridges and how to modify them for better visualization. If you want a ridgeline plot to look a certain way, this article will help. Article on ridgeline plots with ggplot2: Few examples using different examples. Great for starting with ridgeline plots. History of Ridgeline plots: To refer to the theory of ridgeline plots. 8.4 Normal distribution When encountering data that seems to be normally distributed, you may want to overlay a normal curve. There are many ways to draw a normal curve and we introduce one here: ggplot(finches, aes(x = Depth)) + geom_histogram(aes(y=..density..),color=&quot;blue&quot;,fill=&quot;lightblue&quot;,binwidth = 0.5) + stat_function(fun=dnorm, col = &quot;red&quot;,args=list(mean(finches$Depth),sd(finches$Depth))) + ggtitle(&quot;Normal curve overlaid&quot;) In some situations you might want to draw separate normal curves after faceting on a categorical variable. Simply using stat_function will not generate the desired result. Consider the following examples, where normal curves were created for four plots using a single stat_function. As first glance, a normal curve appears in all of the plots. However, if you look closely, all the normal curves are actually the same one and generated on the whole dataset. In such situation, we suggest drawing each graph separately and combine them. "],["unidimensional-categorical-variables.html", "Chapter 9 Unidimensional categorical variables 9.1 Bar plot 9.2 Cleveland dot plot", " Chapter 9 Unidimensional categorical variables In real-world datasets, categorical features are quite common but tricky during both the data pre-processing and visualization process. In this chapter, we will demonstrate several plotting options for the uni-dimensional categorical variables with ggplot. 9.1 Bar plot There are two types of uni-dimensional categorical variables: nominal and ordinal. Here you will be shown how these variables should be plotted differently using bar plot under the same dataset. 9.1.1 Nominal data Nominal data is data with no fixed category order and should be sorted from highest to lowest count (left to right, or top to bottom) By default, R always sorts levels in alphabetical order. To reorder it by a sorted value, you can try fct_reorder , fct_rev, fct_relevel in the forcats package library(vcdExtra) library(ggplot2) library(forcats) library(dplyr) Accident %&gt;% group_by(mode) %&gt;% summarise(freq = sum(Freq)) %&gt;% ggplot(aes(x=fct_reorder(mode,freq,.desc = TRUE),y=freq)) + geom_bar(stat = &quot;identity&quot;,fill = &quot;cornflowerblue&quot;) + ggtitle(&quot;Number of people with different modes in accident&quot;) + xlab(&quot;&quot;) + theme(panel.grid.major.x = element_blank()) … or top to bottom Accident %&gt;% group_by(mode) %&gt;% summarise(freq = sum(Freq)) %&gt;% ggplot(aes(x=fct_rev(fct_reorder(mode,freq,.desc = TRUE)),y=freq)) + geom_bar(stat = &quot;identity&quot;,fill = &quot;cornflowerblue&quot;) + ggtitle(&quot;Number of people with different modes in accident&quot;) + coord_flip() + xlab(&quot;&quot;) + theme(panel.grid.major.x = element_blank()) 9.1.2 Ordinal data Ordinal data is data having a fixed category order and need to sort it in logical order of the categories (left to right) Accident %&gt;% group_by(age) %&gt;% summarise(freq = sum(Freq)) %&gt;% ggplot(aes(x=age,y=freq)) + geom_bar(stat = &quot;identity&quot;,fill = &quot;cornflowerblue&quot;) + ggtitle(&quot;Number of people of different ages in accident&quot;) + xlab(&quot;&quot;) + theme(panel.grid.major.x = element_blank()) Sort in logical order of the categories (starting at bottom OR top) Accident %&gt;% group_by(age) %&gt;% summarise(freq = sum(Freq)) %&gt;% ggplot(aes(x=age,y=freq)) + geom_bar(stat = &quot;identity&quot;,fill = &quot;cornflowerblue&quot;) + ggtitle(&quot;Number of people of different ages in accident&quot;) + xlab(&quot;&quot;) + coord_flip() + theme(panel.grid.major.x = element_blank()) 9.2 Cleveland dot plot Cleveland dot plot is a good alternative to bar plots, making plots more readable and comparable even with more data. Similarly, we also need to reorder the categorical variables just like what we’ve done for nominal bar plot. library(Lock5withR) ggplot(USStates, aes(x = IQ, y = fct_reorder(State, IQ))) + geom_point(color = &quot;blue&quot;) + ggtitle(&quot;Avg. IQ for US states&quot;) + ylab(&quot;&quot;) + theme_linedraw() 9.2.1 Cleveland dot plot with multiple dots Sort by Obese Rate library(tidyr) USStates %&gt;% select(&#39;State&#39;,&#39;Obese&#39;,&#39;HeavyDrinkers&#39;) %&gt;% gather(key=&#39;type&#39;,value=&#39;percentage&#39;,Obese,HeavyDrinkers) %&gt;% ggplot(aes(x=percentage, y=fct_reorder2(State,type==&#39;Obese&#39;,percentage,.desc=FALSE), color = type)) + geom_point() + ggtitle(&quot;Obese rate &amp; heavy drinker rate in US&quot;) + ylab(&quot;&quot;) + theme_linedraw() 9.2.2 Cleveland dot plot with facets You can split the graph into small multiples using facet_grid(). ggplot(USStates, aes(x = IQ, y = reorder(State, IQ))) + geom_point(color = &quot;blue&quot;) + facet_grid(Pres2008 ~ ., scales = &quot;free_y&quot;, space = &quot;free_y&quot;) + ggtitle(&#39;IQ of US state residents facet by Pres2008&#39;) + xlab(&quot;IQ&quot;) + ylab(&#39;&#39;) + theme_linedraw() + theme(panel.grid.major.x = element_blank(), panel.grid.minor.x = element_blank()) "],["two-continuous-variables.html", "Chapter 10 Two continuous variables 10.1 Scatterplot 10.2 Heatmaps", " Chapter 10 Two continuous variables In this chapter, we will look at techniques that explore the relationships between two continuous variables. 10.1 Scatterplot 10.1.1 Basics and implications For the following example, we use data set SpeedSki. library(GDAdata) library(ggplot2) ggplot(SpeedSki, aes(Year, Speed)) + geom_point() + labs(x = &quot;Birth year&quot;, y = &quot;Speed achieved (km/hr)&quot;) + ggtitle(&quot;Skiers by birth year and speed achieved&quot;) In our example, we simply use geom_point on variables Year and Speed to create the scatterplot. we try to capture if there is a relationship between the age of a player and the speed he/she can achieve. From the graph, it seems such relationship does not exist. Overall, scatterplots are very useful in understanding the correlation (or lack thereof) between variables. The scatterplot gives a good idea of whether that relationship is positive or negative and if there’s a correlation. However, don’t mistake correlation in a scatterplot for causation! 10.1.2 Overplotting In some situations a scatter plot faces the problem of overplotting as there are so many points overlapping. Consider the following example from class. To save time, we randomly sample 20% of the data in advance. library(dplyr) library(ggplot2movies) sample &lt;- slice_sample(movies,prop=0.2) ggplot(sample,aes(x=votes,y=rating)) + geom_point() + theme_classic() + ggtitle(&quot;Votes vs. rating&quot;) To create better visuals, we can use: Alpha blending - alpha=... Open circles - pch=21 smaller circles - size=... or shape=\".\" library(gridExtra) f1 &lt;- ggplot(sample,aes(x=votes,y=rating)) + geom_point(alpha=0.3) + theme_classic() + ggtitle(&quot;Alpha blending&quot;) f2 &lt;- ggplot(sample,aes(x=votes,y=rating)) + geom_point(pch = 21) + theme_classic() + ggtitle(&quot;Open circle&quot;) f3 &lt;- ggplot(sample,aes(x=votes,y=rating)) + geom_point(size=0.5) + theme_classic() + ggtitle(&quot;Smaller circle&quot;) grid.arrange(f1, f2, f3,nrow = 3) Other methods that directly deal with the data: Randomly sample data - as shown in the first code chunk using sample_n Subset - split data into bins using ntile(votes, 10) Remove outliers Transform to log scale 10.1.3 Interactive scatterplot You can create an interactive scatterplot using plotly. In the following example, we take 1% of the movie data set to present a better visual. We plotted the votes vs. rating and grouped by the year they are released. In this graph: You can hover on to the points to see the title of the movie You can double click on the year legend to look at a certain year You can zoom into a certain part of the graph to better understand the data points. library(plotly) sample2 &lt;- slice_sample(movies,prop=0.01) %&gt;% filter(year &gt; 2000) plot_ly(sample2, x = ~votes, y = ~rating, color = ~as.factor(year), text= ~title, hoverinfo = &#39;text&#39;) 10.1.4 Modifications 10.1.4.1 Contour lines Contour lines give a sense of the density of the data at a glance. For these contour maps, we will use the SpeedSki dataset. Contour lines can be added to the plot using geom_density_2d() and contour lines work best when combined with other layers ggplot(SpeedSki, aes(Year, Speed)) + geom_density_2d(bins=5) + geom_point() + ggtitle(&quot;Scatter plot with contour line&quot;) You can use bins to control the number of contour bins. 10.1.4.2 Scatterplot matrices If you want to compare multiple parameters to each other, consider using a scatterplot matrix. This will allow you to show many comparisons in a compact and efficient manner. For these scatterplot matrices, we use the movies dataset from the ggplot2movies package. As a default, the base R plot() function will create a scatterplot matrix when given multiple variables: sample3 &lt;- slice_sample(movies,prop=0.01) #sample data splomvar &lt;- sample3 %&gt;% dplyr::select(length, budget, votes, rating, year) plot(splomvar) While this is quite useful for personal exploration of a datset, it is not recommended for presentation purposes. Something called the Hermann grid illusion makes this plot very difficult to examine. 10.2 Heatmaps 10.2.1 Basics and implications In the following example, we still use the SpeedSki data set. ggplot(SpeedSki, aes(Year, Speed)) + geom_bin2d() To create a heatmap, simply substitute geom_point() with geom_bin2d(). Generally, heat maps are like a combination of scatterplots and histograms: they allow you to compare different parameters while also seeing their relative distributions. 10.2.2 Modifications For the following section, we introduce some variations on heatmaps. 10.2.2.1 Change number of bins / binwidth By default, geom_bin2d() use 30 bins. Similar to a histogram, we can change the number of bins or binwidth. ggplot(SpeedSki, aes(Year, Speed)) + geom_bin2d(binwidth = c(5,5)) + ggtitle(&quot;Changing binwidth&quot;) Notice we are specifying the binwidth for both x and y axis. 10.2.2.2 Combine with a scatterplot ggplot(SpeedSki, aes(Year, Speed)) + geom_bin2d(binwidth = c(10, 10), alpha = .4) + geom_point(size = 2) + ggtitle(&quot;Combined with scatterplot&quot;) 10.2.2.3 Change color scale You can change the continuous scale of color ggplot(SpeedSki, aes(Year, Speed)) + geom_bin2d() + ggtitle(&quot;Changing color scale&quot;) + scale_fill_viridis_c() 10.2.2.4 Hex heatmap One alternative is a hex heatmap. You can create the graph using geom_hex ggplot(SpeedSki, aes(Year, Speed)) + geom_hex(binswidth = c(10,10)) + ggtitle(&quot;Hex heatmap&quot;) 10.2.2.5 Alternative approach to color If you look at all the previous examples, you might notice that lighter points corresponds to more clustered points, which is somewhat counter-intuitive. The following exmaple suggest an alternative approach in color scale. ggplot(SpeedSki, aes(Year, Speed)) + geom_hex(bins=12) + scale_fill_gradient(low = &quot;grey&quot;, high = &quot;purple&quot;) + theme_classic(18) + ggtitle(&quot;Alternative approach to color&quot;) "],["multidimensional-continuous-variables.html", "Chapter 11 Multidimensional continuous variables 11.1 Parallel coordinate plot 11.2 Biplot", " Chapter 11 Multidimensional continuous variables In this chapter, we will look at techniques that explore the relationships between multiple continuous variables. 11.1 Parallel coordinate plot 11.1.1 Basics and implications For the following example, we use the famous iris data set. After installing GGally, we use ggparcoord to create the plot simply by specifying the columns we want. library(GGally) ggparcoord(iris, columns=1:4, title = &quot;Parallel coordinate plot for Iris flowers&quot;) Generally, parallel coordinate plots are used to infer relationships between multiple continuous variables - we mostly use them to detect a general trend that our data follows, and also the specific cases that are outliers. Please keep in mind that parallel coordinate plots are not the ideal graph to use when there are just categorical variables involved. We can include a few categorical variables for the sake of clustering, but using a lot of categorical variables results in overlapping profiles, which makes it difficult to interpret. 11.1.2 Modifications The default parallel coordinate plot might be messy and hard to interpret. The following techniques will help to create better visuals and convey clearer trends. 11.1.2.1 Grouping Generally, you use grouping when you want to observe a pattern by group of a categorical variable. To do this, we set groupColumn to the desired categorical variable. 11.1.2.2 Alpha In practice, parallel coordinate plots are not going to be used for very small datasets. Your data will likely have thousands and thousands of cases, and sometimes it can get very difficult to observe anything when there are many overlaps. We set the alphaLines between zero and one, and it reduces the opacity of all lines. 11.1.2.3 Scales Sometimes the value in your variables have very different range and it is necessary to rescale them to make comparisons. By default, ggparcoord standardize your data. The following are some other scaling options: std: default value, where it subtracts mean and divides by standard deviation. robust: subtract median and divide by median absolute deviation. uniminmax: scale all values so that the minimum is at 0 and maximum at 1. globalminmax: no scaling, original values taken. 11.1.2.4 Splines Generally, we use splines if we have a column where there are a lot of repeating values, which adds a lot of noise. The case lines become more and more curved when we set a higher spline factor, which removes noise and makes for easier observations of trends. It can be set using the splineFactor attribute. 11.1.2.5 Reordering You can reorder your columns in any way you want. Simply put the order in a vector. For example: columns = c(1,3,4,2,5) 11.1.2.6 Application Consider the following example, we apply grouping, alpha tuning, scaling and splines on the iris data set. Compare the two plot and the modified graph is noticeably easier to interpret. ggparcoord(iris, columns=1:4, groupColumn=5, alpha=0.5, scale=&#39;uniminmax&#39;,splineFactor=10, title = &quot;Modified parallel coordinate plot for Iris flowers&quot;) 11.1.3 Interactive parallel coordinate plot Package parcoords can help us in creating interactive parallel coordinate plots. The following example is created using New York State crime data. df_a %&gt;% select(-c(&quot;Year&quot;,&quot;Months Reported&quot;,&quot;Index Total&quot;,&quot;Violent Total&quot;,&quot;Property Total&quot;)) %&gt;% arrange(df_a) %&gt;% parcoords(rownames = FALSE, brushMode = &quot;1D-axes&quot;, color = list(colorBy = &quot;Region&quot;, colorScale = &quot;scaleOrdinal&quot;, colorScheme = &quot;schemeCategory10&quot;), alpha = 0.5, withD3 = TRUE, width = 770, height = 600) In the interactive graph, for each feature, you can create a square box to filter for observations. For example, you can look at a certain county, or you can filter for all counties that are in New York City (Region=NYC). Overall, the interactive plot is more flexible for analysis. 11.1.4 External resource Just like a static graph, there is a lot of things you can change in the interactive setting. Refer R documentation for more options. Unfortunately, the original develop blog of the library is unreachable currently. 11.2 Biplot In the following chapter, we will introduce biplot. We will talk briefly on how to create a biplot and how to interpret it. 11.2.1 Principal components analysis (PCA) We first introduce PCA as the existence of biplot is built up on it. Given a data set with multiple variables, the goal of PCA is to reduce dimensionality by finding a few linear combinations of the variables that capture most of the variance. Consider the following example using rating of countries. As a common technique, we first standardize each variable to have mean of 0 and variance of 1 scaled_ratings &lt;- ratings %&gt;% mutate(across(where(is.numeric), ~round((.x-mean(.x))/sd(.x), 2))) scaled_ratings ## # A tibble: 13 × 7 ## country living_standard climate food security hospitality infrastructure ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Italy 0.9 1.04 1.2 0.5 -0.34 0.83 ## 2 Spain 0.9 1.49 1.2 0.5 -0.74 1.23 ## 3 Croatia -0.12 0.14 -0.03 1 0.47 0.43 ## 4 Brazil -0.12 1.04 0.38 -0.5 -0.74 -0.77 ## 5 Russia 0.39 -1.67 -1.68 -0.5 1.27 0.43 ## 6 Germany 1.41 -1.22 -1.68 2 1.27 1.63 ## 7 Turkey -0.12 1.04 1.2 -0.5 -1.15 -0.77 ## 8 Morocco -0.63 0.59 0.79 -1 -1.15 -1.17 ## 9 Peru -0.12 0.14 -0.03 -0.5 0.06 -0.37 ## 10 Nigeria -1.64 -0.76 -0.85 -1 -0.34 -1.17 ## 11 France 1.41 -0.76 0.38 1.5 2.08 1.23 ## 12 Mexico -1.64 -0.31 -0.44 -1 -0.34 -0.77 ## 13 SouthAfrica -0.63 -0.76 -0.44 -0.5 -0.34 -0.77 To apply PCA, we use function prcomp(). summary() will then be used to show result. pca &lt;- prcomp(ratings[,2:7], scale. = TRUE) summary(pca) ## Importance of components: ## PC1 PC2 PC3 PC4 PC5 PC6 ## Standard deviation 1.854 1.4497 0.43959 0.39052 0.27517 0.19778 ## Proportion of Variance 0.573 0.3503 0.03221 0.02542 0.01262 0.00652 ## Cumulative Proportion 0.573 0.9232 0.95544 0.98086 0.99348 1.00000 As we can see that the first two principal components capture 92.3% of the total variance. mat_round &lt;- function(matrix, n = 3) apply(matrix, 2, function(x) round(x, n)) mat_round(pca$rotation) ## PC1 PC2 PC3 PC4 PC5 PC6 ## living_standard -0.429 0.364 0.112 -0.673 0.466 -0.028 ## climate 0.270 0.585 -0.210 0.036 -0.149 -0.719 ## food 0.221 0.596 0.610 0.212 -0.077 0.417 ## security -0.475 0.244 -0.282 0.676 0.419 0.049 ## hospitality -0.484 -0.216 0.636 0.170 -0.213 -0.490 ## infrastructure -0.484 0.252 -0.297 -0.121 -0.731 0.256 We are also able to see the specific linear combination of variables for each principal component. 11.2.2 Draw a biplot To draw a biplot, we suggest using draw_biplot from redav package. You can install the package using remotes::install_github(\"jtr13/redav\"). Note that the function will apply PCA and draw the plot. library(redav) draw_biplot(ratings,arrows=FALSE) The above biplot is set to be without arrows. We can rougly identify clusters from the graph. By running some clustering algorithm like k-means, you will be able to see it clearer. scores &lt;- pca$x[,1:2] k &lt;- kmeans(scores, centers = 6) scores &lt;- data.frame(scores) %&gt;% mutate(cluster = factor(k$cluster), country = ratings$country) g4 &lt;- ggplot(scores, aes(PC1, PC2, color = cluster, label = country)) + geom_point() + geom_text(nudge_y = .2) + guides(color=&quot;none&quot;) g4 Now for a standard bibplot: draw_biplot(ratings) To interpret the graph, you could imagine a perpendicular line from a certain point(country) to a feature arrow you are concerned. The further the intersection is on the arrow line, the higher the score. Take Spain for example, it has high score on all variables except hospitality as the imaginary line would land on the negative axis. You can also add calibrated axis, which will help you better compare a certain variable among countries. draw_biplot(ratings,&quot;living_standard&quot;) You see in this case, a projection line is added. We can clearly see that France has the highest living standard rating and Nigeria has the lowest rating. "],["multidimensional-categorical-variables.html", "Chapter 12 Multidimensional categorical variables 12.1 Barcharts 12.2 Chi square test of independence 12.3 Mosaic plots 12.4 Alluvial diagrams 12.5 Heat map", " Chapter 12 Multidimensional categorical variables In this chapter, we will focus on multivariate categorical data. Here, it is noteworthy that multivariate plot is not the same as multiple variable plot, where the former is used for analysis with multiple outcomes. 12.1 Barcharts Bar chats are used to display the frequency of multidimensional categorical variables. In the next few plots you will be shown different kinds of bar charts. 12.1.1 Stacked bar chart library(ggplot2) library(dplyr) library(tidyr) cases &lt;- read.csv(&quot;data/icecream.csv&quot;) icecreamcolors &lt;- c(&quot;#ff99ff&quot;, &quot;#cc9966&quot;) # pink, coffee ggplot(cases, aes(x = Age, fill = Favorite)) + geom_bar() + scale_fill_manual(values = icecreamcolors) 12.1.2 Grouped bar chart Use position = \"dodge\" to create grouped bar chart ggplot(cases, aes(x = Age, fill = Favorite)) + geom_bar(position = &quot;dodge&quot;) + scale_fill_manual(values = icecreamcolors) 12.1.3 Grouped bar chart with facets ggplot(cases, aes(x = Age)) + geom_bar(position = &quot;dodge&quot;) + facet_wrap(~Favorite) 12.1.4 Grouped barchart with three categorical variables counts3 &lt;- cases %&gt;% group_by(Age, Favorite, Music) %&gt;% summarize(Freq = n()) %&gt;% ungroup() %&gt;% complete(Age, Favorite, Music, fill = list(Freq = 0)) ggplot(counts3, aes(x = Favorite, y = Freq, fill = Music)) + geom_col(position = &quot;dodge&quot;) + facet_wrap(~Age) 12.2 Chi square test of independence In this section, we would like to show how to use chi-square test to check the independence between two features. We will use the following example to answer: Are older Americans more interested in local news than younger Americans? The dataset is collected from here. local &lt;- data.frame(Age = c(&quot;18-29&quot;, &quot;30-49&quot;, &quot;50-64&quot;, &quot;65+&quot;), Freq = c(2851, 9967, 11163, 10911)) %&gt;% mutate(Followers = round(Freq*c(.15, .28, .38, .42)), Nonfollowers = Freq - Followers) %&gt;% select(-Freq) knitr::kable(local[,1:2]) Age Followers 18-29 428 30-49 2791 50-64 4242 65+ 4583 The chi-square hypothesis is set to be: Null hypothesis: Age and tendency to follow local news are independent Alternative hypothesis: Age and tendence to follow local news are NOT independent localmat &lt;- as.matrix(local[,2:3]) rownames(localmat) &lt;- local$Age X &lt;- chisq.test(localmat, correct = FALSE) X$observed ## Followers Nonfollowers ## 18-29 428 2423 ## 30-49 2791 7176 ## 50-64 4242 6921 ## 65+ 4583 6328 X$expected ## Followers Nonfollowers ## 18-29 984.1065 1866.893 ## 30-49 3440.4032 6526.597 ## 50-64 3853.2378 7309.762 ## 65+ 3766.2526 7144.747 X ## ## Pearson&#39;s Chi-squared test ## ## data: localmat ## X-squared = 997.48, df = 3, p-value &lt; 2.2e-16 We compare observed to expected and then the p-value tells that age and tendency are independent features. We are good to move on to next stage on mosaic plots. 12.3 Mosaic plots Mosaic plots are used for visualizing data from two or more qualitative variables to show their proportions or associations. 12.3.1 Mosaic plot with one variable library(grid) icecream &lt;- read.csv(&quot;data/MusicIcecream.csv&quot;) icecreamcolors &lt;- c(&quot;#ff99ff&quot;, &quot;#cc9966&quot;) counts2 &lt;- icecream %&gt;% group_by(Age, Favorite) %&gt;% summarize(Freq = sum(Freq)) vcd::mosaic(~Age, direction = &quot;v&quot;, counts2) 12.3.2 Mosaic plot with two variables vcd::mosaic(Favorite ~ Age, counts2, direction = c(&quot;v&quot;, &quot;h&quot;), highlighting_fill = icecreamcolors) 12.3.3 Mosaic plot with three variables(Best practice) Here’s some criteria of best practice of mosaic plots : Dependent variables is split last and split horizontally Fill is set to dependent variable Other variables are split vertically Most important level of dependent variable is closest to the x-axis and darkest (or most noticable shade) vcd::mosaic(Favorite ~ Age + Music, counts3, direction = c(&quot;v&quot;, &quot;v&quot;, &quot;h&quot;), highlighting_fill = icecreamcolors) 12.3.4 Mosaic pairs plot Use pairs method to plot a matrix of pairwise mosaic plots for class table: pairs(table(cases[,2:4]), highlighting = 2) 12.3.5 Mosaic plots: spine plot Spine plot is a mosaic plot with straight, parallel cuts in one dimension (“spines”) and only one variable cutting in the other direction. library(vcdExtra) library(forcats) foodorder &lt;- Alligator %&gt;% group_by(food) %&gt;% summarize(Freq = sum(count)) %&gt;% arrange(Freq) %&gt;% pull(food) ally &lt;- Alligator %&gt;% rename(Freq = count) %&gt;% mutate(size = fct_relevel(size, &quot;small&quot;), food = factor(food, levels = foodorder), food = fct_relevel(food, &quot;other&quot;)) vcd::mosaic(food ~ sex + size, ally, direction = c(&quot;v&quot;, &quot;v&quot;, &quot;h&quot;), highlighting_fill= RColorBrewer::brewer.pal(5, &quot;Accent&quot;)) 12.3.6 Mosaic plot: tree map Treemap is a filled rectangular plot representing hierarchical data (fill color does not necessarily represent frequency count) library(treemap) data(GNI2014) treemap::treemap(GNI2014, index=c(&quot;continent&quot;, &quot;iso3&quot;), vSize=&quot;population&quot;, vColor=&quot;GNI&quot;, type=&quot;value&quot;, format.legend = list(scientific = FALSE, big.mark = &quot; &quot;)) 12.4 Alluvial diagrams Alluvial diagrams are usually used to represent the flow changes in network structure over time or between different levels. The following plot shows the essential components of alluvial plots used in the naming schemes and documentation (axis, alluvium, stratum, lode): 12.4.1 ggalluvial library(ggalluvial) df2 &lt;- data.frame(Class1 = c(&quot;Stats&quot;, &quot;Math&quot;, &quot;Stats&quot;, &quot;Math&quot;, &quot;Stats&quot;, &quot;Math&quot;, &quot;Stats&quot;, &quot;Math&quot;), Class2 = c(&quot;French&quot;, &quot;French&quot;, &quot;Art&quot;, &quot;Art&quot;, &quot;French&quot;, &quot;French&quot;, &quot;Art&quot;, &quot;Art&quot;), Class3 = c(&quot;Gym&quot;, &quot;Gym&quot;, &quot;Gym&quot;, &quot;Gym&quot;, &quot;Lunch&quot;, &quot;Lunch&quot;, &quot;Lunch&quot;, &quot;Lunch&quot;), Freq = c(20, 3, 40, 5, 10, 2, 5, 15)) ggplot(df2, aes(axis1 = Class1, axis2 = Class2, axis3 = Class3, y = Freq)) + geom_alluvium(color=&#39;black&#39;) + geom_stratum() + geom_text(stat = &quot;stratum&quot;, aes(label = paste(after_stat(stratum), &quot;\\n&quot;, after_stat(count)))) + scale_x_discrete(limits = c(&quot;Class1&quot;, &quot;Class2&quot;, &quot;Class3&quot;)) You can choose to color the alluvium by different variables, for example, the first variable Class1 here: ggplot(df2, aes(axis1 = Class1, axis2 = Class2, axis3 = Class3, y = Freq)) + geom_alluvium(aes(fill = Class1), width = 1/12) + geom_stratum() + geom_text(stat = &quot;stratum&quot;, aes(label = paste(after_stat(stratum), &quot;\\n&quot;, after_stat(count)))) + scale_x_discrete(limits = c(&quot;Class1&quot;, &quot;Class2&quot;, &quot;Class3&quot;)) 12.4.2 geom_flow Another way of plotting alluvial diagrams is using geom_flow rather than geom_alluvium: ggplot(df2, aes(axis1 = Class1, axis2 = Class2, axis3 = Class3, y = Freq)) + geom_flow(aes(fill = Class1), width = 1/12) + geom_stratum() + geom_text(stat = &quot;stratum&quot;, aes(label = paste(after_stat(stratum), &quot;\\n&quot;, after_stat(count)))) + scale_x_discrete(limits = c(&quot;Class1&quot;, &quot;Class2&quot;, &quot;Class3&quot;)) After we use geom_flow, all Math students learning Art came together, which is also the same as Stats students. It makes the graph much clearer than geom_alluvium since there is less cross alluviums between each axises. 12.5 Heat map Besides what have been systematically introduced in Chapter 9.2 Heatmaps, this part demonstrated a special case of heat map when both x and y are categorical. Here the heat map can been seen as a clustered bar chart and a pre-defined theme is used to show the dense more clearly. library(vcdExtra) library(dplyr) theme_heat &lt;- theme_classic() + theme(axis.line = element_blank(), axis.ticks = element_blank()) orderedclasses &lt;- c(&quot;Farm&quot;, &quot;LoM&quot;, &quot;UpM&quot;, &quot;LoNM&quot;, &quot;UpNM&quot;) mydata &lt;- Yamaguchi87 mydata$Son &lt;- factor(mydata$Son, levels = orderedclasses) mydata$Father &lt;- factor(mydata$Father, levels = orderedclasses) mydata3 &lt;- mydata %&gt;% group_by(Country, Father) %&gt;% mutate(Total = sum(Freq)) %&gt;% ungroup() ggplot(mydata3, aes(x = Father, y = Son)) + geom_tile(aes(fill = (Freq/Total)), color = &quot;white&quot;) + coord_fixed() + scale_fill_gradient2(low = &quot;black&quot;, mid = &quot;white&quot;, high = &quot;red&quot;, midpoint = .2) + facet_wrap(~Country) + theme_heat "],["colors.html", "Chapter 13 Colors 13.1 RColorBrewer 13.2 Perceptually uniform color spaces: Viridis", " Chapter 13 Colors When evaluating the power and efficiency of a plot, color is always a key factor that sometimes speaks a language even louder than words. So in this chapter, you will be introduced with several widely-applied color schemes and get to know how to use proper colors to make better plots based on different features of your data. 13.1 RColorBrewer RColorBrewer is an R package having built-in sensible color schemes ready-to-use for figures. Colors are grouped into three types: sequential, diverging, and qualitative. Sequential – Light colours for low data, dark for high data Qualitative(for categorical data) – Colours designed to give maximum visual difference between categories so great for non-ordered categorical data Diverging – Light colours for mid-range data, low and high use dark colours, great to seperate two extremes library(RColorBrewer) display.brewer.all() Here is an example of plotting categorical data using Dark2 pallets under qualitative group of RColorBrewer: library(ggplot2) ggplot(iris, aes(Petal.Length, Sepal.Length, colour = Species)) + geom_point() + scale_colour_brewer(palette = &quot;Dark2&quot;) Also, you can create your own sequential pallets. ggplot(faithfuld, aes(waiting, eruptions, fill = density)) + geom_raster() + scale_fill_gradient(low = &quot;white&quot;, high = &quot;red&quot;) Or diverging pallets: ggplot(faithfuld, aes(waiting, eruptions, fill = density)) + geom_raster() + scale_fill_gradient2(low = &quot;grey&quot;, mid = &quot;white&quot;, high = &quot;red&quot;,midpoint = .02) For discrete data, using scale_colour_manual is a good choice. For discrete ordinal data, we can use another package (such as vcd) ggplot(mtcars, aes(mpg, wt)) + geom_point(aes(colour = factor(cyl))) + scale_colour_manual(values = c(&quot;red&quot;, &quot;yellow&quot;, &quot;blue&quot;)) colors&lt;-brewer.pal(5,&#39;Blues&#39;) barplot(1:5, col=colors) 13.2 Perceptually uniform color spaces: Viridis The viridis R package provides four palettes for use in R which are pretty, perceptually uniform and easy to read by those with colorblindness. The package contains eight color scales: viridis, the primary choice, and five alternatives with similar properties - magma, plasma, inferno, civids, mako, and rocket -, and a rainbow color map - turbo. Perceived differences are proportional to scalar differences when using viridis. The following example shows viridison continuous data using scale_color_viridis_c, use scale_color_viridis_d() for discrete data library(&quot;viridis&quot;) ggplot(iris, aes(Sepal.Length, Sepal.Width))+ geom_point(aes(color = Sepal.Length)) + scale_color_viridis_c() "],["time-series.html", "Chapter 14 Time series 14.1 Dates 14.2 Multiple time series", " Chapter 14 Time series Time series, by definition, is a sequence of data point collected over a certain period of time. In this chapter, we will demonstrate several useful ways of plotting time-series data and how to processing date data type in R. 14.1 Dates Since time series analysis looks into how data is changing over time, the very first step is to transform the data into correct format. 14.1.1 Basic R functions You can convert character data to Date class with as.Date(): dchar &lt;- &quot;2018-10-12&quot; ddate &lt;- as.Date(dchar) class(dchar) ## [1] &quot;character&quot; class(ddate) ## [1] &quot;Date&quot; You can also specifying the format by: as.Date(&quot;Thursday, January 6, 2005&quot;, format = &quot;%A, %B %d, %Y&quot;) ## [1] &quot;2005-01-06&quot; Here is a list of the conversion specifications for date format from this post 14.2 Multiple time series For time-series dataset, line plots are mostly used with time on the x-axis. library(dplyr) library(readxl) library(tidyr) library(ggplot2) df &lt;- read_excel(&quot;data/historicalweeklydata.xls&quot;, col_types = c(&quot;date&quot;, &quot;numeric&quot;, &quot;numeric&quot;, &quot;numeric&quot;)) df &lt;- df %&gt;% pivot_longer(cols = -c(&quot;Week&quot;), names_to = &quot;TYPE&quot;) %&gt;% mutate(TYPE = forcats::fct_reorder2(TYPE, Week, value))# puts legend in correct order ggplot(df, aes(Week, value, color = TYPE)) + geom_line() + ggtitle(&quot;U.S. Mortgage Rates&quot;) + labs (x = &quot;&quot;, y = &quot;percent&quot;) + theme_grey(16) + theme(legend.title = element_blank()) library(lubridate) df2010 &lt;- df %&gt;% filter(year(Week) == 2010) ggplot(df2010, aes(Week, value, color = TYPE)) + geom_line() + ggtitle(&quot;U.S. Mortgage Rates&quot;) "],["spatial-data.html", "Chapter 15 Spatial data 15.1 Introduction 15.2 Packages", " Chapter 15 Spatial data The page is currently being updated, check back later. 15.1 Introduction In this chapter, we will take a glimpse into spatial analysis using R. There are an overwhelming number of R packages for analyzing and visualizing spatial data. In broad terms, spatial visualizations require a merging of non-spatial and spatial information. For example, if you wish to create a choropleth map of the murder rate by county in New York State, you need county level data on murder rates, and you also need geographic data for drawing the county boundaries, stored in what are called shape files. A rough divide exists between packages that don’t require you deal with shape files and those that do. The former work by taking care of the geographic data under the hood: you supply the data with a column for the location and the package takes care of figuring out how to draw those locations. 15.2 Packages 15.2.1 choroplethr Choropleth maps use color to indicate the value of a variable within a defined region, generally political boundaries. choroplethr is capable of drawing state and county level maps without using shape files. Consider the following example using state.x77 showing the percentage of illiterate in each states. Note the process of data transformation, you need to exactly have a column named ‘region’ with the state names and a column named ‘value’. library(dplyr) library(tibble) library(ggplot2) library(choroplethr) # data frame must contain &quot;region&quot; and &quot;value&quot; columns df_illiteracy &lt;- state.x77 %&gt;% as.data.frame() %&gt;% rownames_to_column(&quot;state&quot;) %&gt;% transmute(region = tolower(`state`), value = Illiteracy) state_choropleth(df_illiteracy, title = &quot;State Illiteracy Rates, 1977&quot;, legend = &quot;Percent Illiterate&quot;) Plotting at county level is also possible. In the following example we show the population of counties in New York state in 2012. library(choroplethrMaps) data(county.regions) data(df_pop_county) ny_county_fips = county.regions %&gt;% filter(state.name == &quot;new york&quot;) %&gt;% select(region) county_choropleth(df_pop_county, title = &quot;Population of Counties in New York State in 2012&quot;, legend = &quot;Population&quot;, county_zoom = ny_county_fips$region) We use county_choropleth to create a U.S map at county level and zoom into New York state. Note that county_zoom takes in fips codes of counties. For more reference, visit the R documentation page. 15.2.2 ggmap ggmap is a great package to generate real-world maps. Moreover, it is compatible with ggplot2 allowing you to easily add layers on top of the base map. There are two options in generating maps and we demonstrate one using stamenmap. library(ggmap) ny_map &lt;- get_stamenmap(bbox = c(left = -74.2591, bottom = 40.4774, right = -73.7002, top = 40.9162), zoom = 10, maptype = &quot;toner-lite&quot;) ggmap(ny_map) + geom_point(aes(x=-73.9857,y=40.7484),size=0.8,color=&#39;blue&#39;) + annotate(geom=&quot;text&quot;,label=&quot;Empire State Building&quot;,x=-73.9, y=40.755,color=&#39;blue&#39;,size=3) A map of New York City is created, and we added the point representing Empire State Building. You can very simply add points using geom_point as long as you have the coordinates for the points. However, one clear drawback using stamenmap is that the map resolution is not satisfying and you will eventually find that the smaller zoom value creates blurry maps. For this reason, we encourage readers to try the option using Google maps. You will need to set up a Google Cloud account (requires credit card). After enabling the Google map APIs, register you API keys with ggmap using register_google(key = \"[your key]\") and you are all set. Now take a look at the an example using Google map API ggmap(get_googlemap(center = c(lon = -74.006, lat = 40.7128),zoom = 14)) You will see the map is at great resolution regardless of how you zoom in. For demonstration purpose, we provided a image of the map derived by running the code. For more details regarding the package usage, you can refer at ggmap GitHub page. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
