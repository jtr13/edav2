[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "edav.info v2",
    "section": "",
    "text": "1 Welcome!\nThis is edav.info version 2.0!\nThe first version of edav.info is still available, but will no longer be updated.\nWith this resource, we try to give you a curated collection of tools and references that will make it easier to learn how to work with data and create visualizations in R.\nThis resource is specifically tailored to the graduate courses I teach at Columbia University. However, we hope that anyone interested in working with data in R will benefit from these pages. Happy coding!\n(Note. edav.info 2.0 is still under construction, and we will try our best to update new chapters weekly so that it will be up-to-date with the information you need to complete the current problem set. Please be in touch if a resource that would be helpful doesn’t exist.)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Welcome!</span>"
    ]
  },
  {
    "objectID": "learning_R.html",
    "href": "learning_R.html",
    "title": "2  Getting started",
    "section": "",
    "text": "2.1 Top 10 essentials checklist\nWelcome to the world of EDAV! As you have already known, we will mainly use R through out the course. In an effort to get everyone on the same page, here is a checklist of essentials so you can get up and running. The best resources are scattered in different places online, so bear with links to various sites depending on the topic.\n(r4ds = R for Data Science by Garrett Grolemund and Hadley Wickham, free online)",
    "crumbs": [
      "R resources",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Getting started</span>"
    ]
  },
  {
    "objectID": "learning_R.html#top-10-essentials-checklist",
    "href": "learning_R.html#top-10-essentials-checklist",
    "title": "2  Getting started",
    "section": "",
    "text": "Install R (r4ds) – You need to have this installed but you won’t open the application since you’ll be working in RStudio. If you installed R once upon a time, make sure you’re current! The latest version of R (as of 2025-05-03) is R 4.5.0 “How About a Twenty-Six” released on 2025/04/11. Use &gt; R.version to check what you have.\nInstall RStudio (r4ds) – Download the free, Desktop version for your OS. Working in this IDE will make working in R much more enjoyable. As with R, stay current. The latest version (as of 2025-05-03) is RStudio-2024.12.1-563. Click the RStudio menu, then “About RStudio” to see what version you have. (Note: RStudio, the company, is now Posit. RStudio, the product, is still RStudio.)\nGet comfortable with RStudio – In this chapter of Bruno Rodriguez’s Modern R with the Tidyverse, you’ll learn about panes, options, getting help, keyboard shortcuts, projects, add-ins, and packages. Try to:\n\nDo some math in the console\nCreate an Quarto file (.qmd) and render it to .html\nInstall some packages like tidyverse or MASS\n\nAnother great option for learning the IDE: Watch Writing Code in RStudio (RStudio webinar)\nLearn “R Nuts and Bolts” – Roger Peng’s chapter in R Programming will give you a solid foundation in the basic building blocks of R. It’s worth making the investing in understanding how R objects work now so they don’t cause you problems later. Focus on vectors and especially data frames; matrices and lists don’t come up often in data visualization. Get familiar with R classes: integer, numeric, character, and logical. Understand how factors work; they are very important for graphing.\nTidy up (r4ds) – Install the tidyverse, and get familiar with what it is. We will discuss differences between base R and the tidyverse in class.\nLearn ggplot2 basics (r4ds) – In class we will study the grammar of graphics on which ggplot2 is based, but it will help to familiarize yourself with the syntax in advance. Avail yourself of the “Data Visualization with ggplot2” cheatsheet by clicking “Help” “Cheatsheets…” within RStudio.\nLearn some Quarto, a new tool from Posit (formerly RStudio) that they describe as “a multi-language, next generation version of R Markdown.” The syntax of Quarto is very similar to that of RMarkdown, but is a separate application, not an R package. Current versions of RStudio ship with Quarto, so you don’t need to install it. An in-depth (read: long) “Welcome to Quarto Workshop!” is available on YouTube.\nUse RStudio projects (r4ds) – If you haven’t already, drink the Kool-Aid. Make each problem set a separate project. You will never have to worry about getwd() or setwd() again because everything will just be in the right places. Or watch the webinar: “Projects in RStudio”. If you run into a situation in which you must change the filepaths used to read files depending on whether you are running the code in the Console or knitting the document, it is likely due to having .Rmd files stored in subfolders of the project. The here package will eliminate the need for you to repeatedly make these changes by creating relative paths from the project root, that just work. This is a small but powerful tool; once you start using it there’s no going back.\nLearn the basic dplyr verbs for data manipulation (r4ds) – Concentrate on the main verbs: filter() (rows), select() (columns), mutate(), arrange() (rows), group_by(), and summarize(). Learn the native R pipe |&gt; operator. It is very similar to the magrittr pipe |&gt; which you can see in action in the post “How dplyr replaced my most common R idioms”, which provides a detailed comparison of base R vs. dplyr data transformation.\nKnow how to tidy your data – The pivot_longer() function from the tidyr package – successor to gather() – will help you get your data in the right form for plotting. More on this in class. Check out these super cool animations, which follow a data frame as it is transformed by tidyr functions.",
    "crumbs": [
      "R resources",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Getting started</span>"
    ]
  },
  {
    "objectID": "learning_R.html#troubleshooting",
    "href": "learning_R.html#troubleshooting",
    "title": "2  Getting started",
    "section": "2.2 Troubleshooting",
    "text": "2.2 Troubleshooting\n\n2.2.1 Functions stop working\nStrange behavior from functions that previously worked are often caused by function conflicts. This can happen if you have two packages loaded with the same function names. To indicate the proper package, namespace it. Conflicts commonly occur with select and filter and map. If you intend the tidyverse ones use:\ndplyr::select, dplyr::filter and purrr::map.\nSome other culprits:\ndplyr::summarise() and vcdExtra::summarise()\nggmosaic::mosaic() and vcd::mosaic()\nleaflet::addLegend() and xts::addLegend()\ndplyr::select and MASS::select",
    "crumbs": [
      "R resources",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Getting started</span>"
    ]
  },
  {
    "objectID": "learning_R.html#tips-tricks",
    "href": "learning_R.html#tips-tricks",
    "title": "2  Getting started",
    "section": "2.3 Tips & tricks",
    "text": "2.3 Tips & tricks\n\n2.3.1 Sizing figures\nAlways use chunk options to size figures. You can set a default size in the YAML at the beginning of the .qmd file as so:\n---\nformat:\n  html:\n    fig-width: 6\n    fig-height: 4\n    out-width: 60%\n    embed-resources: true\n---\nThen as needed override one or more defaults in particular chunks:\n```{r}\n#| fig-width: 4\n#| fig-height: 2\n```\n\n\n2.3.2 RStudio keyborad shortcuts\nInsert R chunk - option-command-i (Mac) - ctrl+alt+I (Windows)\n\n\n```{r}\n```\n\n\nInsert |&gt; (“the pipe”):\n\nshift-command(ctrl)-M Mac/Windows\n\nComment/Uncomment lines\n\nshift-command(ctrl)-C Mac/Windows\n\nFor more shortcuts, refer here\n\n\n2.3.3 Viewing plots in plot window\nWould you like your plots to appear in the plot window instead of below each chunk in the .qmd file? Click ⚙️ and then  Chunk Output in Console.\n\n\n2.3.4 Adding figures and links\nAdd images\n![DESCRIPTION HERE](PATH HERE)\n\nAdd links: The text in the content column will act as a hyperlink\n[CONTENT HERE](LINK HERE)   \nNote: Do not use these in r chunks as they will not work.",
    "crumbs": [
      "R resources",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Getting started</span>"
    ]
  },
  {
    "objectID": "factors.html",
    "href": "factors.html",
    "title": "3  Working with factors",
    "section": "",
    "text": "3.1 Recode factor levels\nAs what we have mentioned in the previous chapter, R sorts levels of factors in alphabetical order by default. In this chapter we will talk about working with factors using forcats package, which can be helpful when you managing categorical variables.\nDon’t directly assign levels with levels()&lt;-. Instead, using fct_recode().\nlibrary(forcats)\nx &lt;- factor(c(\"G234\", \"G452\", \"G136\"))  \ny &lt;- fct_recode(x, Physics = \"G234\", Math = \"G452\", Chemistry = \"G136\")  \ny\n\n[1] Physics   Math      Chemistry\nLevels: Chemistry Physics Math",
    "crumbs": [
      "R resources",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Working with factors</span>"
    ]
  },
  {
    "objectID": "factors.html#relevel-the-factor",
    "href": "factors.html#relevel-the-factor",
    "title": "3  Working with factors",
    "section": "3.2 Relevel the factor",
    "text": "3.2 Relevel the factor\nFor the binned, ordinal data with levels out of order, fct_relevel() can be used to set a correct order.\n\nlibrary(tibble)\nlibrary(ggplot2)\nBirths2015 &lt;- tibble(MotherAge = c(\"15-19 years\", \"20-24 years\", \"25-29 years\", \"30-34 years\", \"35-39 years\",  \"40-44 years\", \"45-49 years\", \"50 years and over\", \"Under 15 years\"), Num = c(229.715, 850.509, 1152.311, 1094.693, 527.996, 111.848, 8.171, .754, 2.5)) \n \nggplot(Births2015, aes(fct_relevel(MotherAge, \"Under 15 years\"), Num)) +\n  geom_col() +\n  coord_flip() +\n  scale_y_continuous(breaks = seq(0, 1250, 250)) +\n  ggtitle(\"United States Births, 2015\", subtitle = \"in thousands\") +\n  theme_grey(16) +\n  labs(y = \"mother age\", x = \"count\")\n\n\n\n\n\n\n\n\nThe following examples give three circumstances when using fct_relevel().\n\nUsing fct_relevel() to move levels to the beginning:\n\n\nx &lt;- c(\"A\", \"B\", \"C\", \"move1\", \"D\", \"E\", \"move2\", \"F\")  \nfct_relevel(x, \"move1\", \"move2\")\n\n[1] A     B     C     move1 D     E     move2 F    \nLevels: move1 move2 A B C D E F\n\n\n\nUsing fct_relevel() to move levels after an item (by position):\n\n\nx &lt;- c(\"A\", \"B\", \"C\", \"move1\", \"D\", \"E\", \"move2\", \"F\")  \nfct_relevel(x, \"move1\", \"move2\", after = 4) # move after the fourth item\n\n[1] A     B     C     move1 D     E     move2 F    \nLevels: A B C D move1 move2 E F\n\n\n\nUsing fct_relevel() to move levels to the end\n\n\nx &lt;- c(\"A\", \"B\", \"C\", \"move1\", \"D\", \"E\", \"move2\", \"F\")  \nfct_relevel(x, \"move1\", \"move2\", after = Inf)\n\n[1] A     B     C     move1 D     E     move2 F    \nLevels: A B C D E F move1 move2\n\n\nIf the row order is correct, use fct_inorder():\n\ndf &lt;- data.frame(temperature = factor(c(\"cold\", \"warm\", \"hot\")),  \n                 count = c(15, 5, 22)) \n \n# row order is correct (think: factor in ROW order) \nggplot(df, aes(x = fct_inorder(temperature), y = count)) +  \n  geom_col() +\n  theme_grey(16) +\n  labs( x = \"temperature\")",
    "crumbs": [
      "R resources",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Working with factors</span>"
    ]
  },
  {
    "objectID": "factors.html#reorder-the-factors",
    "href": "factors.html#reorder-the-factors",
    "title": "3  Working with factors",
    "section": "3.3 Reorder the factors",
    "text": "3.3 Reorder the factors\nUsually, unbinned, nominal data should be sorted by frequency order, which can be achieved using fct_infreq() (default is decreasing order of frequency)\n\ndf &lt;- data.frame(  \n  color = c(\"orange\",\"blue\", \"red\",\"brown\",\"yellow\", \"green\", \"orange\", \"red\", \"yellow\",\"blue\",\"blue\",\"red\",\"orange\",\"blue\",\"red\",\"orange\",\"orange\")\n)  \n \nggplot(df, aes(fct_infreq(color))) +   \n  geom_bar() +  \n  theme_grey(16)\n\n\n\n\n\n\n\n\nFor binned, nominal data which should be sorted by frequency order, use fct_reorder(). In the following example count is used, generally you can also apply mean,median, etc. to .fun inside `fct_reorder()``.\n\npack1 &lt;- data.frame(  \n  color = c(\"blue\", \"brown\", \"green\", \"orange\", \"red\", \"yellow\"),  \n  count = c(13, 7, 12, 9, 7, 8)  \n)  \n \nggplot(pack1, aes(fct_reorder(color, count, .desc = TRUE), count)) +   \n  geom_col() +  \n  theme_grey(16) +\n  labs(x = \"color\")",
    "crumbs": [
      "R resources",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Working with factors</span>"
    ]
  },
  {
    "objectID": "factors.html#dealing-with-nas",
    "href": "factors.html#dealing-with-nas",
    "title": "3  Working with factors",
    "section": "3.4 Dealing with NAs",
    "text": "3.4 Dealing with NAs\nFor prominent NA bars which should not be eliminated, use fct_explicit_na(x). And using fct_rev(x) to reverse the factor level doesn’t help.\n\nlibrary(dplyr)\ndf &lt;- data.frame(temperature = factor(c(\"cold\", \"warm\", \"hot\", NA)), count = c(15, 5, 22, 12))\n \ndf |&gt;   \n  mutate(temperature = fct_explicit_na(temperature, \"NA\") |&gt; \n  fct_relevel(\"NA\", \"hot\", \"warm\", \"cold\")) |&gt;\n  ggplot(aes(x = temperature, y = count)) +\n  geom_col() +\n  coord_flip() +\n  theme_grey(16) +\n  labs(x = \"temperature\")",
    "crumbs": [
      "R resources",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Working with factors</span>"
    ]
  },
  {
    "objectID": "factors.html#summary-of-useful-functions",
    "href": "factors.html#summary-of-useful-functions",
    "title": "3  Working with factors",
    "section": "3.5 Summary of useful functions",
    "text": "3.5 Summary of useful functions\nFor analyzing categorical variables, the first step is always to decide whether the class is ordinal or nominal.\n\nfct_recode(x, …) – change names of levels\nfct_inorder(x) – set level order of x to row order\nfct_relevel(x, …) – manually set the order of levels of x\nfct_reorder(x, y) – reorder x by y\nfct_infreq(x) – order the levels of x by decreasing frequency\nfct_rev(x) – reverse the order of factor levels of x\nfct_explicit_na(x) – turn NAs into a real factor level",
    "crumbs": [
      "R resources",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Working with factors</span>"
    ]
  },
  {
    "objectID": "factors.html#continuous-to-categorical",
    "href": "factors.html#continuous-to-categorical",
    "title": "3  Working with factors",
    "section": "3.6 Continuous to Categorical",
    "text": "3.6 Continuous to Categorical\nSometimes you want to transfer a continuous variable to a categorical variable. For example, you might want assign grades to final scores of a course. In the following example, we generated a data set of test scores randomly and we assign grades based on some thresholds. We then apply function cut. (You can similarly use case_when)\n\nset.seed(2022)\ntestscore &lt;- round(runif(100, min = 70, max = 100))\n\ndf &lt;- data.frame(testscore) |&gt; \n  mutate(grade = cut(testscore, breaks = seq(70, 100, 10), \n                     labels = c(\"C\", \"B\", \"A\"), right = FALSE,\n                     include.lowest = TRUE))\n\nhead(df)\n\n  testscore grade\n1        94     A\n2        89     B\n3        74     C\n4        86     B\n5        76     C\n6        89     B",
    "crumbs": [
      "R resources",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Working with factors</span>"
    ]
  },
  {
    "objectID": "data_import.html",
    "href": "data_import.html",
    "title": "4  Data importation",
    "section": "",
    "text": "4.1 Packages with built in data set\nData is the core to any analysis. In this chapter, we will talk about various ways to import data into R.\nMany of the packages in R have built in data sets. To gain access of the data, call the package and you can access them by the name of the data sets. For example, we can access the ExerciseHours data set from Lock5withR\nlibrary(Lock5withR)\nhead(ExerciseHours)\n\n  Year Gender Hand Exercise TV Pulse Pierces\n1    4      M    l       15  5    57       0\n2    2      M    l       20 14    70       0\n3    3      F    r        2  3    70       2\n4    1      F    l       10  5    66       3\n5    1      M    r        8  2    62       0\n6    1      M    r       14 14    62       0",
    "crumbs": [
      "R resources",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data importation</span>"
    ]
  },
  {
    "objectID": "data_import.html#data-from-web",
    "href": "data_import.html#data-from-web",
    "title": "4  Data importation",
    "section": "4.2 Data from web",
    "text": "4.2 Data from web\n\n4.2.1 Read in from URL\nSome of the data you found online might be files ended with ‘.csv’ or ‘.xls’. In this case, you can directly read them using the URL. For example,\n\nX &lt;- read.csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\",\n              header = FALSE) #Read in iris data\n\nhead(X)\n\n   V1  V2  V3  V4          V5\n1 5.1 3.5 1.4 0.2 Iris-setosa\n2 4.9 3.0 1.4 0.2 Iris-setosa\n3 4.7 3.2 1.3 0.2 Iris-setosa\n4 4.6 3.1 1.5 0.2 Iris-setosa\n5 5.0 3.6 1.4 0.2 Iris-setosa\n6 5.4 3.9 1.7 0.4 Iris-setosa\n\n\nNote that this is not a very stable way of reading data as the structure of the website might change, which will result in failure of reading the data.\n\n\n4.2.2 API / R API package\nSome data sources provide APIs to access their data, for example CDC, Census, and Twitter. However, there is a learning curve in utilizing their APIs. Best practices for API packages will help you to get a head start.\nThe other option is to find packages that handles the API calls for you. For example:\n\nCDC data - package wonderapi\nCensus data - package censusapi\nTwitter - package rtweet\n\nA well-built client will save you a lot of time in retrieving data and should be your first resort.",
    "crumbs": [
      "R resources",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data importation</span>"
    ]
  },
  {
    "objectID": "data_import.html#web-scraping",
    "href": "data_import.html#web-scraping",
    "title": "4  Data importation",
    "section": "4.3 Web scraping",
    "text": "4.3 Web scraping\nWeb scraping is mostly considered as the last resort in obtaining data. As we put it in the last section, meaning that you should always explore the possibilities above before turning to web scraping. When scarping, you should\n\nthink and investigate legal issues\nthink about ethical questions\nlimit bandwidth use\nscrape only what you need\n\nTo start, you will need to know some backgrounds about the structure of a html page. In a webpage, you can always right click -&gt; inspect to check on the structure. Also, as a sanity check, we recommend using package robotstxt to see if scarping is allowed on a certain webpage. You can simply feed in the URL into function paths_allowed(). We will use the CRAN page for package forcats for the scraping example.\n\nlibrary(robotstxt)\nlibrary(rvest)\npaths_allowed('https://cran.r-project.org/web/packages/forcats/index.html')\n\n[1] TRUE\n\n\n\n4.3.1 rvest\nPackage rvest is widely used for web scraping. In the following example, read_html() takes the target webpage URL and html_table() extracts all table element in the page.\n\nforcats_data &lt;- read_html(\"https://cran.r-project.org/web/packages/forcats/index.html\") \n\nforcats_table &lt;- forcats_data |&gt; html_table()\nforcats_table[[1]]\n\n# A tibble: 14 × 2\n   X1                X2                                                         \n   &lt;chr&gt;             &lt;chr&gt;                                                      \n 1 Version:          \"1.0.0\"                                                    \n 2 Depends:          \"R (≥ 3.4)\"                                                \n 3 Imports:          \"cli (≥ 3.4.0), glue, lifecycle, magrittr, rlang (≥ 1.0.0)…\n 4 Suggests:         \"covr, dplyr, ggplot2, knitr, readr, rmarkdown, testthat (…\n 5 Published:        \"2023-01-29\"                                               \n 6 DOI:              \"10.32614/CRAN.package.forcats\"                            \n 7 Author:           \"Hadley Wickham [aut, cre],\\n  RStudio [cph, fnd]\"         \n 8 Maintainer:       \"Hadley Wickham  &lt;hadley at rstudio.com&gt;\"                  \n 9 BugReports:       \"https://github.com/tidyverse/forcats/issues\"              \n10 License:          \"MIT + file LICENSE\"                                       \n11 URL:              \"https://forcats.tidyverse.org/,\\nhttps://github.com/tidyv…\n12 NeedsCompilation: \"no\"                                                       \n13 Materials:        \"README NEWS\"                                              \n14 CRAN checks:      \"forcats results\"                                          \n\n\nIf you want contents that are not in the table format, you can use html_nodes() specifying specific html structure. Namely,\n\nh2 tag - html_nodes(\"h2\")\nid attribute - html_nodes(\"#XXX\")\nclass attribute - html_nodes(\".XXX\")",
    "crumbs": [
      "R resources",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data importation</span>"
    ]
  },
  {
    "objectID": "data_transformation.html",
    "href": "data_transformation.html",
    "title": "5  Data transformation",
    "section": "",
    "text": "5.1 What is tidy data?\nPlotting a graph is easy. You just need to find the right library with the right function. However, it is sometimes not so easy to get your data into the form desired to generate a graph. In this chapter, we will cover some basic techniques in tidying data with ggplot2.\nHere’s the definition of Tidy Data given by Hadley Wickham:\nWhat are the advantages of tidy data?\nTake a look at the following data and can you tell whether this data is messy or not?\nmpg cyl disp  hp drat    wt  qsec vs am gear carb\nMazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\nValiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1\nTo transform the data, we use pivot_longer.",
    "crumbs": [
      "R resources",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data transformation</span>"
    ]
  },
  {
    "objectID": "data_transformation.html#what-is-tidy-data",
    "href": "data_transformation.html#what-is-tidy-data",
    "title": "5  Data transformation",
    "section": "",
    "text": "A dataset is messy or tidy depending on how rows, columns and tables are matched up with observations, variables and types. In tidy data:\n\nEach variable forms a column.\nEach observation forms a row.\nEach observational unit forms a value in the table.\n\nSee r4ds on tidy data for more info.\n\n\n\nUniformity : It is easier to learn the tools that work with the data because they have a consistent way of storing data.\nMost built-in R functions work with vectors of values. Thus, having variables as columns/vectors allows R’s vectorized nature to shine.\n\n\n\n\nIn this data set,all the variables are parameters of cars. This means that they are not different variables, but are values of a common variable.",
    "crumbs": [
      "R resources",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data transformation</span>"
    ]
  },
  {
    "objectID": "data_transformation.html#pivot_longer",
    "href": "data_transformation.html#pivot_longer",
    "title": "5  Data transformation",
    "section": "5.2 pivot_longer",
    "text": "5.2 pivot_longer\n\nmtcars |&gt;  \n  rownames_to_column(\"carname\") |&gt;\n  pivot_longer(cols = !carname, names_to = \"Parameters\",values_to = \"value\") |&gt;\n  head()\n\n# A tibble: 6 × 3\n  carname   Parameters  value\n  &lt;chr&gt;     &lt;chr&gt;       &lt;dbl&gt;\n1 Mazda RX4 mpg         21   \n2 Mazda RX4 cyl          6   \n3 Mazda RX4 disp       160   \n4 Mazda RX4 hp         110   \n5 Mazda RX4 drat         3.9 \n6 Mazda RX4 wt           2.62\n\n\nFollow the simple two steps:\n\nIdentify the column you want to keep as is. In this case, we want all variables to match car names.\nAdditionally, notice that in the original data set, carname acts as the index of the data set. You would want to convert the index to a column using rownames_to_column.\nCreate meaningful names for the two new columns. In our case, straightforwardly, column names go into parameters and corresponding values go into value.",
    "crumbs": [
      "R resources",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data transformation</span>"
    ]
  },
  {
    "objectID": "data_transformation.html#pivot_wider",
    "href": "data_transformation.html#pivot_wider",
    "title": "5  Data transformation",
    "section": "5.3 pivot_wider",
    "text": "5.3 pivot_wider\npivot_wider is just the opposite of pivot_longer. Using pivot_wider, we can transform our tidy data back into the messy form as all distinct values in Parameters will become column names.\npivot_wider is often used in the case such that one observation being recorded over multiple rows. Consider the following example:\n\n\n# A tibble: 4 × 3\n  Country Type  Number\n  &lt;chr&gt;   &lt;chr&gt;  &lt;dbl&gt;\n1 USA     Case       4\n2 USA     Death      3\n3 Canada  Case       2\n4 Canada  Death      1\n\n\n\nexample |&gt; pivot_wider(names_from = Type, values_from = Number)\n\n# A tibble: 2 × 3\n  Country  Case Death\n  &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1 USA         4     3\n2 Canada      2     1\n\n\nIt would make much more sense if Case and Death are separate features.\nThe main focus of this chapter is pivot_longer and pivot_wider. However, other fundamental functions in dplyr are also very important in manipulating your data set. In the following section, we will give an overview of the basics.",
    "crumbs": [
      "R resources",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data transformation</span>"
    ]
  },
  {
    "objectID": "data_transformation.html#basic-transformation-functions",
    "href": "data_transformation.html#basic-transformation-functions",
    "title": "5  Data transformation",
    "section": "5.4 Basic transformation functions",
    "text": "5.4 Basic transformation functions\nFor the following sections, we will use data set biopsy from MASS for demonstration purpose.\n\n\n       ID V1 V2 V3 V4 V5 V6 V7 V8 V9     class\n1 1000025  5  1  1  1  2  1  3  1  1    benign\n2 1002945  5  4  4  5  7 10  3  2  1    benign\n3 1015425  3  1  1  1  2  2  3  1  1    benign\n4 1016277  6  8  8  1  3  4  3  7  1    benign\n5 1017023  4  1  1  3  2  1  3  1  1    benign\n6 1017122  8 10 10  8  7 10  9  7  1 malignant\n\n\n\n5.4.1 rename\nUpon getting the data, we noticed that the names of the columns are very vague. After reading the documentation, we wanted to change the names of the column so that the viewer gets a sense of the values they’re referring to. We use rename to modify the column names.\n\nbiopsy_new &lt;- rename(biopsy,\n       thickness = V1,cell_size = V2,\n       cell_shape = V3, marg_adhesion = V4,\n       epithelial_cell_size = V5, bare_nuclei = V6,\n       chromatin = V7, norm_nucleoli = V8, mitoses = V9)\n\nhead(biopsy_new)\n\n       ID thickness cell_size cell_shape marg_adhesion epithelial_cell_size\n1 1000025         5         1          1             1                    2\n2 1002945         5         4          4             5                    7\n3 1015425         3         1          1             1                    2\n4 1016277         6         8          8             1                    3\n5 1017023         4         1          1             3                    2\n6 1017122         8        10         10             8                    7\n  bare_nuclei chromatin norm_nucleoli mitoses     class\n1           1         3             1       1    benign\n2          10         3             2       1    benign\n3           2         3             1       1    benign\n4           4         3             7       1    benign\n5           1         3             1       1    benign\n6          10         9             7       1 malignant\n\n\n\n\n5.4.2 select\nselect is column-wise operation. Specifically, only the columns that are specified will be returned.\nIn the biopsy data, we do not require the variables “chromatin” and “mitoses”. So, let’s drop them using a minus sign:\n\n#selecting all except the columns chromatin and mitoses\nbiopsy_new &lt;- biopsy_new |&gt; dplyr::select(-chromatin,-mitoses)\n\nhead(biopsy_new,5)\n\n       ID thickness cell_size cell_shape marg_adhesion epithelial_cell_size\n1 1000025         5         1          1             1                    2\n2 1002945         5         4          4             5                    7\n3 1015425         3         1          1             1                    2\n4 1016277         6         8          8             1                    3\n5 1017023         4         1          1             3                    2\n  bare_nuclei norm_nucleoli  class\n1           1             1 benign\n2          10             2 benign\n3           2             1 benign\n4           4             7 benign\n5           1             1 benign\n\n\n\n\n5.4.3 mutate\nThe mutate function computes new variables from the already existing variables and adds them to the dataset. It gives information that the data already contained but was never displayed.\nThe variable bare_nucleus contains the values from 1.00 to 10.00. If we wish to normalize the variable, we can use the mutate function:\n\n#normalize the bare nuclei values \nmaximum_bare_nuclei&lt;-max(biopsy_new$bare_nuclei,na.rm=TRUE)\nbiopsy_new &lt;- biopsy_new |&gt; mutate(bare_nuclei=bare_nuclei/maximum_bare_nuclei)\n\nhead(biopsy_new,5)\n\n       ID thickness cell_size cell_shape marg_adhesion epithelial_cell_size\n1 1000025         5         1          1             1                    2\n2 1002945         5         4          4             5                    7\n3 1015425         3         1          1             1                    2\n4 1016277         6         8          8             1                    3\n5 1017023         4         1          1             3                    2\n  bare_nuclei norm_nucleoli  class\n1         0.1             1 benign\n2         1.0             2 benign\n3         0.2             1 benign\n4         0.4             7 benign\n5         0.1             1 benign\n\n\nIn some situations, your new variable might involve conditions. You can consider using case_when combined with mutate.\n\n\n5.4.4 filter\nfilter is a row-wise operation. It returns a modified copy that contains only certain rows. This function filters rows based on conditions supplied in its argument. The filter function takes the data frame as the first argument. The next argument contains one or more logical tests. The rows/observations that pass these logical tests are returned in the result of the filter function.\nFor our example, say we only want the data of those tumor cells that have clump thickness greater than 6.\n\nbiopsy_new &lt;- biopsy_new |&gt; filter(thickness&gt;5.5)\n\nhead(biopsy_new,5)\n\n       ID thickness cell_size cell_shape marg_adhesion epithelial_cell_size\n1 1016277         6         8          8             1                    3\n2 1017122         8        10         10             8                    7\n3 1044572         8         7          5            10                    7\n4 1047630         7         4          6             4                    6\n5 1050670        10         7          7             6                    4\n  bare_nuclei norm_nucleoli     class\n1         0.4             7    benign\n2         1.0             7 malignant\n3         0.9             5 malignant\n4         0.1             3 malignant\n5         1.0             1 malignant\n\n\nIf you want to filter using multiple conditions, use logical operators: &(And), |(Or).\n\n\n5.4.5 arrange\nArrange reorders the rows of the data based on their contents in the ascending order by default.\nSay in our example, the doctors would want to view the data in the order of the cell size of the tumor.\n\n#arrange in the order of V2:cell size\nhead(arrange(biopsy_new,cell_size))\n\n       ID thickness cell_size cell_shape marg_adhesion epithelial_cell_size\n1 1050718         6         1          1             1                    2\n2 1204898         6         1          1             1                    2\n3 1223967         6         1          3             1                    2\n4  543558         6         1          3             1                    4\n5   63375         9         1          2             6                    4\n6  752904        10         1          1             1                    2\n  bare_nuclei norm_nucleoli     class\n1         0.1             1    benign\n2         0.1             1    benign\n3         0.1             1    benign\n4         0.5            10 malignant\n5         1.0             7 malignant\n6         1.0             4 malignant\n\n\nIn case you want your data in descending order, wrap your variable with desc().\n\n\n5.4.6 group_by and summarize\nThe summarize function uses the data to create a new data frame with the summary statistics such as minimum, maximum, average, and so on. These statistical functions must be aggregate functions which take a vector of values as input and output a single value.\nThe group_by function groups the data by the values of the variables. This, along with summarize, makes observations about groups of rows of the dataset.\nThe doctors would want to see the maximum cell size and the thickness for each of the classes: benign and malignant. This can be done by grouping the data by class and finding the maximum of the required variables:\n\nbiopsy_grouped &lt;- group_by(biopsy_new,class)\nsummarize(biopsy_grouped, max(thickness), mean(cell_size), var(norm_nucleoli))\n\n# A tibble: 2 × 4\n  class     `max(thickness)` `mean(cell_size)` `var(norm_nucleoli)`\n  &lt;fct&gt;                &lt;int&gt;             &lt;dbl&gt;                &lt;dbl&gt;\n1 benign                   8              2.67                 5.93\n2 malignant               10              6.73                11.3 \n\n\n\n\n5.4.7 slice_max (slice_min)\nThe slice_max function helps you to find the top n values of a specific column. Suppose we now want to see the top five biopsies with the biggest thickness. Notice in this case, since we have more than five rows with thickness 10, all of them are selected (for neatness, we only show first several rows).\n\nbiopsy_new |&gt; \n  slice_max(order_by = thickness,n=5) |&gt; \n  head()\n\n       ID thickness cell_size cell_shape marg_adhesion epithelial_cell_size\n1 1050670        10         7          7             6                    4\n2 1054593        10         5          5             3                    6\n3 1072179        10         7          7             3                    8\n4 1080185        10        10         10             8                    6\n5 1099510        10         4          3             1                    3\n6 1103608        10        10         10             4                    8\n  bare_nuclei norm_nucleoli     class\n1         1.0             1 malignant\n2         0.7            10 malignant\n3         0.5             4 malignant\n4         0.1             9 malignant\n5         0.3             5 malignant\n6         0.1            10 malignant\n\n\n\n\n5.4.8 join\nSometimes you will need to combine two data sets and this is when function join comes into play. There are four types of joins provided by dplyr and take a look at the following example.\n\n# Main dataset\ns77 &lt;- data.frame(state.x77) |&gt; \n  rownames_to_column(\"state\") |&gt;\n  dplyr::select(-c(Illiteracy))\n\nhead(s77)\n\n       state Population Income Life.Exp Murder HS.Grad Frost   Area\n1    Alabama       3615   3624    69.05   15.1    41.3    20  50708\n2     Alaska        365   6315    69.31   11.3    66.7   152 566432\n3    Arizona       2212   4530    70.55    7.8    58.1    15 113417\n4   Arkansas       2110   3378    70.66   10.1    39.9    65  51945\n5 California      21198   5114    71.71   10.3    62.6    20 156361\n6   Colorado       2541   4884    72.06    6.8    63.9   166 103766\n\n\n\n# https://www.cookpolitical.com/2020-national-popular-vote-tracker\npartyinfo &lt;- read_csv(\"https://docs.google.com/spreadsheets/d/e/2PACX-1vS3Z8Rq9xqOLISwoKdK0n6CFLBuPSCoXbbLeY8vhi-rzFS3ZFNEtR0BCdEbHcS-2Tlh5aPcnZbwBLao/pub?output=csv\")\npartyinfo &lt;- partyinfo |&gt;\n  dplyr::select(state, called)\n\nhead(left_join(s77, partyinfo))\n\n       state Population Income Life.Exp Murder HS.Grad Frost   Area called\n1    Alabama       3615   3624    69.05   15.1    41.3    20  50708      R\n2     Alaska        365   6315    69.31   11.3    66.7   152 566432      R\n3    Arizona       2212   4530    70.55    7.8    58.1    15 113417      D\n4   Arkansas       2110   3378    70.66   10.1    39.9    65  51945      R\n5 California      21198   5114    71.71   10.3    62.6    20 156361      D\n6   Colorado       2541   4884    72.06    6.8    63.9   166 103766      D\n\n\ns77 contains statistics of 50 states in the US and partyinfo holds information whether a state is democratic or republican. The two data sets are joined on common feature state. If you want to join on features with different names, specify using the argument by. For detailed explanations of differnet types of joins, refer to the documentation.\n\n\n5.4.9 Cases to tables\nWhen you want to perform a Chi-squared test or create a paired mosaic plot, your data has to follow a table format. For example, the following table is in the correct format. The columns are anxiety statues and rows are class years.\n\n\n  moderate normal severe\n1       11     34      2\n2       22     69      4\n3        8     41      5\n4       15     37      5\n\n\nThe following example demonstrates how you can convert cases to tables. Notice the starting data has a count for each of the categorical combinations.\n\n# watch out: summarise\nrebates &lt;- read_csv(\"https://data.ny.gov/resource/thd2-fu8y.csv\")\nrebate_counts &lt;- rebates |&gt; group_by(make, ev_type) |&gt; \n  summarize(Freq = n())\nhead(rebate_counts)\n\n# A tibble: 6 × 3\n# Groups:   make [3]\n  make      ev_type  Freq\n  &lt;chr&gt;     &lt;chr&gt;   &lt;int&gt;\n1 Audi      BEV         6\n2 Audi      PHEV        1\n3 BMW       BEV         1\n4 BMW       PHEV        7\n5 Chevrolet BEV        73\n6 Chevrolet PHEV       33\n\n\nBy using xtabs, we are able to transform our data into a table ready for Chi-squared test or paired mosaic plot.\n\nhead(xtabs(Freq ~ ., data = rebate_counts))\n\n           ev_type\nmake        BEV PHEV\n  Audi        6    1\n  BMW         1    7\n  Chevrolet  73   33\n  Chrysler    0   11\n  Ford        1   28\n  Honda       0   45",
    "crumbs": [
      "R resources",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data transformation</span>"
    ]
  },
  {
    "objectID": "git_GitHub.html",
    "href": "git_GitHub.html",
    "title": "6  GitHub/git Resources",
    "section": "",
    "text": "6.1 Overview\nThis section describes workflows for working with GitHub/git and advice on how to collaborate in teams on large coding projects. GitHub is super useful and powerful, but people also find it quite annoying and difficult to understand. We suggest taking it one step at a time, beginning with the basic workflows outlined below. You can derive great benefits from it without being an expert.",
    "crumbs": [
      "R resources",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>GitHub/git Resources</span>"
    ]
  },
  {
    "objectID": "git_GitHub.html#first-things-first",
    "href": "git_GitHub.html#first-things-first",
    "title": "6  GitHub/git Resources",
    "section": "6.2 First things first",
    "text": "6.2 First things first\n\nInstall Git. To do so, follow the instructions in the Install Git chapter of Happy Git with R.\nTell git your name and email address. Introduce yourself to Git in Happy Git explains it all.\nSet up a personal access token. See Personal access token for HTTPS. (When you create the token, you will be given a choice of “Beta” or “classic”. Choose classic.)\n(Optional) Check that your setup works. See Connect RStudio to Git and GitHub. To be clear, you don’t have to do any connecting – the steps in this chapter check that it’s all working properly.",
    "crumbs": [
      "R resources",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>GitHub/git Resources</span>"
    ]
  },
  {
    "objectID": "git_GitHub.html#usage",
    "href": "git_GitHub.html#usage",
    "title": "6  GitHub/git Resources",
    "section": "6.3 Usage",
    "text": "6.3 Usage\nChoose the right section based on what you’re trying to accomplish:\n\nIf you are working by yourself and just getting started: the no branch workflow.\nIf you are working by yourself and want to learn how to use branches, or are a collaborator (i.e. have write access) to another repo: your repo with branching.\nIf you are not a collaborator (that is, don’t have write access to a repository) but wish to contribute to a project for the first time: 1st PR on another repo with branching.\nIf you are not a collaborator but wish to contribute to the same project again: 2nd-nth PR on another repo with branching.",
    "crumbs": [
      "R resources",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>GitHub/git Resources</span>"
    ]
  },
  {
    "objectID": "git_GitHub.html#the-no-branch-besides-main-workflow",
    "href": "git_GitHub.html#the-no-branch-besides-main-workflow",
    "title": "6  GitHub/git Resources",
    "section": "6.4 The no branch (besides main) workflow",
    "text": "6.4 The no branch (besides main) workflow\nTo get comfortable with Git, start with this basic workflow in which you will be pulling from and pushing to your repo on GitHub. Just you, no collaboration:\n\n\n\nThe Connect RStudio to Git and GitHub chapter of Happy Git will get you set up: you will create a repo on GitHub, clone the repo into an RStudio project, and practice making changes. Once you’re set up, your local workflow will be pull, work, commit/push.\nPULL Each time you open RStudio and switch to the project, you will pull down any changes made to the repo on GitHub by clicking the Down Arrow in the Git pane of RStudio. You may think that no changes have been made to GitHub and there’s nothing to pull, but you may forget the typos that you fixed online, so it’s good practice to always start by pulling changes just in case.\nWORK Do your stuff. Make changes to files. Add new files. Keep an eye on the Git panel in RStudio; it will show you which files were changes.\nCOMMIT/PUSH When you’re done working, you’ll want to think about what to do with the files that have changed. I like to keep the Git panel clear, so when I’m done I do one of three things with each file: 1) click “Staged” to get it ready for a sendoff to GitHub, 2) delete it if it’s not needed, 3) add it to .gitignore if it’s a file I want to keep locally but not send to GitHub. (Keep in mind that files in .gitignore are not backed up unless you have another backup system.) If I have a file that belongs somewhere else, I will move it there, so the only files left are the ones to send to GitHub.\nThe next step is to click the Commit button and enter a commit message that meaningful describes what was done. Finally clicking the Up Arrow will send the commit to GitHub.\nIt’s not considered good practice to commit too often, but as a beginner, it’s useful to do so to learn how it all works.",
    "crumbs": [
      "R resources",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>GitHub/git Resources</span>"
    ]
  },
  {
    "objectID": "git_GitHub.html#your-repo-with-branching",
    "href": "git_GitHub.html#your-repo-with-branching",
    "title": "6  GitHub/git Resources",
    "section": "6.5 Your repo with branching",
    "text": "6.5 Your repo with branching\nOnce you’ve comfortable with the workflow described above, you’re ready to start branching.\n\n\n\nIf it’s your repo–or you have write access to someone else’s repo–follow the steps in the next section, skipping steps 1 and 3. For emphasis, if you have write access, the repo will be “origin” not “upstream” from your perspective, and you will clone it directly, not fork it first.\nAt any point, you can check the remotes (in this case, GitHub repositories) that are linked to your project with git remote -v. If your GitHub username is person1 and you have write access to a repo called finalproject created by person2, your remotes will look like this:\n$ git remote -v\norigin  https://github.com/person2/finalproject.git(fetch)\norigin  https://github.com/person2/finalproject.git(push)",
    "crumbs": [
      "R resources",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>GitHub/git Resources</span>"
    ]
  },
  {
    "objectID": "git_GitHub.html#st-pr-on-another-repo-with-branching",
    "href": "git_GitHub.html#st-pr-on-another-repo-with-branching",
    "title": "6  GitHub/git Resources",
    "section": "6.6 1st PR on another repo with branching",
    "text": "6.6 1st PR on another repo with branching\n\n\n\n\nStep 1: Fork the upstream repo (once)\nSkip this step if you are syncing with a repo that you have write access to, whether it’s your own or someone else’s. Let’s say you want to contribute to edav.info! Fork our GitHub repo and then on your own GitHub page, you will see a forked edav2 repo under the repositories section. Note, from now on, the term upstream repository refers to the original repo of the project that you forked and the term origin repository refers to the repo that you created or forked on GitHub. From your respective, both upstream and origin are remote repositories.\n\n A fork of tidyverse/forcats\n\n\n\nStep 2: Clone origin and create a local repository (once)\nA local repository is the repo that resides on your computer. In order to be able to work locally, we need to create a local copy of the remote reposiotry. (For this to work you must first follow the instructions in First things first section.)\nOn your GitHub repo page, copy the url of the origin repo by clicking on the green Code button and then the clipboard icon. It should look like this: https://github.com/jtr13/EDAV.git Then switch to RStudio, and click File -&gt; New Project -&gt; Version Control -&gt; Git. Now you can paste in the url of the origin repo and click Create Project to create a local repository. It is best to choose a location that is outside of other version control systems such as Dropbox to avoid conflicts.\n\n\nStep 3: Configure remote that points to the upstream repository (once)\nSkip this step if you’re syncing with a repo that you have write access to. The purpose of this step is to specify the location of the upstream repository, that is, the original project, not your copy of it.\nTo complete this step, type in the following at the command line:\n$ git remote add upstream &lt;upstream repo url&gt;\nSource: Configuring a remote for a fork\nOnce the upstream remote is added, you will have two remotes: origin and upstream. For example, the remotes for my (jtr13) local forcats repository are:\n$ git remote -v\norigin  https://github.com/jtr13/forcats.git (fetch)\norigin  https://github.com/jtr13/forcats.git (push)\nupstream        https://github.com/tidyverse/forcats (fetch)\nupstream        https://github.com/tidyverse/forcats (push)\n(Although four options are listed, that is, fetching or pushing from either remote, as the diagram above indicates, we will only fetch from upsteam and push to origin.)\n\n\nStep 4: Branch\nWith this workflow, all new work is done on a branch, so it’s important to remember to create a new branch before you begin working. Once the work is complete, a pull request is submitted and if all goes well the new code will be merged into the main branch of the project on GitHub.\nWhen you’re ready to start working on something new, create a new branch. Do not reuse a merged branch. Each “fix” should get its own branch and be deleted after it’s been merged.\nTo create a branch, click on the button shown below:\n\n\n\n\n\nGive your new branch a meaningful name. For example, if you intend to add a faceting example to the histogram chapter, you might call your branch add_hist_facet. Leave the “Sync branch with remote” box checked. Thereby you will not only create a local branch but also a remote branch on origin, and the local branch will be set up to track the remote branch. In short, they will be linked and git will take note of any changes on the other.\n\n\nStep 5: Work, commit and push\nWhen you create a branch following the method in Step 4, you will be automatically switched to the new branch. You can switch branches by clicking on the branch dropdown box to the right of the new branch button. However, be careful doing so. Work that isn’t committed, even if it is saved, doesn’t belong to a branch so it will move with you as you change branches. This makes it easy to accidentally be on the wrong branch. Check that you are in the right place and as you work keep an eye on changed files in the Git pane.\n\n\n\n\nRecall that there are three steps to moving saved work from your working directory to GitHub, represented by the git commands: add, commit, and push.\n\n\n\n\n\nIn RStudio, to add, you simply click the checkbox for each file you have modified in the “staged” column on the left of the Git pane. To commit, you just click on the commit button under the Git tab. Entering a commit message is mandatory; choose a meaningful description of the code changes. Finally, to push changes to GitHub, click on the push button, which is represented by an upward pointing arrow. You can combine multiple commits into one “push”.\nIt is not considered good practice to commit too enough because all the commits are entered into the commit history and it’s hard to find what you need if you commit your work every five minutes. (As you’re starting out, though, I wouldn’t be concerned about this. It’s more important to use the commands frequently to gain experience.)\nThe Repeated Amend chapter of Happy Git with R describes one approach to dealing with the how-often-should-I-commit dilemma.\n\n\nStep 6: Submit a pull request\nNow you are able to see the branch you have created on the GitHub page. The next step is to submit a pull request and the process is very similar to the process described in the GitHub only walkthrough from the first version of edav.info, beginning with step 6.\n\n\nStep 7: Merge the pull request\nIf you submitted a PR to another project, you are not the one who will be merging the pull request, so there’s nothing for you to do here.\nIf it is your project, and it is your job to do so, be aware that there are many methods to merge a request. The most direct simple and direct is to merge the PR on GitHub. This method works well for merging fixed typos and the like. If you want to be able to test code, you may want to check out the PR locally, test it, and perhaps even make edits to it before merging.\nBest practices in this area are evolving. My current recommendation is to use the usethis package, which makes complex tasks very simple. “How to edit a pull request locally” explains how to do so.\nAnother great resource is “Explore and extend a pull request” in Happy Git with R. This chapter describes two official GitHub versions of merging a pull request, as well as a workflow in development using git2r.",
    "crumbs": [
      "R resources",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>GitHub/git Resources</span>"
    ]
  },
  {
    "objectID": "git_GitHub.html#nd-nth-pr-on-another-repo-with-branching",
    "href": "git_GitHub.html#nd-nth-pr-on-another-repo-with-branching",
    "title": "6  GitHub/git Resources",
    "section": "6.7 2nd-nth PR on another repo with branching",
    "text": "6.7 2nd-nth PR on another repo with branching\n\n\n\nAfter the first pull request, the process changes a little. We no longer need to fork and clone the repo. What we do need to do though is make sure that our local copy of the repository is up to date with the GitHub version. There is some other cleanup we need to do, so after the first pull request, we’ll replace steps #1 - #3 above with the following:\n\nStep 1: Sync\nHow you sync depends on whether you are syncing with your own repo (“origin”) or someone else’s repo (“upstream”). This should be done at the beginning of every work session.\nYour repo\nSwitch to the main branch (important!), then click the pull button (down arrow) in the Git pane in RStudio. Or you can type the following in the Terminal:\n$ git checkout main\n$ git pull\nThere are no reminders that you’re behind, so it’s up to you. Make it a habit.\nSomeone else’s repo\nIf you’re working on someone else’s repo, make sure you’ve configured an upstream remote.\nThen do the following to update your fork:\n$ git fetch upstream\n$ git checkout main\n$ git merge upstream/main\nSource: Syncing a fork\nNote that these commands bring in changes directly from the upstream repo. If you are working on a branch and want to sync, check out that branch rather than main and fetch / merge. Switching branches can be performed by clicking on the appropriate branch in RStudio instead of git checkout.\n\n\nStep 2: Delete the old branch\nIf your previous pull request was merged, it’s good practice to delete the associated branch since the upstream already contains all the changes you have made. To fully delete a branch you will need to 1) delete the local branch, 2) delete the remote branch, 3) stop tracking the branch:\n\nOne way to delete the remote branch is to do so on GitHub. Navigate to the closed pull request on the upstream repo. If your branch has been merged, the pull request dialogue will display the following message: “You’re all set—the &lt;branchname&gt; branch can be safely deleted.” Simply click on the Delete branch button next to the message.\n\nIf you prefer to work in the terminal, you can delete the remote branch with:\n$ git push origin --delete &lt;branchname&gt;\n\nTo delete the local branch, switch to the main branch in RStudio and then type the following in the terminal:\n\n$ git branch -d branchname\n\nTake note that git doesn’t stop tracking the remote branch even though it’s gone in both places! To stop tracking deleted branches use the following:\n\n$ git fetch -p\nOtherwise you will still see the deleted branches listed in RStudio’s Git pane, and they will still appear when you look at all of your branches with\n$ git branch -a (* = checked out branch)\nSpeaking of which, be aware that the Git pane doesn’t tend to update in real time, so you’ll likely still see branches listed that have been deleted. Be careful not to switch to them, or you will inadvertently recreate them. (Deleted branches have a habit of coming back.) Clicking on main (even though you’re already on main) appears to trigger an update of the dropdown list. If that doesn’t work, switching out of the project and back in will do so, if you want to be sure that the branches you deleted are really gone.\n\n\nStep 3: Update your fork on GitHub\nSkip this step if there’s no upstream repo.\nYes, it’s odd, but once you’ve forked and cloned the project repo, the copy on GitHub becomes fairly irrelevant. However it’s not a bad idea to keep it up to date, if for no other reason than it’s disturbing to see messages like the following in your Git pane:\n\n\n\n\n\nThankfully, your fork on GitHub can be updated easily by clicking the green up arrow or entering git push in the Terminal.\n\n\nSteps 4-7: See above\nNow we’re ready to repeat the branch, work, commit, push, submit a pull request workflow. To do so, follow Steps 4-7 above.",
    "crumbs": [
      "R resources",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>GitHub/git Resources</span>"
    ]
  },
  {
    "objectID": "git_GitHub.html#fixing-mistakes",
    "href": "git_GitHub.html#fixing-mistakes",
    "title": "6  GitHub/git Resources",
    "section": "6.8 Fixing mistakes",
    "text": "6.8 Fixing mistakes\nFixing things generally involves returning to an earlier point in git history. To do so we need a way of referring to the point we want to return to. There are multiple ways of referring to the past. Most of the examples below use HEAD (the last commit) or HEAD~1 (the parent of the last commit, a.k.a. the 2nd to last commit).\nIf you are contributing to someone else’s repo and things on your end get hopelessly messed up, the easiest way out is to start over. First be sure to keep a local copy of the files you need in a new folder, then delete your fork on GitHub, delete the local clone, fork again on GitHub, clone again to get a fresh local copy, and add the files you need back into the project. This is a variation of the “Burn it all down” described in Happy Git with R.\n\n6.8.1 Forgot to branch\n\nif you didn’t commit anything yet:  Just create the new branch and your work will be moved there, as changes in the working directory do not belong to a branch until they are committed.\nif you committed but didn’t push to GitHub:  Undo the last commit with git reset --soft HEAD~1 (i.e. return to the parent commit). --soft means your changes won’t be erased. Then create the new branch. (Your work will move to it, see above.)\nif you committed and pushed to GitHub:  Undo the last commit with git reset --soft HEAD~1, push to GitHub (you will need to use git push --force since the push will cause origin to lose commits, then create the new branch. (Your work will move to it, see above.)  Note: Be very, very careful with --force as it is a dangerous tool. However, since the stakes are lower if you are force pushing to a fork, as would be the case if you are contributing to someone else’s repo, it’s ok to use it in this particular case.\n\n\n\n6.8.2 Undoing stuff\n\nUndo the last commit: git reset --soft HEAD~1  (Fun fact: “How do I undo the most recent local commits in Git?” has the second highest number of votes of any question on Stack Overflow, and over 8 million views.)\nUndo changes since the last commit: git reset --hard HEAD\nUndo changes in one file since the last commit:git checkout -- [filename] SO link\nUndo deleted branch: Look for the SHA (hash) returned when you deleted the branch. Then:git checkout -b &lt;branch-name&gt; &lt;SHA&gt;  SO link\nRemove all new, untracked files: git clean -f\nRemove all new, untracked files, including in new subdirectories: git clean -f -d\nRevert to a previous commit Using Git — how to go back to a previous commit\n\n\n\n6.8.3 Random\n\nMake local the same as origin:git fetch origingit reset --hard origin/main SO link\nAdd back a file that was deleted but still exists on another branch:git checkout otherbranch myfile.txt SO link\nGet rid of a file on GitHub that was added to .gitignore but is still there:git rm --cached [filename](then commit and push changes to GitHub) SO link\nCompletely remove a folder from git history (use with caution) SO link",
    "crumbs": [
      "R resources",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>GitHub/git Resources</span>"
    ]
  },
  {
    "objectID": "git_GitHub.html#troubleshooting",
    "href": "git_GitHub.html#troubleshooting",
    "title": "6  GitHub/git Resources",
    "section": "6.9 Troubleshooting",
    "text": "6.9 Troubleshooting\n\n6.9.1 Deleting a branch isn’t working\n\nMake sure you’re not on the branch you’re trying to delete.\nNote that if you try to delete a branch that hasn’t been fully merged, you’ll get a warning, or perhaps an error depending on what’s transpired. It’s possible that it just thinks it hasn’t been merged even though it has, since you’re not up to date. This can be remedied with git pull. In other cases, you’ll need to follow the instructions to use -D instead of -d, for example, if you decide to abandon and delete a branch without submitting a pull request.\nIf you have trouble getting rid of branches, rest assured, that you’re not alone. How do I delete a Git branch locally and remotely? is the third most asked question on StackOverflow!",
    "crumbs": [
      "R resources",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>GitHub/git Resources</span>"
    ]
  },
  {
    "objectID": "git_GitHub.html#other-resources",
    "href": "git_GitHub.html#other-resources",
    "title": "6  GitHub/git Resources",
    "section": "6.10 Other resources",
    "text": "6.10 Other resources\n\nGetting Help\nIf you’re lost, these might help.\n\nGitHub Guides: This is a phenomenal collection of short articles from GitHub to help you learn about the fundamentals around their product. They are so great, we have already listed their Hello World article. Here are some other important ones:\n\nUnderstanding the GitHub Flow: Explains how working with GitHub generally goes.\nGit Handbook: Explains what version control is.\n\nGitHub Help: This is the yellow-pages of GitHub. Ask a question and it will try to push you in the right direction. Get it?\n\n\n\nBranching out\nGitHub is super social. Learn how to git involved! \n\nOpen Source Guide: Info on how to contribute to open source projects. Great links to the GitHub skills involved as well as good GitHub etiquette to adopt.\nForking Projects: Quick read from GitHub on how to fork a repository so you can contribute to it.\nOpening Issues: On what Issues are in GitHub and how they can help get things done.",
    "crumbs": [
      "R resources",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>GitHub/git Resources</span>"
    ]
  },
  {
    "objectID": "learning_ggplot2.html",
    "href": "learning_ggplot2.html",
    "title": "7  Learning ggplot2",
    "section": "",
    "text": "7.1 Getting started\nMake sure you have installed the tidyverse collection of packages with:\ninstall.packages(\"tidyverse\")\nTo use ggplot2 you can either call the library with\nlibrary(tidyverse)\nto load all tidyverse packages or:\nlibrary(ggplot2)\nfor the ggplot2 package only.",
    "crumbs": [
      "R graphics",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Learning ggplot2</span>"
    ]
  },
  {
    "objectID": "learning_ggplot2.html#grammar-of-graphics",
    "href": "learning_ggplot2.html#grammar-of-graphics",
    "title": "7  Learning ggplot2",
    "section": "7.2 Grammar of Graphics",
    "text": "7.2 Grammar of Graphics\nUnlike many graphics software packages, ggplot2 has an underlying grammar which enables you to create graphs by combining different basic components or building blocks. Therefore you are not limited by a list of premade charts but can design your own unique graphics given your data and research goals.\nThe underlying grammar is called the Grammar of Graphics based on a book by Leland Wilkinson with the same title. (That is what the “gg” in ggplot2 stands for.)\nAs implemented in ggplot2 the five basic components of graphs are 1) layers, 2) scales, 3) coordinate system, 4) faceting system, and 5) theme.\nThe layers contain the data; everything else in a sense helps us to view and interpret the data. Plots contain one or more layers.",
    "crumbs": [
      "R graphics",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Learning ggplot2</span>"
    ]
  },
  {
    "objectID": "learning_ggplot2.html#data-layers",
    "href": "learning_ggplot2.html#data-layers",
    "title": "7  Learning ggplot2",
    "section": "7.3 Data layers",
    "text": "7.3 Data layers\n\nknitr::include_graphics(\"images/layers.png\")\n\n\n\n\n\n\n\n\nData layers are made up of: 1) data, 2) a geom, 3) aesthetic mappings, 4) stat, and 5) position. The first three are required; the second two are optional and will rarely need to be changed from the default settings. So, let’s focus on data, geom and aesthetic mappings. Data refers simply to the data frame you are working with. Note that ggplot2 requires a data.frame or tibble. You cannot plot with other data structures such as vectors, matrices, or lists.\nGeom stands for geometric object, which you can think of as the shape in which the data will appear in your graph. Common geoms are point, bar, boxplot, line, histogram, and density. Each geom has a certain number of required pieces of information. For example, to draw a point, you need two pieces of information, an x and a y. These pieces of information are called aesthetic mappings. Let’s say we want to create a scatterplot. We start by recognizing that our graph will contain points so the geom we need is geom_point(). Next we have to\n\nlibrary(ggplot2)\n\nggplot(data = iris) +  # Data part\n  geom_point(aes(x = Sepal.Length, y = Sepal.Width))  # Mapping part\n\n\n\n\n\n\n\n\nThe most important part of all plots is data, which includes the information you want to visualize. Based on that, the next step is to decide its mapping, which determine how the data’s variable are mapped to aesthetic attributes on a graphic. Since data is independent from the other elements, you can always add several layers of data into the same ggplot while keeping the other components the same.\n\nggplot(data = iris) +  # Data part\n  geom_point(aes(Petal.Length, Petal.Width)) +  # layer 1 with mapping \n  geom_point(aes(Sepal.Length, Sepal.Width), color = 'red')  # layer 2 with a different mapping",
    "crumbs": [
      "R graphics",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Learning ggplot2</span>"
    ]
  },
  {
    "objectID": "learning_ggplot2.html#customized-parts",
    "href": "learning_ggplot2.html#customized-parts",
    "title": "7  Learning ggplot2",
    "section": "7.4 Customized parts",
    "text": "7.4 Customized parts\nThe following picture shows the order of ggplot functions:\n\n\n\nFor more function order suggestions and auto-correction when writing your own ggplot2 functions, please refer to ggformat addin created by Joyce.\n\n7.4.1 Geometric object, statistical transformation and position adjustment\nGeometric object, statistical transformation and position adjustment are components that can be customized in each layer.\nGeometric objects, called geoms, control graphical elements representing the data–think shapes. Different types of plot have different aesthetics features. For example, a point geom has position, color, shape, and size aesthetics. You should first decide which kind of plot better explains the data before choosing geoms and use help function to check what aesthetics can be modified to achieve your desired effects.\nA statistical transformation stat transforms the data. And Position adjustment is applied when you need to adjust the position of elements on the plot for dense data, otherwise data points might obscure one another.\n\nggplot(data = iris) +\n  geom_histogram(mapping = aes(x = Petal.Length, fill = Species),\n                 stat = 'bin',position = 'stack')\n\n\n\n\n\n\n\n\n\n\n7.4.2 Scale\n\n\n\nA scale controls how data is mapped to aesthetic attributes, so one scale for one layer.\n\nggplot(data = iris) +\n  geom_histogram(mapping = aes(x = Petal.Length, fill = Species),\n                 stat = 'bin', position = 'stack') +\n  scale_x_continuous(limits = c(0, 10)) +\n  scale_y_continuous(limits = c(0, 50))\n\n\n\n\n\n\n\n\n\n\n7.4.3 Coordinate system\nA coordinate system coord maps the position of objects onto the plane of the plot, and controls how the axes and grid lines are drawn. One ggplot can only have one `coord``\n\nggplot(data = iris) +\n  geom_histogram(mapping = aes(x = Petal.Length, fill = Species),\n                 stat = 'bin', position = 'stack') +\n  coord_polar()\n\n\n\n\n\n\n\n\n\n\n7.4.4 Faceting\nFaceting can be used to split the data up into subsets of the entire dataset.\n\nggplot(data = iris) +\n  geom_histogram(mapping = aes(x = Petal.Length), stat = 'bin') +\n  facet_wrap(~Species)\n\n\n\n\n\n\n\n\n\n\n7.4.5 Labels\nLabels include titles, labels for x,y axis and annotates. Good graphics also need to give clear information by using labels to tell readers’ of the background knowledge of your data.\n\nggplot(data = iris) +\n  geom_histogram(mapping = aes(x = Petal.Length, fill = Species), stat = 'bin',position = 'stack') +\n  ggtitle('Stacked petal length of different species') +\n  xlab('Length of Petal')",
    "crumbs": [
      "R graphics",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Learning ggplot2</span>"
    ]
  },
  {
    "objectID": "learning_ggplot2.html#resources-for-ggplot2",
    "href": "learning_ggplot2.html#resources-for-ggplot2",
    "title": "7  Learning ggplot2",
    "section": "7.5 Resources for ggplot2",
    "text": "7.5 Resources for ggplot2\n\nFor more implementations and examples, one easiest way is referring to the ggplot2 Cheatsheets provided by R. Follow the steps shown below and you can find the cheat-sheets in your RStudio.\n\n\n\n\nThe cheat-sheets clearly list the basic components of a ggplot where you can customize your unique plot by choosing different functions.\n\nIf you are seeking for more detailed explanations and examples with real datasets, here are some useful links for you:\n\n\nggplot2: Elegant Graphics\nggformat",
    "crumbs": [
      "R graphics",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Learning ggplot2</span>"
    ]
  },
  {
    "objectID": "learning_ggplot2.html#required-aesthetic-mappings",
    "href": "learning_ggplot2.html#required-aesthetic-mappings",
    "title": "7  Learning ggplot2",
    "section": "7.6 Required aesthetic mappings",
    "text": "7.6 Required aesthetic mappings\n\n\n\n\n\nGEOM\nREQUIRED MAPPINGS\n\n\n\n\ngeom_abline\nNA\n\n\ngeom_area\nx and y.\n\n\ngeom_bar\nx or y\n\n\ngeom_bin_2d\nx and y.\n\n\ngeom_bin2d\nx and y.\n\n\ngeom_blank\nNA\n\n\ngeom_boxplot\nx or y\n\n\ngeom_col\nx and y.\n\n\ngeom_contour\nx, y, and z.\n\n\ngeom_contour_filled\nx, y, and z.\n\n\ngeom_count\nx and y.\n\n\ngeom_crossbar\nx, y, ymin, and ymax or x, y, xmin, and xmax.\n\n\ngeom_curve\nx, y, and xend or x, y, and yend.\n\n\ngeom_density\nx or y\n\n\ngeom_density_2d\nx and y.\n\n\ngeom_density_2d_filled\nx and y.\n\n\ngeom_density2d\nx and y.\n\n\ngeom_density2d_filled\nx and y.\n\n\ngeom_dotplot\nx.\n\n\ngeom_errorbar\nx, ymin, and ymax or y, xmin, and xmax.\n\n\ngeom_errorbarh\nxmin, xmax, and y.\n\n\ngeom_freqpoly\nx or y\n\n\ngeom_function\nNA\n\n\ngeom_hex\nx and y.\n\n\ngeom_histogram\nx or y\n\n\ngeom_hline\nyintercept.\n\n\ngeom_jitter\nx and y.\n\n\ngeom_label\nx, y, and label.\n\n\ngeom_line\nx and y.\n\n\ngeom_linerange\nx, ymin, and ymax or y, xmin, and xmax.\n\n\ngeom_map\nNA\n\n\ngeom_path\nx and y.\n\n\ngeom_point\nx and y.\n\n\ngeom_pointrange\nx, y, ymin, and ymax or x, y, xmin, and xmax.\n\n\ngeom_polygon\nx and y.\n\n\ngeom_qq\nsample.\n\n\ngeom_qq_line\nsample.\n\n\ngeom_quantile\nx and y.\n\n\ngeom_raster\nx and y.\n\n\ngeom_rect\nxmin, xmax, ymin, and ymax.\n\n\ngeom_ribbon\nx, ymin, and ymax or y, xmin, and xmax.\n\n\ngeom_rug\nNA\n\n\ngeom_segment\nx, y, and xend or x, y, and yend.\n\n\ngeom_sf\ngeometry.\n\n\ngeom_sf_label\ngeometry.\n\n\ngeom_sf_text\ngeometry.\n\n\ngeom_smooth\nx and y.\n\n\ngeom_spoke\nx, y, angle, and radius.\n\n\ngeom_step\nx and y.\n\n\ngeom_text\nx, y, and label.\n\n\ngeom_tile\nx and y.\n\n\ngeom_violin\nx and y.\n\n\ngeom_vline\nxintercept.",
    "crumbs": [
      "R graphics",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Learning ggplot2</span>"
    ]
  },
  {
    "objectID": "faceting.html",
    "href": "faceting.html",
    "title": "8  Faceting",
    "section": "",
    "text": "8.1 Faceting on one variable\nIn this chapter, we will introduce facets, which are usually used to combine continuous and categorical data.\nFacet partitions a plot into a matrix of panels. Each panel shows a different subset of the data. By default, facet_wrap gives consistent scales, which is easier for comparison between different panels.\nlibrary(ggplot2)\nmycol = \"#7192E3\"  \nggplot(iris, aes(Sepal.Length, Sepal.Width)) +  \n  geom_point(color = mycol) +  \n  facet_wrap(~Species) +  \n  theme_grey(18)\nRather than faceting on factor level, we can have one panel for each numerical variable.\nlibrary(pgmm) \nlibrary(dplyr)\nlibrary(tidyr)\ndata(wine)  \ntidywine &lt;- wine |&gt; \n  pivot_longer(cols = -Type, names_to = \"variable\", values_to = \"value\")  \ntidywine |&gt;  \n  ggplot(aes(value)) +  \n  geom_histogram() +  \n  facet_wrap(~variable) +   \n  ggtitle(\"Consistent scales\") +  \n  theme_grey(14)\nAxis scales can be made independent, by setting scales to free, free_x, or free_y.\nIn this case, scales = \"free_x\" is a better option because the distribution of each numerical variable is more obvious.\ntidywine  |&gt;\n  ggplot(aes(value)) +\n  geom_histogram() +\n  facet_wrap(~variable,scales = \"free_x\") +\n  ggtitle(\"Consistent scales\") +\n  theme_grey(14)",
    "crumbs": [
      "R graphics",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Faceting</span>"
    ]
  },
  {
    "objectID": "faceting.html#faceting-on-two-variables",
    "href": "faceting.html#faceting-on-two-variables",
    "title": "8  Faceting",
    "section": "8.2 Faceting on two variables",
    "text": "8.2 Faceting on two variables\nfacet_grid can be used to split data-sets on two variables and plot them on the horizontal and/or vertical direction.\n\nwine |&gt;   \n  mutate(Type = paste(\"Type\", Type)) |&gt;   \n  select(1:6) |&gt;   \n  pivot_longer(cols = -Type, names_to = \"variable\", values_to = \"value\") |&gt;  \n  ggplot(aes(value)) +  \n  geom_histogram(color = mycol, fill = \"lightblue\") +  \n  facet_grid(Type ~ variable, scales = \"free_x\") +  \n  theme_grey(14)",
    "crumbs": [
      "R graphics",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Faceting</span>"
    ]
  },
  {
    "objectID": "continuous_var.html",
    "href": "continuous_var.html",
    "title": "9  Unidimensional continuous variables",
    "section": "",
    "text": "9.1 Histogram\nIn this chapter, we will demonstrate graphs with unidimensional continuous variables only using ggplot2.",
    "crumbs": [
      "R graphics",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Unidimensional continuous variables</span>"
    ]
  },
  {
    "objectID": "continuous_var.html#histogram",
    "href": "continuous_var.html#histogram",
    "title": "9  Unidimensional continuous variables",
    "section": "",
    "text": "9.1.1 Basics and implications\nWe will start with an easy example.\n\nlibrary(ggplot2)\nlibrary(gridExtra)\n\n#Example data\nx &lt;- c(50, 51, 53, 55, 56, 60, 65, 65, 68)\n#Stored as a dataframe\ndf &lt;- data.frame(x)\n\nggplot(df, aes(x)) +\n  ggtitle(\"Histogram of x with ggplot2\") +\n  geom_histogram(color = \"blue\", fill = \"lightBlue\", binwidth = 5, center = 52.5)\n\n\n\n\n\n\n\n\nIn this example, we used geom_histogram to create a histogram on variable x. We can see that it is quick to make and does not need much pre-processing. Moreover, Histograms show data’s empirical distribution within a set of intervals and we suggest using it as a one of the first steps to understand your data.\nNote: as shown above, ggplot expects a dataframe, so make sure you do not throw a vector into ggplot.\n\n\n9.1.2 Types of histograms\nThe y-scale of histograms can be represented in a variety of ways to express different results:\n\nFrequency or count: y = number of values that fall in each bin\n\n\nggplot(finches, aes(x = Depth)) +\n  geom_histogram(color=\"blue\",fill=\"lightblue\",binwidth = 0.5,boundary = 6) +\n  ggtitle(\"Frequency histogram\")\n\n\n\n\n\n\n\n\n\nCumulative frequency: y = total number of values &lt;= (or &lt;) right boundary of bin\n\n\nggplot(finches, aes(x = Depth)) +\n  geom_histogram(aes(y = cumsum(after_stat(count))), color=\"blue\", fill=\"lightblue\", binwidth = 0.5, boundary = 6) +\n  ggtitle(\"Cumulative frequency histogram\") +\n  xlab(\"Cumulative frequency\")\n\n\n\n\n\n\n\n\n\nDensity: y = relative frequency / binwidth\n\n\nggplot(finches, aes(x = Depth)) +\n  geom_histogram(aes(y = after_stat(density)), color = \"blue\", fill = \"lightblue\", binwidth = 0.5, boundary = 6) +\n  ggtitle(\"Density histogram\")\n\n\n\n\n\n\n\n\n\n\n9.1.3 Parameters for geom_histogram\n\n9.1.3.1 Bin boundaries\nBe mindful of the boundaries of the bins and whether a point will fall into the left or right bin if it is on a boundary. You can use the parameter closed to control the intervals.\n\np1 &lt;- ggplot(df, aes(x)) +\n  geom_histogram(color = \"blue\", fill = \"lightblue\", \n                 binwidth = 5, center = 52.5, closed = \"left\")  +\n  ggtitle(\"Left closed graph\")\n\np2 &lt;- ggplot(df, aes(x)) +\n  geom_histogram(color = \"blue\", fill = \"lightblue\", \n                 binwidth = 5, center = 52.5, closed=\"right\")  +\n  ggtitle(\"Right closed graph\")\n\ngrid.arrange(p1, p2, ncol = 2)\n\n\n\n\n\n\n\n\n\n\n9.1.3.2 Bin numbers\n\n#Default / Only adding some styles to make graph consistent\nggplot(finches, aes(x = Depth)) +\n  geom_histogram(color = \"blue\", fill = \"lightblue\") +\n  ggtitle(\"Default with pop-up about bin number\")\n\n\n\n\n\n\n\n\nWe start by passing no parameters into geom_histogram and you will notice a pop-up saying that the default number of bins is 30. We see that the graph is not ideal with some gaps. There are two ways to modify the number of bins: specify the width explicitly with binwidth or provide the desired number of bins with bins. Consider the following modifications:\n\n# using binwidth\np3 &lt;- ggplot(finches, aes(x = Depth)) +\n  geom_histogram(color = \"blue\", fill = \"lightblue\", binwidth = 0.5, boundary = 6) +\n  ggtitle(\"Changed binwidth value\")\n\n# using bins\np4 &lt;- ggplot(finches, aes(x = Depth)) +\n  geom_histogram(color=\"blue\", fill = \"lightblue\", bins = 15, boundary = 6) +\n  ggtitle(\"Changed bin value\")\n\n# format plot layout\ngrid.arrange(p3, p4, ncol = 2)\n\n\n\n\n\n\n\n\nNote: There is no gold standard on the number of bins, so try different numbers to generate best results.\n\n\n9.1.3.3 Bin alignment\nConsider this comparison\n\np5 &lt;- ggplot(finches, aes(x = Depth)) +\n  geom_histogram(color = \"blue\", fill = \"lightblue\", binwidth = 0.5) +\n  ggtitle(\"Without alignment\")\n\np6 &lt;- ggplot(finches, aes(x = Depth)) +\n  geom_histogram(color = \"blue\", fill = \"lightblue\", bins = 15, boundary = 6) +\n  ggtitle(\"With alignment\")\n\ngrid.arrange(p5, p6, ncol = 2)\n\n\n\n\n\n\n\n\nNotice that the boundary of bins does not start at an axis and the only difference in the code is the removal of boundry. To control the position of bins, we can use either parameter center or boundary. You can use boundary to specify the endpoint of any bin or center to specify the center of any bin and ggplot2 will be able to calculate where to place the rest of the bins. (Also, notice that when the boundary was changed, the number of bins got smaller by one. This is because by default the bins are centered and go over/under the range of the data.) In the above example, we specify boundary to be 6. We can see the first bin starts at 6 and the position of other bins are calculated based on the binwidth 0.5.\n\n\n\n9.1.4 Interactive histograms with ggvis\nThe ggvis package is not currently in development, but does certain things very well, such as adjusting parameters of a histogram interactively while coding. If you are interested, refer here.",
    "crumbs": [
      "R graphics",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Unidimensional continuous variables</span>"
    ]
  },
  {
    "objectID": "continuous_var.html#boxplots",
    "href": "continuous_var.html#boxplots",
    "title": "9  Unidimensional continuous variables",
    "section": "9.2 Boxplots",
    "text": "9.2 Boxplots\n\n9.2.1 Single boxplot\nA boxplot is one of the simplest ways of representing a distribution of a continuous variable (Never use boxplots for categorical data). It consists of two parts: box and whiskers. Let’s starting with a simple example: single boxplot.\n\nggplot(chickwts, aes(x = weight)) +\n  geom_boxplot() +\n  ggtitle(\"Boxplot of chicken weights\")\n\n\n\n\n\n\n\n\nHere as you can see, boxplots provide a ton of information for a single chart. Boxplots tell you whether the variable is normally distributed, or if the distribution is skewed in either direction. You can also easily spot the outliers, which always helps.\nMake a boxplot interactively (created with D3)\n\n\n9.2.2 Multiple boxplots\nNext, what if you want to compare the distributions between multiple classes? Here, you can create a multiple boxplot. But remember, your data frame needs to be tidy, that is you need to have a column with levels of the grouping variable. It can be be factor, character, or integer class.\nThe following example still use the chickwts dataset. We compare the distributions of weight between different feed(which is a column with six factor levels).\n\nggplot(chickwts, aes(x = reorder(feed, -weight, median),y = weight)) +\n  geom_boxplot() +\n  ggtitle(\"Multiple boxplots of chicken weights according to feed type\") +\n  labs(y = \"Weight\", x = \"Feed Type\")\n\n\n\n\n\n\n\n\nNote. Usually in a boxplot, the boxes should be reordered so that there will be a decreasing order of the class medians from left to right.\nOften you want boxplots to be horizontal. Super easy to do in ggplot2: just tack on + coord_flip() and remove the - from the reordering so that the factor level with the highest median will be on top:\n\nggplot(chickwts, aes(x = reorder(feed, weight, median),y = weight)) +\n  geom_boxplot() +\n  coord_flip() +\n  ggtitle(\"Multiple boxplots of chicken weights according to feed type\") +\n  labs(y = \"Weight\", x = \"Feed Type\")\n\n\n\n\n\n\n\n\n\n\n9.2.3 Additional resources\n\nTukey, John W. 1977. Exploratory Data Analysis. Addison-Wesley. (Chapter 2): the primary source in which boxplots are first presented.\nArticle on boxplots with ggplot2: An excellent collection of code examples on how to make boxplots with ggplot2. Covers layering, working with legends, faceting, formatting, and more. If you want a boxplot to look a certain way, this article will help.\nBoxplots with plotly package: boxplot examples using the plotly package. These allow for a little interactivity on hover, which might better explain the underlying statistics of your plot.\nggplot2 Boxplot: Quick Start Guide: Article from STHDA on making boxplots using ggplot2. Excellent starting point for getting immediate results and custom formatting.\nHadley Wickhan and Lisa Stryjewski on boxplots: good for understanding basics of more complex boxplots and some of the history behind them.",
    "crumbs": [
      "R graphics",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Unidimensional continuous variables</span>"
    ]
  },
  {
    "objectID": "continuous_var.html#ridgeline-plot",
    "href": "continuous_var.html#ridgeline-plot",
    "title": "9  Unidimensional continuous variables",
    "section": "9.3 Ridgeline plot",
    "text": "9.3 Ridgeline plot\n\n9.3.1 Basics and implications\nRidgeline plots can be used when a number of data segments have to be plotted on the same horizontal scale. It is presented with slight overlap. Ridgeline plots are very useful to visualize the distribution of a categorical variable over time or space.\nA good example using ridgeline plots will be a great example is visualizing the distribution of salary over different departments in a company.\nConsider the following example:\n\nlibrary(ggridges)\nlibrary(forcats)\n\nworld &lt;- read.csv(\"countries2012.csv\")\n\nggplot(world, aes(x = GDP, y = reorder(CONTINENT, -GDP,median))) +\n  geom_density_ridges(fill = \"blue\") +\n  ggtitle(\"2012 continental GDP\") +\n  ylab(\"Continent\")\n\n\n\n\n\n\n\n\nggridge uses two main geoms to plot the ridgeline density plots: geom_density_ridges and geom_ridgeline. They are used to plot the densities of categorical variable factors and see their distribution over a continuous scale.\n\n\n9.3.2 Create better visuals\n\nggplot(world, aes(x = GDP, y = reorder(CONTINENT, GDP,median))) +\n  geom_density_ridges(fill = \"blue\",alpha = .5, scale = 1.2) +\n  ggtitle(\"2012 continental GDP\") +\n  ylab(\"Continent\")\n\n\n\n\n\n\n\n\nIn this example, we added parameter scale and alpha to control overlaps between ridges. Scale defines how much the peak of the lower curve touches the curve above and alpha controls transparency. Note that the curves are ordered from lowest median GDP on the bottom (Africa) to highest on the top (Europe).\n\n\n9.3.3 Additional resources\n\nIntroduction to ggridges: An excellent collection of code examples on how to make ridgeline plots with ggplot2. Covers every parameter of ggridges and how to modify them for better visualization. If you want a ridgeline plot to look a certain way, this article will help.\nArticle on ridgeline plots with ggplot2: Few examples using different examples. Great for starting with ridgeline plots.\nHistory of Ridgeline plots: To refer to the theory of ridgeline plots.",
    "crumbs": [
      "R graphics",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Unidimensional continuous variables</span>"
    ]
  },
  {
    "objectID": "continuous_var.html#normal-distribution",
    "href": "continuous_var.html#normal-distribution",
    "title": "9  Unidimensional continuous variables",
    "section": "9.4 Normal distribution",
    "text": "9.4 Normal distribution\nWhen encountering data that seems to be normally distributed, you may want to overlay a normal curve.\nThere are many ways to draw a normal curve and we introduce one here:\n\nggplot(finches, aes(x = Depth)) +\n  geom_histogram(aes(y = after_stat(density)), color = \"blue\", fill = \"lightblue\", binwidth = 0.5) +\n  geom_function(fun = dnorm, col = \"red\", args = list(mean(finches$Depth), sd(finches$Depth)), lwd = 1) +\n  labs(title = \"Normal curve overlaid\")\n\n\n\n\n\n\n\n\nIn some situations you might want to draw separate normal curves after faceting on a categorical variable. Simply using stat_function will not generate the desired result. Consider the following examples, where normal curves were created for four plots using a single stat_function.\n\n\n\nAs first glance, a normal curve appears in all of the plots. However, if you look closely, all the normal curves are actually the same one and generated on the whole dataset. In such situation, we suggest drawing each graph separately and combine them.",
    "crumbs": [
      "R graphics",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Unidimensional continuous variables</span>"
    ]
  },
  {
    "objectID": "uni_categorical_var.html",
    "href": "uni_categorical_var.html",
    "title": "10  Unidimensional categorical variables",
    "section": "",
    "text": "10.1 Bar plot\nIn real-world datasets, categorical features are quite common but tricky during both the data pre-processing and visualization process. In this chapter, we will demonstrate several plotting options for the uni-dimensional categorical variables with ggplot.\nThere are two types of uni-dimensional categorical variables: nominal and ordinal. Here you will be shown how these variables should be plotted differently using bar plot under the same dataset.",
    "crumbs": [
      "R graphics",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Unidimensional categorical variables</span>"
    ]
  },
  {
    "objectID": "uni_categorical_var.html#bar-plot",
    "href": "uni_categorical_var.html#bar-plot",
    "title": "10  Unidimensional categorical variables",
    "section": "",
    "text": "10.1.1 Nominal data\nNominal data is data with no fixed category order and should be sorted from highest to lowest count (left to right, or top to bottom)\nBy default, R always sorts levels in alphabetical order. To reorder it by a sorted value, you can try fct_reorder , fct_rev, fct_relevel in the forcats package\n\nlibrary(vcdExtra)\nlibrary(ggplot2)\nlibrary(forcats)\nlibrary(dplyr)\n\nAccident |&gt;\n  group_by(mode) |&gt;\n  summarise(freq = sum(Freq)) |&gt;\n  ggplot(aes(x=fct_reorder(mode,freq,.desc = TRUE),y=freq)) +\n  geom_bar(stat = \"identity\",fill = \"cornflowerblue\") +\n  ggtitle(\"Number of people with different modes in accident\") +\n  xlab(\"\") +\n  theme(panel.grid.major.x = element_blank())\n\n\n\n\n\n\n\n\n… or top to bottom\n\nAccident |&gt;\n  group_by(mode) |&gt;\n  summarise(freq = sum(Freq)) |&gt;\n  ggplot(aes(x=fct_rev(fct_reorder(mode,freq,.desc = TRUE)),y=freq)) +\n  geom_bar(stat = \"identity\",fill = \"cornflowerblue\") +\n  ggtitle(\"Number of people with different modes in accident\") +\n  coord_flip() +\n  xlab(\"\") +\n  theme(panel.grid.major.x = element_blank())\n\n\n\n\n\n\n\n\n\n\n10.1.2 Ordinal data\nOrdinal data is data having a fixed category order and need to sort it in logical order of the categories (left to right)\n\nAccident |&gt;\n  group_by(age) |&gt;\n  summarise(freq = sum(Freq)) |&gt;\n  ggplot(aes(x=age,y=freq)) +\n  geom_bar(stat = \"identity\",fill = \"cornflowerblue\") +\n  ggtitle(\"Number of people of different ages in accident\") +\n  xlab(\"\") +\n  theme(panel.grid.major.x = element_blank())\n\n\n\n\n\n\n\n\nSort in logical order of the categories (starting at bottom OR top)\n\nAccident |&gt;\n  group_by(age) |&gt;\n  summarise(freq = sum(Freq)) |&gt;\n  ggplot(aes(x=age,y=freq)) +\n  geom_bar(stat = \"identity\",fill = \"cornflowerblue\") +\n  ggtitle(\"Number of people of different ages in accident\") +\n  xlab(\"\") +\n  coord_flip() +\n  theme(panel.grid.major.x = element_blank())",
    "crumbs": [
      "R graphics",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Unidimensional categorical variables</span>"
    ]
  },
  {
    "objectID": "uni_categorical_var.html#cleveland-dot-plot",
    "href": "uni_categorical_var.html#cleveland-dot-plot",
    "title": "10  Unidimensional categorical variables",
    "section": "10.2 Cleveland dot plot",
    "text": "10.2 Cleveland dot plot\nCleveland dot plot is a good alternative to bar plots, making plots more readable and comparable even with more data. Similarly, we also need to reorder the categorical variables just like what we’ve done for nominal bar plot.\n\nlibrary(Lock5withR)\nggplot(USStates, aes(x = IQ, y = fct_reorder(State, IQ))) +\n  geom_point(color = \"blue\") +\n  ggtitle(\"Avg. IQ for US states\") +\n  ylab(\"\") +\n  theme_linedraw()\n\n\n\n\n\n\n\n\n\n10.2.1 Cleveland dot plot with multiple dots\nSort by Obese Rate\n\nlibrary(tidyr)\nUSStates |&gt;\n  select('State','Obese','HeavyDrinkers') |&gt;\n  gather(key='type',value='percentage',Obese,HeavyDrinkers) |&gt;\n  ggplot(aes(x=percentage, y=fct_reorder2(State,type=='Obese',percentage,.desc=FALSE), color = type)) +\n  geom_point() +\n  ggtitle(\"Obese rate & heavy drinker rate in US\") +\n  ylab(\"\") +\n  theme_linedraw()\n\n\n\n\n\n\n\n\n\n\n10.2.2 Cleveland dot plot with facets\nYou can split the graph into small multiples using facet_grid().\n\nggplot(USStates, aes(x = IQ, y = reorder(State, IQ))) +\n  geom_point(color = \"blue\") +\n  facet_grid(Pres2008 ~ ., scales = \"free_y\", space = \"free_y\") +\n  ggtitle('IQ of US state residents facet by Pres2008') +\n  xlab(\"IQ\") +\n  ylab('') +\n  theme_linedraw() +\n  theme(panel.grid.major.x = element_blank(), panel.grid.minor.x = element_blank())\n\n\n\n\n\n\n\n\n\n\n10.2.3 Example: How Much People in the Trump Administration Are Worth\n\n# create dot plot theme\ntheme_dotplot &lt;- \n  theme_bw(16) +\n  theme(axis.text.y = element_text(size = rel(.8)), axis.ticks.y = element_blank(),\n        axis.title.x = element_text(), axis.text = element_text(face = \"bold\"),\n        plot.background = element_rect(fill = \"lightcyan2\"),\n        panel.background = element_rect(fill = \"moccasin\"),\n        panel.grid.major.x = element_line(size = 0.5),\n        panel.grid.major.y = element_line(size = 0.5, color = \"lightblue\"),\n        panel.grid.minor.x = element_blank(),\n        strip.text = element_text(size = rel(.7)), legend.position = \"top\")\n\n# data source:\n# NYT, How Much People in the Trump Administration Are Worth\n# https://www.nytimes.com/interactive/2017/04/01/us/politics/how-much-people-in-the-trump-administration-are-worth-financial-disclosure.html\ndf &lt;- read.csv(\"data/Assets.csv\")\n\n# change units to millions\ndf$Assets &lt;- df$Assets / 1000000\n\nggplot(df, aes(x = Assets, y = reorder(Name, Assets))) +\n  geom_point() +\n  ggtitle(\"How Much People in the Trump\\nAdministration Are Worth\") +\n  xlab(\"Assets in Millions $\") +\n  ylab(\"\") +\n  theme_dotplot\n\n\n\n\n\n\n\n\n\n# create Panel column\ndf &lt;- df |&gt; \n  mutate(Panel = cut(Assets, 4, breaks = fivenum(Assets),\n         labels = c(\"$66k - $604k\", \"$1 - 3.5 Million\",\n                    \"$4 - 12 Million\", \"$18 Million+\"))) |&gt; mutate(Panel = fct_rev(Panel))\n\nggplot(df, aes(x = Assets, y = reorder(Name, Assets))) +\n  geom_point() +\n  facet_wrap(~Panel, ncol = 1, scales = \"free\") +\n  ggtitle(\"How Much People in the Trump\\nAdministration Are Worth\") +\n  xlab(\"Assets in Millions $\") +\n  ylab(\"\") +\n  theme_dotplot",
    "crumbs": [
      "R graphics",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Unidimensional categorical variables</span>"
    ]
  },
  {
    "objectID": "two_continuous_var.html",
    "href": "two_continuous_var.html",
    "title": "11  Two continuous variables",
    "section": "",
    "text": "11.1 Scatterplot\nIn this chapter, we will look at techniques that explore the relationships between two continuous variables.",
    "crumbs": [
      "R graphics",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Two continuous variables</span>"
    ]
  },
  {
    "objectID": "two_continuous_var.html#scatterplot",
    "href": "two_continuous_var.html#scatterplot",
    "title": "11  Two continuous variables",
    "section": "",
    "text": "11.1.1 Basics and implications\nFor the following example, we use data set SpeedSki.\n\nlibrary(GDAdata)\nlibrary(ggplot2)\n\nggplot(SpeedSki, aes(Year, Speed)) + \n  geom_point() +\n  labs(x = \"Birth year\", y = \"Speed achieved (km/hr)\") +\n  ggtitle(\"Skiers by birth year and speed achieved\")\n\n\n\n\n\n\n\n\nIn our example, we simply use geom_point on variables Year and Speed to create the scatterplot. we try to capture if there is a relationship between the age of a player and the speed he/she can achieve. From the graph, it seems such relationship does not exist. Overall, scatterplots are very useful in understanding the correlation (or lack thereof) between variables. The scatterplot gives a good idea of whether that relationship is positive or negative and if there’s a correlation. However, don’t mistake correlation in a scatterplot for causation!\n\n\n11.1.2 Overplotting\nIn some situations a scatter plot faces the problem of overplotting as there are so many points overlapping. Consider the following example from class. To save time, we randomly sample 20% of the data in advance.\n\nlibrary(dplyr)\nlibrary(ggplot2movies)\n\nsample &lt;- slice_sample(movies, prop = 0.2)\n\nggplot(sample,aes(x=votes,y=rating)) +\n  geom_point() +\n  ggtitle(\"Votes vs. rating\") +\n  theme_classic()\n\n\n\n\n\n\n\n\nTo create better visuals, we can use:\n\nAlpha blending - alpha=...\nOpen circles - pch=21\nsmaller circles - size=... or shape=\".\"\n\n\nlibrary(gridExtra)\n\nf1 &lt;- ggplot(sample,aes(x=votes,y=rating)) +\n  geom_point(alpha=0.3) +\n  theme_classic() +\n  ggtitle(\"Alpha blending\")\n\nf2 &lt;- ggplot(sample,aes(x=votes,y=rating)) +\n  geom_point(pch = 21) +\n  theme_classic() +\n  ggtitle(\"Open circle\")\n\nf3 &lt;- ggplot(sample,aes(x=votes,y=rating)) +\n  geom_point(size=0.5) +\n  theme_classic() +\n  ggtitle(\"Smaller circle\")\n\ngrid.arrange(f1, f2, f3,nrow = 3)\n\n\n\n\n\n\n\n\nOther methods that directly deal with the data:\n\nRandomly sample data - as shown in the first code chunk using sample_n\nSubset - split data into bins using ntile(votes, 10)\nRemove outliers\nTransform to log scale\n\n\n\n11.1.3 Interactive scatterplot\nYou can create an interactive scatterplot using plotly. In the following example, we take 1% of the movie data set to present a better visual. We plotted the votes vs. rating and grouped by the year they are released. In this graph:\n\nYou can hover on to the points to see the title of the movie\nYou can double click on the year legend to look at a certain year\nYou can zoom into a certain part of the graph to better understand the data points.\n\n\nlibrary(plotly)\n\nsample2 &lt;- slice_sample(movies,prop=0.01) |&gt;\n  filter(year &gt; 2000)\n\nplot_ly(sample2, x = ~votes, y = ~rating,\n        color = ~as.factor(year), text= ~title,\n        hoverinfo = 'text') \n\n\n\n\n\n\n\n11.1.4 Modifications\n\n11.1.4.1 Contour lines\nContour lines give a sense of the density of the data at a glance.\nFor these contour maps, we will use the SpeedSki dataset.\nContour lines can be added to the plot using geom_density_2d() and contour lines work best when combined with other layers\n\nggplot(SpeedSki, aes(Year, Speed)) + \n  geom_density_2d(bins=5) +\n  geom_point() +\n  ggtitle(\"Scatter plot with contour line\")\n\n\n\n\n\n\n\n\nYou can use bins to control the number of contour bins.\n\n\n11.1.4.2 Scatterplot matrices\nIf you want to compare multiple parameters to each other, consider using a scatterplot matrix. This will allow you to show many comparisons in a compact and efficient manner.\nFor these scatterplot matrices, we use the movies dataset from the ggplot2movies package.\nAs a default, the base R plot() function will create a scatterplot matrix when given multiple variables:\n\nsample3 &lt;- slice_sample(movies,prop=0.01) #sample data\n\nsplomvar &lt;- sample3 |&gt; \n  dplyr::select(length, budget, votes, rating, year)\n\nplot(splomvar)\n\n\n\n\n\n\n\n\nWhile this is quite useful for personal exploration of a dataset, it is not recommended for presentation purposes. Something called the Hermann grid illusion makes this plot very difficult to examine.",
    "crumbs": [
      "R graphics",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Two continuous variables</span>"
    ]
  },
  {
    "objectID": "two_continuous_var.html#heatmaps",
    "href": "two_continuous_var.html#heatmaps",
    "title": "11  Two continuous variables",
    "section": "11.2 Heatmaps",
    "text": "11.2 Heatmaps\n\n11.2.1 Basics and implications\nIn the following example, we still use the SpeedSki data set.\n\nggplot(SpeedSki, aes(Year, Speed)) + \n  geom_bin2d() \n\n\n\n\n\n\n\n\nTo create a heatmap, simply substitute geom_point() with geom_bin2d(). Generally, heat maps are like a combination of scatterplots and histograms: they allow you to compare different parameters while also seeing their relative distributions.\n\n\n11.2.2 Modifications\nFor the following section, we introduce some variations on heatmaps.\n\n11.2.2.1 Change number of bins / binwidth\nBy default, geom_bin2d() use 30 bins. Similar to a histogram, we can change the number of bins or binwidth.\n\nggplot(SpeedSki, aes(Year, Speed)) + \n  geom_bin2d(binwidth = c(5,5)) +\n  ggtitle(\"Changing binwidth\")\n\n\n\n\n\n\n\n\nNotice we are specifying the binwidth for both x and y axis.\n\n\n11.2.2.2 Combine with a scatterplot\n\nggplot(SpeedSki, aes(Year, Speed)) +\n  geom_bin2d(binwidth = c(10, 10), alpha = .4) + \n  geom_point(size = 2) +\n  ggtitle(\"Combined with scatterplot\")\n\n\n\n\n\n\n\n\n\n\n11.2.2.3 Change color scale\nYou can change the continuous scale of color\n\nggplot(SpeedSki, aes(Year, Speed)) + \n  geom_bin2d() +\n  ggtitle(\"Changing color scale\") + \n  scale_fill_viridis_c()\n\n\n\n\n\n\n\n\n\n\n11.2.2.4 Hex heatmap\nOne alternative is a hex heatmap. You can create the graph using geom_hex\n\nggplot(SpeedSki, aes(Year, Speed)) + \n  geom_hex(binswidth = c(10,10)) +\n  ggtitle(\"Hex heatmap\")\n\n\n\n\n\n\n\n\n\n\n11.2.2.5 Alternative approach to color\nIf you look at all the previous examples, you might notice that lighter points correspond to more clustered points, which is somewhat counter-intuitive. The following example suggests an alternative approach in color scale.\n\nggplot(SpeedSki, aes(Year, Speed)) + \n  geom_hex(bins=12) +\n  scale_fill_gradient(low = \"grey\", high = \"purple\") +  \n  theme_classic(18) +\n  ggtitle(\"Alternative approach to color\")",
    "crumbs": [
      "R graphics",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Two continuous variables</span>"
    ]
  },
  {
    "objectID": "multidimensional_continuous.html",
    "href": "multidimensional_continuous.html",
    "title": "12  Multidimensional continuous variables",
    "section": "",
    "text": "12.1 Parallel coordinate plot\nIn this chapter, we will look at techniques that explore the relationships between multiple continuous variables.",
    "crumbs": [
      "R graphics",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Multidimensional continuous variables</span>"
    ]
  },
  {
    "objectID": "multidimensional_continuous.html#parallel-coordinate-plot",
    "href": "multidimensional_continuous.html#parallel-coordinate-plot",
    "title": "12  Multidimensional continuous variables",
    "section": "",
    "text": "12.1.1 Basics and implications\nFor the following example, we use the famous iris data set. After installing GGally, we use ggparcoord to create the plot simply by specifying the columns we want.\n\nlibrary(GGally)\n\nggparcoord(iris, columns=1:4, \n           title = \"Parallel coordinate plot for Iris flowers\")\n\n\n\n\n\n\n\n\nGenerally, parallel coordinate plots are used to infer relationships between multiple continuous variables - we mostly use them to detect a general trend that our data follows, and also the specific cases that are outliers.\nPlease keep in mind that parallel coordinate plots are not the ideal graph to use when there are just categorical variables involved. We can include a few categorical variables for the sake of clustering, but using a lot of categorical variables results in overlapping profiles, which makes it difficult to interpret.\n\n\n12.1.2 Modifications\nThe default parallel coordinate plot might be messy and hard to interpret. The following techniques will help to create better visuals and convey clearer trends.\n\n12.1.2.1 Grouping\nGenerally, you use grouping when you want to observe a pattern by group of a categorical variable. To do this, we set groupColumn to the desired categorical variable.\n\n\n12.1.2.2 Alpha\nIn practice, parallel coordinate plots are not going to be used for very small datasets. Your data will likely have thousands and thousands of cases, and sometimes it can get very difficult to observe anything when there are many overlaps. We set the alphaLines between zero and one, and it reduces the opacity of all lines.\n\n\n12.1.2.3 Scales\nSometimes the value in your variables have very different range and it is necessary to rescale them to make comparisons. By default, ggparcoord standardize your data.\nThe following are some other scaling options:\n\nstd: default value, where it subtracts mean and divides by standard deviation.\nrobust: subtract median and divide by median absolute deviation.\nuniminmax: scale all values so that the minimum is at 0 and maximum at 1.\nglobalminmax: no scaling, original values taken.\n\n\n\n12.1.2.4 Splines\nGenerally, we use splines if we have a column where there are a lot of repeating values, which adds a lot of noise. The case lines become more and more curved when we set a higher spline factor, which removes noise and makes for easier observations of trends. It can be set using the splineFactor attribute.\n\n\n12.1.2.5 Reordering\nYou can reorder your columns in any way you want. Simply put the order in a vector. For example:\ncolumns = c(1,3,4,2,5)\n\n\n12.1.2.6 Application\nConsider the following example, we apply grouping, alpha tuning, scaling and splines on the iris data set. Compare the two plot and the modified graph is noticeably easier to interpret.\n\nggparcoord(iris, columns=1:4, groupColumn=5, alpha=0.5, scale='uniminmax',splineFactor=10,\n           title = \"Modified parallel coordinate plot for Iris flowers\")\n\n\n\n\n\n\n\n\n\n\n\n12.1.3 Interactive parallel coordinate plot\nPackage parcoords can help us in creating interactive parallel coordinate plots. The following example is created using New York State crime data.\n\ndf_a |&gt; \n  select(-c(\"Year\",\"Months Reported\",\"Index Total\",\"Violent Total\",\"Property Total\")) |&gt;\n  arrange(df_a) |&gt;\n  parcoords(rownames = FALSE,\n            brushMode = \"1D-axes\",\n            color = list(colorBy = \"Region\",\n                         colorScale = \"scaleOrdinal\",\n                         colorScheme = \"schemeCategory10\"),\n            alpha = 0.5,\n            withD3 = TRUE,\n            width = 770,\n            height = 600)\n\n\n\n\n\nIn the interactive graph, for each feature, you can create a square box to filter for observations. For example, you can look at a certain county, or you can filter for all counties that are in New York City (Region=NYC). Overall, the interactive plot is more flexible for analysis.\n\n\n12.1.4 External resource\nJust like a static graph, there is a lot of things you can change in the interactive setting. Refer to the Introduction to parcoords vignette for more options. Unfortunately, at the time of this writing the original blog post about the library is not available.",
    "crumbs": [
      "R graphics",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Multidimensional continuous variables</span>"
    ]
  },
  {
    "objectID": "multidimensional_continuous.html#biplot",
    "href": "multidimensional_continuous.html#biplot",
    "title": "12  Multidimensional continuous variables",
    "section": "12.2 Biplot",
    "text": "12.2 Biplot\nIn the following chapter, we will introduce biplot. We will talk briefly on how to create a biplot and how to interpret it.\n\n12.2.1 Principal components analysis (PCA)\nWe first introduce PCA as the existence of biplot is built up on it. Given a data set with multiple variables, the goal of PCA is to reduce dimensionality by finding a few linear combinations of the variables that capture most of the variance. Consider the following example using rating of countries.\nAs a common technique, we first standardize each variable to have mean of 0 and variance of 1\n\nscaled_ratings &lt;- ratings |&gt; \n  mutate(across(where(is.numeric), ~round((.x-mean(.x))/sd(.x), 2)))\nscaled_ratings\n\n# A tibble: 13 × 7\n   country     living_standard climate  food security hospitality infrastructure\n   &lt;chr&gt;                 &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;       &lt;dbl&gt;          &lt;dbl&gt;\n 1 Italy                  0.9     1.04  1.2       0.5       -0.34           0.83\n 2 Spain                  0.9     1.49  1.2       0.5       -0.74           1.23\n 3 Croatia               -0.12    0.14 -0.03      1          0.47           0.43\n 4 Brazil                -0.12    1.04  0.38     -0.5       -0.74          -0.77\n 5 Russia                 0.39   -1.67 -1.68     -0.5        1.27           0.43\n 6 Germany                1.41   -1.22 -1.68      2          1.27           1.63\n 7 Turkey                -0.12    1.04  1.2      -0.5       -1.15          -0.77\n 8 Morocco               -0.63    0.59  0.79     -1         -1.15          -1.17\n 9 Peru                  -0.12    0.14 -0.03     -0.5        0.06          -0.37\n10 Nigeria               -1.64   -0.76 -0.85     -1         -0.34          -1.17\n11 France                 1.41   -0.76  0.38      1.5        2.08           1.23\n12 Mexico                -1.64   -0.31 -0.44     -1         -0.34          -0.77\n13 SouthAfrica           -0.63   -0.76 -0.44     -0.5       -0.34          -0.77\n\n\nTo apply PCA, we use function prcomp(). summary() will then be used to show result.\n\npca &lt;- prcomp(ratings[,2:7], scale. = TRUE)\nsummary(pca)\n\nImportance of components:\n                         PC1    PC2     PC3     PC4     PC5     PC6\nStandard deviation     1.854 1.4497 0.43959 0.39052 0.27517 0.19778\nProportion of Variance 0.573 0.3503 0.03221 0.02542 0.01262 0.00652\nCumulative Proportion  0.573 0.9232 0.95544 0.98086 0.99348 1.00000\n\n\nAs we can see that the first two principal components capture 92.3% of the total variance.\n\nmat_round &lt;- function(matrix, n = 3) apply(matrix, 2, function(x) round(x, n))\n\nmat_round(pca$rotation)\n\n                   PC1    PC2    PC3    PC4    PC5    PC6\nliving_standard -0.429  0.364  0.112 -0.673  0.466 -0.028\nclimate          0.270  0.585 -0.210  0.036 -0.149 -0.719\nfood             0.221  0.596  0.610  0.212 -0.077  0.417\nsecurity        -0.475  0.244 -0.282  0.676  0.419  0.049\nhospitality     -0.484 -0.216  0.636  0.170 -0.213 -0.490\ninfrastructure  -0.484  0.252 -0.297 -0.121 -0.731  0.256\n\n\nWe are also able to see the specific linear combination of variables for each principal component.\n\n\n12.2.2 Draw a biplot\nTo draw a biplot, we suggest using draw_biplot from redav package. You can install the package using remotes::install_github(\"jtr13/redav\"). Note that the function will apply PCA and draw the plot.\n\nlibrary(redav)\ndraw_biplot(ratings,arrows=FALSE)\n\n\n\n\n\n\n\n\nThe above biplot is set to be without arrows. We can rougly identify clusters from the graph. By running some clustering algorithm like k-means, you will be able to see it clearer.\n\nscores &lt;- pca$x[,1:2]\nk &lt;- kmeans(scores, centers = 6)\nscores &lt;- data.frame(scores) |&gt;\n  mutate(cluster = factor(k$cluster), country = ratings$country)\ng4 &lt;- ggplot(scores, aes(PC1, PC2, color = cluster, label = country)) +\n  geom_point() +\n  geom_text(nudge_y = .2) +\n  guides(color=\"none\")\ng4\n\n\n\n\n\n\n\n\nNow for a standard bibplot:\n\ndraw_biplot(ratings)\n\n\n\n\n\n\n\n\nTo interpret the graph, you could imagine a perpendicular line from a certain point(country) to a feature arrow you are concerned. The further the intersection is on the arrow line, the higher the score. Take Spain for example, it has high score on all variables except hospitality as the imaginary line would land on the negative axis.\nYou can also add calibrated axis, which will help you better compare a certain variable among countries.\n\ndraw_biplot(ratings,\"living_standard\")\n\n\n\n\n\n\n\n\nYou see in this case, a projection line is added. We can clearly see that France has the highest living standard rating and Nigeria has the lowest rating.",
    "crumbs": [
      "R graphics",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Multidimensional continuous variables</span>"
    ]
  },
  {
    "objectID": "multidimensional_categorical.html",
    "href": "multidimensional_categorical.html",
    "title": "13  Multidimensional categorical variables",
    "section": "",
    "text": "13.1 Barcharts\nIn this chapter, we will focus on multivariate categorical data. Here, it is noteworthy that multivariate plot is not the same as multiple variable plot, where the former is used for analysis with multiple outcomes.\nBar chats are used to display the frequency of multidimensional categorical variables. In the next few plots you will be shown different kinds of bar charts.",
    "crumbs": [
      "R graphics",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Multidimensional categorical variables</span>"
    ]
  },
  {
    "objectID": "multidimensional_categorical.html#barcharts",
    "href": "multidimensional_categorical.html#barcharts",
    "title": "13  Multidimensional categorical variables",
    "section": "",
    "text": "13.1.1 Stacked bar chart\n\nlibrary(tidyverse)\ncases &lt;- read.csv(\"data/icecream.csv\") |&gt; \n  mutate(Age = fct_relevel(Age, \"young\"))\nicecreamcolors &lt;- c(\"#ff99ff\", \"#cc9966\") # pink, coffee\nggplot(cases, aes(x = Age, fill = Favorite)) + \n    geom_bar() + scale_fill_manual(values = icecreamcolors)\n\n\n\n\n\n\n\n\n\n\n13.1.2 Grouped bar chart\nUse position = \"dodge\" to create grouped bar chart\n\nggplot(cases, aes(x = Age, fill = Favorite)) +\n  geom_bar(position = \"dodge\") +\n  scale_fill_manual(values = icecreamcolors)\n\n\n\n\n\n\n\n\n\n\n13.1.3 Grouped bar chart with facets\n\nggplot(cases, aes(x = Age)) +\n  geom_bar(position = \"dodge\") +\n  facet_wrap(~Favorite)\n\n\n\n\n\n\n\n\n\n\n13.1.4 Grouped barchart with three categorical variables\n\ncounts3 &lt;- cases |&gt;\n  group_by(Age, Favorite, Music) |&gt;\n  summarize(Freq = n()) |&gt;\n  ungroup() |&gt;\n  complete(Age, Favorite, Music, fill = list(Freq = 0))\n\nggplot(counts3, aes(x = Favorite, y = Freq, fill = Music)) +\n  geom_col(position = \"dodge\") +\n  facet_wrap(~Age)",
    "crumbs": [
      "R graphics",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Multidimensional categorical variables</span>"
    ]
  },
  {
    "objectID": "multidimensional_categorical.html#chi-square-test-of-independence",
    "href": "multidimensional_categorical.html#chi-square-test-of-independence",
    "title": "13  Multidimensional categorical variables",
    "section": "13.2 Chi square test of independence",
    "text": "13.2 Chi square test of independence\nIn this section, we would like to show how to use chi-square test to check the independence between two features.\nWe will use the following example to answer: Are older Americans more interested in local news than younger Americans? The dataset is collected from here.\n\nlocal &lt;- data.frame(Age = c(\"18-29\", \"30-49\", \"50-64\", \"65+\"),\n                        Freq = c(2851, 9967, 11163, 10911)) |&gt;\n  mutate(Followers = round(Freq*c(.15, .28, .38, .42)),\n         Nonfollowers = Freq - Followers) |&gt;\n  select(-Freq)\nknitr::kable(local[,1:2])\n\n\n\n\nAge\nFollowers\n\n\n\n\n18-29\n428\n\n\n30-49\n2791\n\n\n50-64\n4242\n\n\n65+\n4583\n\n\n\n\n\nThe chi-square hypothesis is set to be:\nNull hypothesis: Age and tendency to follow local news are independent\nAlternative hypothesis: Age and tendence to follow local news are NOT independent\n\nlocalmat &lt;- as.matrix(local[,2:3])\nrownames(localmat) &lt;- local$Age\nX &lt;- chisq.test(localmat, correct = FALSE)\nX$observed\n\n      Followers Nonfollowers\n18-29       428         2423\n30-49      2791         7176\n50-64      4242         6921\n65+        4583         6328\n\nX$expected\n\n      Followers Nonfollowers\n18-29  984.1065     1866.893\n30-49 3440.4032     6526.597\n50-64 3853.2378     7309.762\n65+   3766.2526     7144.747\n\nX\n\n\n    Pearson's Chi-squared test\n\ndata:  localmat\nX-squared = 997.48, df = 3, p-value &lt; 2.2e-16\n\n\nWe compare observed to expected and then the p-value tells that age and tendency are independent features. We are good to move on to next stage on mosaic plots.",
    "crumbs": [
      "R graphics",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Multidimensional categorical variables</span>"
    ]
  },
  {
    "objectID": "multidimensional_categorical.html#mosaic-plots",
    "href": "multidimensional_categorical.html#mosaic-plots",
    "title": "13  Multidimensional categorical variables",
    "section": "13.3 Mosaic plots",
    "text": "13.3 Mosaic plots\nMosaic plots are used for visualizing data from two or more qualitative variables to show their proportions or associations.\n\n13.3.1 Mosaic plot with one variable\n\nlibrary(grid)\nicecream &lt;- read.csv(\"data/MusicIcecream.csv\") |&gt; \n  mutate(Age = fct_relevel(Age, \"young\"))\nicecreamcolors &lt;- c(\"#ff99ff\", \"#cc9966\") \ncounts2 &lt;- icecream |&gt;\n  group_by(Age, Favorite) |&gt;\n  summarize(Freq = sum(Freq))\nvcd::mosaic(~Age, direction = \"v\", counts2)\n\n\n\n\n\n\n\n\n\n\n13.3.2 Mosaic plot with two variables\n\nvcd::mosaic(Favorite ~ Age, counts2, direction = c(\"v\", \"h\"),\n            highlighting_fill = icecreamcolors)\n\n\n\n\n\n\n\n\n\n\n13.3.3 Mosaic plot with three variables(Best practice)\nHere’s some criteria of best practice of mosaic plots :\n\nDependent variables is split last and split horizontally\nFill is set to dependent variable\nOther variables are split vertically\nMost important level of dependent variable is closest to the x-axis and darkest (or most noticable shade)\n\n\nvcd::mosaic(Favorite ~ Age + Music, counts3,\n            direction = c(\"v\", \"v\", \"h\"),\n            highlighting_fill = icecreamcolors)\n\n\n\n\n\n\n\n\n\n\n13.3.4 Mosaic pairs plot\nUse pairs method to plot a matrix of pairwise mosaic plots for class table:\n\npairs(table(cases[,2:4]), highlighting = 2)\n\n\n\n\n\n\n\n\n\n\n13.3.5 Mosaic plots: spine plot\nSpine plot is a mosaic plot with straight, parallel cuts in one dimension (“spines”) and only one variable cutting in the other direction.\n\nlibrary(vcdExtra)\nlibrary(forcats)\nfoodorder &lt;- Alligator |&gt; group_by(food) |&gt; summarize(Freq = sum(count)) |&gt; \n  arrange(Freq) |&gt; pull(food)\nally &lt;- Alligator |&gt; \n  rename(Freq = count) |&gt; \n  mutate(size = fct_relevel(size, \"small\"),\n         food = factor(food, levels = foodorder),\n         food = fct_relevel(food, \"other\"))\n\nvcd::mosaic(food ~ sex + size, ally,\n       direction = c(\"v\", \"v\", \"h\"),\n       highlighting_fill= RColorBrewer::brewer.pal(5, \"Accent\"))\n\n\n\n\n\n\n\n\n\n\n13.3.6 Mosaic plot: tree map\nTreemap is a filled rectangular plot representing hierarchical data (fill color does not necessarily represent frequency count)\n\nlibrary(treemap)\ndata(GNI2014)\ntreemap::treemap(GNI2014,\n       index=c(\"continent\", \"iso3\"),\n       vSize=\"population\",\n       vColor=\"GNI\",\n       type=\"value\",\n       format.legend = list(scientific = FALSE, big.mark = \" \"))",
    "crumbs": [
      "R graphics",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Multidimensional categorical variables</span>"
    ]
  },
  {
    "objectID": "multidimensional_categorical.html#diverging-stacked-bar-chart",
    "href": "multidimensional_categorical.html#diverging-stacked-bar-chart",
    "title": "13  Multidimensional categorical variables",
    "section": "13.4 Diverging stacked bar chart",
    "text": "13.4 Diverging stacked bar chart\nThis type of chart works well with likert data, or any ordinal data with categories that span two opposing poles. The code below uses the likert() function from the HH package.\n\nlibrary(HH)\ngdata &lt;- read_csv(\"data/gender.csv\")\nHH::likert(Group~., gdata, positive.order = TRUE,\n           col=likertColorBrewer(3, ReferenceZero = NULL,\n                             BrewerPaletteName = \"BrBG\"),\n       main = \"% saying the country __ when \\n it comes to giving women equal rights with men\",\n       xlab = \"percent\", ylab = \"\")",
    "crumbs": [
      "R graphics",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Multidimensional categorical variables</span>"
    ]
  },
  {
    "objectID": "multidimensional_categorical.html#diverging-stacked-bar-chart-with-faceting",
    "href": "multidimensional_categorical.html#diverging-stacked-bar-chart-with-faceting",
    "title": "13  Multidimensional categorical variables",
    "section": "13.5 Diverging stacked bar chart (with faceting)",
    "text": "13.5 Diverging stacked bar chart (with faceting)\nUse | to condition (facet) on factor levels\n\ngdata$Section &lt;- c(\"Overall\", \"Gender\", \"Gender\", \"Party\", \"Party\")\ngdata &lt;- gdata |&gt; dplyr::select(Section, Group, everything())\n# sort facets manually\ngdata &lt;- gdata |&gt; mutate(Section = factor(Section,\n                  levels = c(\"Party\", \"Gender\", \"Overall\")))\n  likert(Group ~ . | Section,\n    data = gdata,\n    scales = list(y = list(relation = \"free\")),  # equivalent to scales = \"free_y\"\n    layout = c(1, 3), # controls position of subplots\n    positive.order = TRUE,\n     col=likertColorBrewer(3, ReferenceZero = NULL,\n                             BrewerPaletteName = \"BrBG\"),\n    main = \"% saying the country __ when \\n it comes to giving women equal rights with men\", \n    xlab = \"percent\",\n    ylab = NULL)\n\n\n\n\n\n\n\n\nReference: R. Heiberger and N. Robbins, Design of Diverging Stacked Bar Charts for Likert Scales and Other Applications",
    "crumbs": [
      "R graphics",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Multidimensional categorical variables</span>"
    ]
  },
  {
    "objectID": "multidimensional_categorical.html#alluvial-diagrams",
    "href": "multidimensional_categorical.html#alluvial-diagrams",
    "title": "13  Multidimensional categorical variables",
    "section": "13.6 Alluvial diagrams",
    "text": "13.6 Alluvial diagrams\nAlluvial diagrams are usually used to represent the flow changes in network structure over time or between different levels.\nThe following plot shows the essential components of alluvial plots used in the naming schemes and documentation (axis, alluvium, stratum, lode):\n\n\n\n\n13.6.1 ggalluvial\n\nlibrary(ggalluvial)\ndf2 &lt;- data.frame(Class1 = c(\"Stats\", \"Math\", \"Stats\", \"Math\", \"Stats\", \"Math\", \"Stats\", \"Math\"),\n                 Class2 = c(\"French\", \"French\", \"Art\", \"Art\", \"French\", \"French\", \"Art\", \"Art\"),\n                 Class3 = c(\"Gym\", \"Gym\", \"Gym\", \"Gym\", \"Lunch\", \"Lunch\", \"Lunch\", \"Lunch\"),\n                 Freq = c(20, 3, 40, 5, 10, 2, 5, 15))\nggplot(df2, aes(axis1 = Class1, axis2 = Class2, axis3 = Class3, y = Freq)) +\n  geom_alluvium(color='black') +\n  geom_stratum() +\n  geom_text(stat = \"stratum\", aes(label = paste(after_stat(stratum), \"\\n\", after_stat(count)))) +\n  scale_x_discrete(limits = c(\"Class1\", \"Class2\", \"Class3\"))\n\n\n\n\n\n\n\n\nYou can choose to color the alluvium by different variables, for example, the first variable Class1 here:\n\nggplot(df2, aes(axis1 = Class1, axis2 = Class2, axis3 = Class3, y = Freq)) +\n  geom_alluvium(aes(fill = Class1), width = 1/12) +\n  geom_stratum() +\n  geom_text(stat = \"stratum\", aes(label = paste(after_stat(stratum), \"\\n\", after_stat(count)))) +\n  scale_x_discrete(limits = c(\"Class1\", \"Class2\", \"Class3\"))\n\n\n\n\n\n\n\n\n\n\n13.6.2 geom_flow\nAnother way of plotting alluvial diagrams is using geom_flow rather than geom_alluvium:\n\nggplot(df2, aes(axis1 = Class1, axis2 = Class2, axis3 = Class3, y = Freq)) +\n  geom_flow(aes(fill = Class1), width = 1/12) +\n  geom_stratum() +\n  geom_text(stat = \"stratum\", aes(label = paste(after_stat(stratum), \"\\n\", after_stat(count)))) +\n  scale_x_discrete(limits = c(\"Class1\", \"Class2\", \"Class3\"))\n\n\n\n\n\n\n\n\nAfter we use geom_flow, all Math students learning Art came together, which is also the same as Stats students. It makes the graph much clearer than geom_alluvium since there is less cross alluviums between each axises.",
    "crumbs": [
      "R graphics",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Multidimensional categorical variables</span>"
    ]
  },
  {
    "objectID": "multidimensional_categorical.html#heat-map",
    "href": "multidimensional_categorical.html#heat-map",
    "title": "13  Multidimensional categorical variables",
    "section": "13.7 Heat map",
    "text": "13.7 Heat map\nBesides what have been systematically introduced in Chapter 9.2 Heatmaps, this part demonstrated a special case of heat map when both x and y are categorical. Here the heat map can been seen as a clustered bar chart and a pre-defined theme is used to show the dense more clearly.\n\nlibrary(vcdExtra)\nlibrary(dplyr)\ntheme_heat &lt;- theme_classic() +\n  theme(axis.line = element_blank(),\n        axis.ticks = element_blank())\norderedclasses &lt;- c(\"Farm\", \"LoM\", \"UpM\", \"LoNM\", \"UpNM\")\nmydata &lt;- Yamaguchi87\nmydata$Son &lt;- factor(mydata$Son, levels = orderedclasses)\nmydata$Father &lt;- factor(mydata$Father,\n                        levels = orderedclasses)\nmydata3 &lt;- mydata |&gt; group_by(Country, Father) |&gt; \n  mutate(Total = sum(Freq)) |&gt; ungroup()\nggplot(mydata3, aes(x = Father, y = Son)) +\n  geom_tile(aes(fill = (Freq/Total)), color = \"white\") +\n  coord_fixed() + \n  scale_fill_gradient2(low = \"black\", mid = \"white\",\n                        high = \"red\", midpoint = .2) +\n  facet_wrap(~Country) + theme_heat",
    "crumbs": [
      "R graphics",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Multidimensional categorical variables</span>"
    ]
  },
  {
    "objectID": "missing_data.html",
    "href": "missing_data.html",
    "title": "14  Missing data",
    "section": "",
    "text": "14.1 Introduction\nRegardless what kind of data you have, missing data is a common issue. In this chapter, we will talk about missing data. Our focus will be on visualizing missing data and patterns to help you better understand your data.",
    "crumbs": [
      "R graphics",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Missing data</span>"
    ]
  },
  {
    "objectID": "missing_data.html#row-column-missing-patterns",
    "href": "missing_data.html#row-column-missing-patterns",
    "title": "14  Missing data",
    "section": "14.2 Row / Column missing patterns",
    "text": "14.2 Row / Column missing patterns\nLet’s consider the following two problem:\n\nDo all rows / columns have the same percentage of missing values?\nAre there correlations between missing rows / columns? (If a value is missing in one column it is likely to be missing in another column.)\n\nWe will explore these two problems using mtcars with artificially generated missing values.\n\nlibrary(dplyr)\nlibrary(tibble)\nlibrary(tidyr)\nlibrary(ggplot2)\nlibrary(forcats)\n\nset.seed(5702)\nmycars &lt;- mtcars\nmycars[,\"gear\"] &lt;- NA\nmycars[10:20, 3:5] &lt;- NA\nfor (i in 1:10) mycars[sample(32,1), sample(11,1)] &lt;- NA\n\n\n14.2.1 colSums() / rowSums()\nThe most straightforward way to check missing values is using is.na() wrapped in colSums() / rowSums(). You will be able to observe the number of missing values column or row-wise.\n\ncolSums(is.na(mycars)) |&gt;\n  sort(decreasing = TRUE)\n\ngear disp   hp drat   am  cyl qsec   vs  mpg   wt carb \n  32   12   12   11    3    1    1    1    0    0    0 \n\n\n\n#Show only the head\nrowSums(is.na(head(mycars))) |&gt;\n  sort(decreasing = TRUE)\n\n        Mazda RX4     Mazda RX4 Wag        Datsun 710    Hornet 4 Drive \n                1                 1                 1                 1 \nHornet Sportabout           Valiant \n                1                 1 \n\n\n\n\n14.2.2 Heatmap\nA graph can be more informative than plain numbers. If there are not a lot of rows or columns, we can use heatmaps to visualize the missing values.\n\ntidycars &lt;- mycars |&gt; \n    rownames_to_column(\"id\") |&gt; \n    gather(key, value, -id) |&gt; \n    mutate(missing = ifelse(is.na(value), \"yes\", \"no\"))\n\n\nggplot(tidycars, aes(x = key, y = fct_rev(id), fill = missing)) +\n  geom_tile(color = \"white\") + \n  ggtitle(\"mtcars with NAs added\") +\n  ylab('') + \n  scale_fill_viridis_d() + # discrete scale\n  theme_bw()\n\n\n\n\n\n\n\n\nIn the above example, we can clearly see where the missing values are for both rows and columns.\nNow, to add more information to the graph, consider the following example:\n\ntidycars &lt;- tidycars |&gt; group_by(key) |&gt; \n  mutate(Std = (value-mean(value, na.rm = TRUE))/sd(value, na.rm = TRUE)) |&gt; ungroup()\n\nggplot(tidycars, aes(x = key, y = fct_rev(id), fill = Std)) +\n  geom_tile(color = \"white\") + \n  ylab('') + \n  scale_fill_gradient2(low = \"blue\", mid = \"white\", high =\"yellow\", na.value = \"black\") + theme_bw()\n\n\n\n\n\n\n\n\nIn this graph, black represents missing values. The color scale from purple to yellow represents the magnitude of the values.\n\n\n14.2.3 Patterns\nOther than the actual location of missing values, we can also explore the missing patterns. A Missing pattern refer to the combination of columns missing. The following picture should be a great demonstration of the concept.\n\nTo explore the patterns, we use plot_missing() from redav.\n\nlibrary(redav)\nplot_missing(mycars, percent = FALSE)\n\n\n\n\n\n\n\n\nNotice that there are three parts in the aggregated graph. The top part shows the number of missing values in each column. The middle part presents the missing patterns and the right part shows the counts for each missing patterns. You can also show the percentage in the top/right graphs by setting percentage = True.",
    "crumbs": [
      "R graphics",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Missing data</span>"
    ]
  },
  {
    "objectID": "colors.html",
    "href": "colors.html",
    "title": "15  Colors",
    "section": "",
    "text": "15.1 RColorBrewer\nWhen evaluating the power and efficiency of a plot, color is always a key factor that sometimes speaks a language even louder than words. So in this chapter, you will be introduced with several widely-applied color schemes and get to know how to use proper colors to make better plots based on different features of your data.\nRColorBrewer is an R package having built-in sensible color schemes ready-to-use for figures. Colors are grouped into three types: sequential, diverging, and qualitative.\nlibrary(RColorBrewer)\ndisplay.brewer.all()\nHere is an example of plotting categorical data using Dark2 pallets under qualitative group of RColorBrewer:\nlibrary(ggplot2)\nggplot(iris, aes(Petal.Length, Sepal.Length, colour = Species)) +\n  geom_point() +\n  scale_colour_brewer(palette = \"Dark2\")\nAlso, you can create your own sequential pallets.\nggplot(faithfuld, aes(waiting, eruptions, fill = density)) +\n  geom_raster() +\n  scale_fill_gradient(low = \"white\", high = \"red\")\nOr diverging pallets:\nggplot(faithfuld, aes(waiting, eruptions, fill = density)) +\n  geom_raster() +\n  scale_fill_gradient2(low = \"grey\", mid = \"white\", high = \"red\",midpoint = .02)\nFor discrete data, using scale_colour_manual is a good choice. For discrete ordinal data, we can use another package (such as vcd)\nggplot(mtcars, aes(mpg, wt)) +\n  geom_point(aes(colour = factor(cyl))) +\n  scale_colour_manual(values = c(\"red\", \"yellow\", \"blue\"))\n\n\n\n\n\n\n\ncolors&lt;-brewer.pal(5,'Blues')\nbarplot(1:5, col=colors)",
    "crumbs": [
      "R graphics",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Colors</span>"
    ]
  },
  {
    "objectID": "colors.html#rcolorbrewer",
    "href": "colors.html#rcolorbrewer",
    "title": "15  Colors",
    "section": "",
    "text": "Sequential – Light colours for low data, dark for high data\nQualitative(for categorical data) – Colours designed to give maximum visual difference between categories so great for non-ordered categorical data\nDiverging – Light colours for mid-range data, low and high use dark colours, great to seperate two extremes",
    "crumbs": [
      "R graphics",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Colors</span>"
    ]
  },
  {
    "objectID": "colors.html#perceptually-uniform-color-spaces-viridis",
    "href": "colors.html#perceptually-uniform-color-spaces-viridis",
    "title": "15  Colors",
    "section": "15.2 Perceptually uniform color spaces: Viridis",
    "text": "15.2 Perceptually uniform color spaces: Viridis\nThe viridis R package provides four palettes for use in R which are pretty, perceptually uniform and easy to read by those with colorblindness.\nThe package contains eight color scales: viridis, the primary choice, and five alternatives with similar properties - magma, plasma, inferno, civids, mako, and rocket -, and a rainbow color map - turbo.\n\n\n\nPerceived differences are proportional to scalar differences when using viridis. The following example shows viridison continuous data using scale_color_viridis_c, use scale_color_viridis_d() for discrete data\n\nlibrary(\"viridis\")\nggplot(iris, aes(Sepal.Length, Sepal.Width))+\n  geom_point(aes(color = Sepal.Length)) +\n  scale_color_viridis_c()",
    "crumbs": [
      "R graphics",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Colors</span>"
    ]
  },
  {
    "objectID": "time_series.html",
    "href": "time_series.html",
    "title": "16  Time series",
    "section": "",
    "text": "16.1 Dates\nTime series, by definition, is a sequence of data point collected over a certain period of time. In this chapter, we will demonstrate several useful ways of plotting time-series data and how to processing date data type in R.\nSince time series analysis looks into how data is changing over time, the very first step is to transform the data into correct format.",
    "crumbs": [
      "R graphics",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Time series</span>"
    ]
  },
  {
    "objectID": "time_series.html#dates",
    "href": "time_series.html#dates",
    "title": "16  Time series",
    "section": "",
    "text": "16.1.1 Basic R functions\nYou can convert character data to Date class with as.Date():\n\ndchar &lt;- \"2018-10-12\"\nddate &lt;- as.Date(dchar)\nclass(dchar)\n\n[1] \"character\"\n\nclass(ddate)\n\n[1] \"Date\"\n\n\nYou can also specifying the format by:\n\nas.Date(\"Thursday, January 6, 2005\", format = \"%A, %B %d, %Y\")\n\n[1] \"2005-01-06\"\n\n\nFor a list of the conversion specifications available in R, see ?strptime.\nHere is a list of the conversion specifications for date format from this post\n\n\n\nAlso, Date class supports calculation between dates:\n\nas.Date(\"2017-11-02\") - as.Date(\"2017-01-01\")\n\nTime difference of 305 days\n\nas.Date(\"2017-11-12\") &gt; as.Date(\"2017-3-3\")\n\n[1] TRUE\n\n\n\n\n16.1.2 Lubridate\nThe tidyverse lubridate makes it easy to convert dates that are not in standard format with ymd(), ydm(), mdy(), myd(), dmy(), and dym() (among many other useful date-time functions):\n\nlubridate::mdy(\"April 13, 1907\")\n\n[1] \"1907-04-13\"\n\n\nThe lubridate package also provides additional functions to extract information from a date:\n\ntoday &lt;- Sys.Date()\nlubridate::year(today)\n\n[1] 2025\n\nlubridate::yday(today)\n\n[1] 123\n\nlubridate::month(today, label = TRUE)\n\n[1] May\n12 Levels: Jan &lt; Feb &lt; Mar &lt; Apr &lt; May &lt; Jun &lt; Jul &lt; Aug &lt; Sep &lt; ... &lt; Dec\n\nlubridate::week(today)\n\n[1] 18",
    "crumbs": [
      "R graphics",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Time series</span>"
    ]
  },
  {
    "objectID": "time_series.html#time-series",
    "href": "time_series.html#time-series",
    "title": "16  Time series",
    "section": "16.2 Time series",
    "text": "16.2 Time series\nFor time-series data-sets, line plots are mostly used with time on the x-axis. Both base R graphics and ggplot2 “know” how to work with a Date class variable, and label the axes properly:\nThe data comes from the official website.\n\nlibrary(dplyr)\nlibrary(readxl)\nlibrary(tidyr)\nlibrary(ggplot2)\ndf &lt;- read_excel(\"data/historicalweeklydata.xls\", \n    col_types = c(\"date\", \"numeric\", \"numeric\", \n        \"numeric\"))\n\nplot(df$Week, df$`30 yr FRM`, type = \"l\") # on the order of years\n\n\n\n\n\n\n\ng&lt;-ggplot(df |&gt; filter(Week &lt; as.Date(\"2006-01-01\")), \n       aes(Week, `30 yr FRM`)) + \n  geom_line() + \n  theme_grey(14)\ng\n\n\n\n\n\n\n\n\nWe can control the x-axis breaks, limits, and labels with scale_x_date(), and use geom_vline() with annotate() to mark specific events in a time series.",
    "crumbs": [
      "R graphics",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Time series</span>"
    ]
  },
  {
    "objectID": "time_series.html#multiple-time-series",
    "href": "time_series.html#multiple-time-series",
    "title": "16  Time series",
    "section": "16.3 Multiple time series",
    "text": "16.3 Multiple time series\nThe following plot shows a multiple time series of U.S. Mortgage rates.\n\ndf2 &lt;- df |&gt; pivot_longer(cols = -c(\"Week\"), names_to = \"TYPE\") |&gt;\n  mutate(TYPE = forcats::fct_reorder2(TYPE, Week, value))# puts legend in correct order\n\nggplot(df2, aes(Week, value, color = TYPE)) +\n  geom_line() +\n  ggtitle(\"U.S. Mortgage Rates\") +  labs (x = \"\", y = \"percent\") +\n  theme_grey(16) +\n  theme(legend.title = element_blank())\n\n\n\n\n\n\n\n\nTo plot the time series in a specific period of time, use filter() before ggplot:\n\nlibrary(lubridate)\ndf2010 &lt;- df2 |&gt; filter(year(Week) == 2010)\nggplot(df2010, aes(Week, value, color = TYPE)) +\n  geom_line() +\n  ggtitle(\"U.S. Mortgage Rates\")",
    "crumbs": [
      "R graphics",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Time series</span>"
    ]
  },
  {
    "objectID": "time_series.html#time-series-patterns",
    "href": "time_series.html#time-series-patterns",
    "title": "16  Time series",
    "section": "16.4 Time series patterns",
    "text": "16.4 Time series patterns\nNext, as an important part of time series analysis, we want to find the existing patterns of the data. We first starting from plotting the overall long-term trend:\n\nlibrary (readr)\nurlfile=\"https://raw.githubusercontent.com/jtr13/data/master/ManchesterByTheSea.csv\"\ndata&lt;-read_csv(url(urlfile))\n\ng &lt;- ggplot(data, aes(Date, Gross)) +\n  geom_line() +\n  ggtitle(\"Manchester by the Sea\", \"Daily Gross (US$), United States\") +\n  xlab(\"2016-2017\")\ng\n\n\n\n\n\n\n\n\nAdding a smoother to the data, adjusting the smoothing parameter span = to find a proper smoother which is not overfitting/underfitting:\n\ng &lt;- ggplot(data, aes(Date, Gross)) + geom_point()\ng + geom_smooth(method = \"loess\", span = .5, se = FALSE)\n\n\n\n\n\n\n\n\nMark the pattern by high-lighting the data on very Saturday:\n\ng &lt;- ggplot(data, aes(Date, Gross)) +\n  geom_line() +\n  ggtitle(\"Manchester by the Sea\", \"Daily Gross, United States\")\nsaturday &lt;- data |&gt; filter(wday(Date) == 7) \ng +\n  geom_point(data = saturday, aes(Date, Gross), color = \"deeppink\")\n\n\n\n\n\n\n\n\nAnother way is to use facet to show the cyclical pattern:\n\nggplot(data, aes(Date, Gross)) +  \n    geom_line(color = \"grey30\") + geom_point(size = 1) +  \n    facet_grid(.~wday(Date, label = TRUE)) +  \n    geom_smooth(se = FALSE)\n\n\n\n\n\n\n\n\nAlso, basic R can plot the decomposed time series automatically. This method is used to study the trend, seasonal effect on data with at least 2 periods. For additive components, use type = \"additive\".\n\ntsData &lt;- EuStockMarkets[, 2]\ndecomposedRes &lt;- decompose(tsData, type=\"mul\")\nplot (decomposedRes)",
    "crumbs": [
      "R graphics",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Time series</span>"
    ]
  },
  {
    "objectID": "time_series.html#index",
    "href": "time_series.html#index",
    "title": "16  Time series",
    "section": "16.5 Index",
    "text": "16.5 Index\nWhen making comparisons on multi-line plots, index is a way of scaling the data: Each value is divided by the first value for that group and multiplied by 100.\n\nurlfile=\"https://raw.githubusercontent.com/jtr13/data/master/WA_Sales_Products_2012-14.csv\"\nsale&lt;-read_csv(url(urlfile))\n\nsale$Q &lt;- as.numeric(substr(sale$Quarter, 2, 2))  \n# convert Q to end-of-quarter date \nsale$Date &lt;- as.Date(paste0(sale$Year, \"-\",as.character(sale$Q*3),\"-30\")) \n\nMethoddata &lt;- sale |&gt;\n  mutate(Revenue = Revenue/1000000) |&gt;\n  group_by(Date,`Order method type`) |&gt;\n  summarize(Revenue = sum(Revenue))  |&gt;\n  ungroup() |&gt;\n  group_by(`Order method type`) |&gt;\n  mutate(index = round(100*Revenue/Revenue[1], 2)) |&gt;\n  ungroup()\n  \ng &lt;- ggplot(Methoddata, aes(Date, index,color = `Order method type`)) +\n  geom_line(aes(group = `Order method type`)) +\n  scale_x_date(limits = c(as.Date(\"2012-02-01\"), as.Date(\"2014-12-31\")), date_breaks = \"6 months\", date_labels = \"%b %Y\")\ng",
    "crumbs": [
      "R graphics",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Time series</span>"
    ]
  },
  {
    "objectID": "spatial.html",
    "href": "spatial.html",
    "title": "17  Spatial data",
    "section": "",
    "text": "17.1 Introduction\nThe page is currently being updated, check back later.\nIn this chapter, we will take a glimpse into spatial analysis using R. There are an overwhelming number of R packages for analyzing and visualizing spatial data. In broad terms, spatial visualizations require a merging of non-spatial and spatial information. For example, if you wish to create a choropleth map of the murder rate by county in New York State, you need county level data on murder rates, and you also need geographic data for drawing the county boundaries, stored in what are called shape files.\nA rough divide exists between packages that don’t require you deal with shape files and those that do. The former work by taking care of the geographic data under the hood: you supply the data with a column for the location and the package takes care of figuring out how to draw those locations.",
    "crumbs": [
      "R graphics",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Spatial data</span>"
    ]
  },
  {
    "objectID": "spatial.html#packages",
    "href": "spatial.html#packages",
    "title": "17  Spatial data",
    "section": "17.2 Packages",
    "text": "17.2 Packages\n\n17.2.1 choroplethr\nChoropleth maps use color to indicate the value of a variable within a defined region, generally political boundaries. choroplethr is capable of drawing state and county level maps without using shape files.\nConsider the following example using state.x77 showing the percentage of illiterate in each states. Note the process of data transformation, you need to exactly have a column named ‘region’ with the state names and a column named ‘value’.\n\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(tibble)\nlibrary(ggplot2)\nlibrary(choroplethr)\n\n# data frame must contain \"region\" and \"value\" columns\n\ndf_illiteracy &lt;- state.x77 |&gt; as.data.frame() |&gt; \n  rownames_to_column(\"state\") |&gt; \n  transmute(region = tolower(`state`), value = Illiteracy)\n\nstate_choropleth(df_illiteracy,\n                 title = \"State Illiteracy Rates, 1977\",\n                 legend = \"Percent Illiterate\")\n\n\n\n\n\n\n\n\nPlotting at county level is also possible. In the following example we show the population of counties in New York state in 2012.\n\nlibrary(choroplethrMaps)\ndata(county.regions)\ndata(df_pop_county) \n\nny_county_fips = county.regions |&gt;\n  filter(state.name == \"new york\") |&gt;\n  select(region)\n\ncounty_choropleth(df_pop_county, \n                  title = \"Population of Counties in New York State in 2012\",\n                  legend = \"Population\",\n                  county_zoom = ny_county_fips$region)\n\n\n\n\n\n\n\n\nWe use county_choropleth to create a U.S map at county level and zoom into New York state. Note that county_zoom takes in fips codes of counties. For more reference, visit the R documentation page.\n\n\n17.2.2 ggmap\nggmap is a great package to generate real-world maps. Moreover, it is compatible with ggplot2 allowing you to easily add layers on top of the base map. There are two options in generating maps and we demonstrate one using stamenmap. (This now requires an API key… to be updated.)\n\n# eval=FALSE for now...\nlibrary(ggmap)\n\nny_map &lt;- get_stadiamap(bbox = c(left = -74.2591, bottom = 40.4774, \n                                 right = -73.7002, top = 40.9162),\n                        zoom = 10, maptype = \"stamen_toner_lite\")\n\nggmap(ny_map) +\n  geom_point(aes(x=-73.9857,y=40.7484),size=0.8,color='blue') \n\nA map of New York City is created, and you will see a blue point representing Empire State Building. You can very simply add points using geom_point as long as you have the coordinates for the points. However, one clear drawback using stamenmap is that the map resolution is not satisfying and you will eventually find that the smaller zoom value creates blurry maps.\nFor this reason, we encourage readers to try the option using Google maps. You will need to set up a Google Cloud account (requires credit card). After enabling the Google map APIs, register you API keys with ggmap using register_google(key = \"[your key]\") and you are all set. Now take a look at the an example using Google map API\nggmap(get_googlemap(center = c(lon = -74.006, lat = 40.7128),zoom = 14))\n\n\n\nYou will see the map is at great resolution regardless of how you zoom in. For demonstration purpose, we provided a image of the map derived by running the code. For more details regarding the package usage, you can refer at ggmap GitHub page.",
    "crumbs": [
      "R graphics",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Spatial data</span>"
    ]
  },
  {
    "objectID": "spatial.html#shape-file",
    "href": "spatial.html#shape-file",
    "title": "17  Spatial data",
    "section": "17.3 Shape file",
    "text": "17.3 Shape file\nThere are cases such that no existing packages can directly create your desired map. For example, what if we want to create a map of highways in New York State. In such case, we will resort to shape files. In the following example, we use the shape file of police precinct in New York City.\n\n17.3.1 sf\nWe use sf library to read in shape files. One of the first thing to remember is that one shape file contains a set of files and all of them required for the shape file to run properly. However, when reading the file, we only need to use the one ending with .shp. For example\n\nlibrary(sf)\nny_police = st_read('nyc_police/nypp.shp',quiet=TRUE) |&gt;\n  mutate(Precinct = as.character(Precinct))\n\nhead(ny_police)\n\nSimple feature collection with 6 features and 3 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 971013.5 ymin: 188082.3 xmax: 992119.1 ymax: 217541.3\nProjected CRS: NAD83 / New York Long Island (ftUS)\n  Precinct Shape_Leng Shape_Area                       geometry\n1        1   81117.86   47300568 MULTIPOLYGON (((972081.8 19...\n2        5   18807.12   18094527 MULTIPOLYGON (((987399.2 20...\n3        6   26413.24   22103327 MULTIPOLYGON (((984337.5 20...\n4        7   17288.06   18365996 MULTIPOLYGON (((991608.6 20...\n5        9   19773.00   21395839 MULTIPOLYGON (((992119.1 20...\n6       10   40281.97   27266581 MULTIPOLYGON (((983866 2172...\n\n\nYou can see that the object looks like a data set, except with a long column called geometry. The geometry column contains spatial information and is the key to map generation.\nTo simply see the shape, we can use st_geometry() to extract spatial information and feed into plot()\n\nplot(st_geometry(ny_police))\n\n\n\n\n\n\n\n\nWe get a map of New York City divided by police precinct. Note that if you directly feed in ny_police into plot(), you will get mulitiply maps drawn from each column. It might not create you desired maps and when you are dealing with large shape files, it will be extremely slow.\n\n\n17.3.2 tmap\nOnly generating the map is not particularly meaningful. We want to combine data with the map to convey some meaningful findings. Since we are using police precinct, it is only natural to use crime data.\n\nlibrary(readxl)\nlibrary(tmap)\n\nny_crime &lt;- read_xls('data/felony.xls', skip = 1) |&gt; \n  rename(Precinct = PCT, Crime = CRIME) |&gt; \n  fill(Precinct) |&gt; \n  filter(Crime == \"TOTAL SEVEN MAJOR FELONY OFFENSES\")\n\nny_crime &lt;- left_join(ny_police, ny_crime)\n\nWe read in the felony data for nyc in 2021 and joined it with the sf object. Then, we create map using tmap package. Notice that in tm_polygons(), we specify the column to be 2021.\n\nny_crime |&gt; \n  tm_shape() + \n  tm_polygons(\"2021\", palette = \"Blues\", title=\"\") + \n  tm_text(\"Precinct\", size = .65) +\n  tm_layout(\"Major Felony Offenses in 2021 by\\nNYC Police Precinct\",\n            title.size = .95, frame = FALSE)\n\n\n\n\n\n\n\n\nFor more usage, you can refer at tmap:get started!",
    "crumbs": [
      "R graphics",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Spatial data</span>"
    ]
  },
  {
    "objectID": "cutting_room_floor.html",
    "href": "cutting_room_floor.html",
    "title": "18  Cutting room floor",
    "section": "",
    "text": "18.1 Parallel coordinate plots\nIt’s worth remembering that most graphs end up on the proverbial cutting room floor. Some graph types in particular are truly hit or miss: parallel coordinate plots are at the top of the list in this category. I’m including some of the “misses” here so you’ll realize you’re not alone if you create a graph that does not show anything worthwhile.\nlibrary(dplyr)\nlibrary(forcats)\nlibrary(ggplot2)\nlibrary(readr)\nlibrary(stringr)\nlibrary(tibble)\nlibrary(tidyr)\n\noedi_building &lt;- read_csv(\"data/oedi_building.csv\")\noedi_building |&gt;\n  filter(str_detect(in.building_type, \"Office\")) |&gt; \n  GGally::ggparcoord(columns = 1:4, groupColumn = 5, \n                     alphaLines = .5, splineFactor = 10)\noedi_building |&gt;\n  select(c(starts_with(\"in.week\")), in.heating_fuel) |&gt;\n  rownames_to_column(\"ID\") |&gt; \n  pivot_longer(cols = starts_with(\"in.week\"),\n               names_to = \"variable\", values_to = \"value\") |&gt; \n  ggplot(aes(x = variable, y = value, group = ID, color = in.heating_fuel)) +\n  geom_line(lwd = .1) +\n  theme_bw() +\n  coord_flip()\n# https://collegescorecard.ed.gov/data\ndf &lt;- read_csv(\"data/college_scorecard.csv\")\n\ndf |&gt; \n  na.omit() |&gt; \n  mutate(COMP_ORIG_YR4_RT = as.numeric(COMP_ORIG_YR4_RT)) |&gt; \n  mutate(WOMENONLY = fct_recode(factor(WOMENONLY), `Women only` = \"0\", `Not women only` = \"1\")) |&gt; \nGGally::ggparcoord(columns = 1:4, alphaLines = .5,\n                   scale = \"globalminmax\", groupColumn = 5) +\n  theme_bw() +\n  theme(legend.position = \"bottom\", legend.title = element_blank())\nuk &lt;- read_csv(\"data/uk_universities.csv\",\n               col_types = \"ccdcddddddnncccccdddc\")\nuk |&gt; \n  GGally::ggparcoord(columns = c(5, 7, 9:12),\n                     alphaLines = .5, groupColumn = 2) + \n  coord_flip()\n# https://www.strava.com/clubs/537620/leaderboard \nrun &lt;- read_csv(\"data/leaderboard.csv\", na = \"--\")\n\nrun$Longest &lt;- parse_number(run$Longest)\nrun$Distance &lt;- parse_number(run$Distance)\nrun$Pace &lt;- parse_number(run$`Avg. Pace`)\nrun$Gain &lt;- parse_number(run$`Elev. Gain`)\n\nrun |&gt; \n  filter(Distance &lt; 1000, Rank &lt;= 50) |&gt; \n  select(Athlete, Distance, Runs, Longest, Pace, Gain) |&gt; \n  parcoords::parcoords(rownames = F,\n                       reorderable = TRUE,\n                       brushMode = \"1D-axes\")\nlibrary(parcoords)\nuk |&gt; \n  filter(str_detect(Region, \"England\")) |&gt; \n  select(University_name, UK_rank, UGfees = `UG_average_fees_(in_pounds)`,\n         PGfees = `PG_average_fees_(in_pounds)`,\n         International_students, \n         Student_satisfaction,\n         COL = `Estimated_cost_of_living_per_year_(in_pounds)`,\n         Campus_setting) |&gt; \n parcoords(rownames = FALSE,\n           reorderable = TRUE,\n           brushMode = \"1D-axes\",\n           color = list(colorBy = \"Campus_setting\",\n                         colorScale = \"scaleOrdinal\",\n                         colorScheme = \"schemeCategory10\"),\n           withD3 = TRUE,\n           width = 770,\n           height = 600)",
    "crumbs": [
      "Appendix",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Cutting room floor</span>"
    ]
  }
]